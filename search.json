[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Programming for Engineering Biology (EB501, KAIST 2023)",
    "section": "",
    "text": "0.1 소개\n카이스트 공학생물학 대학원 강의용 강의노트 (2023.11)\n일부 R 관련 좀 더 상세한 내용은 다음 사이트를 참고하세요 kribbr2022",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>EB501</span>"
    ]
  },
  {
    "objectID": "index.html#데이터-분석",
    "href": "index.html#데이터-분석",
    "title": "R Programming for Engineering Biology (EB501, KAIST 2023)",
    "section": "0.2 데이터 분석",
    "text": "0.2 데이터 분석\n\n\n\nfrom https://r4ds.had.co.nz/\n\n\nposit의 대표적 개발자인 해들리위컴은 R for Data Science의 서두에 위와 같은 그림으로 데이터과학을 설명하고 있습니다. 원본 데이터는 Tidy 형태로 R로 불러와야 하고 언제든 분석에 맞는 형태로 변형 할 수 있어야 합니다. 그리고 항상 시각화를 통해 데이터를 직접 검증해야하고 모델을 사용해서 원하는 분석을 수행합니다. 분석 후에는 공유를 통해 객관적인 검증이 필요합니다. R은 이 모든 과정을 빠르고 효율적으로 수행할 수 있는 최고의 언어입니다. 데이터과학 입장에서는 위 도구들을 둘러싸고 있는것이 프로그래밍 입니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>EB501</span>"
    ]
  },
  {
    "objectID": "index.html#라이선스",
    "href": "index.html#라이선스",
    "title": "R Programming for Engineering Biology (EB501, KAIST 2023)",
    "section": "0.3 라이선스",
    "text": "0.3 라이선스\n이 책은 Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) 라이선스에 따라 제공됩니다.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>EB501</span>"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 R / RStudio Introduction\nR은 통계학, 생물통계학, 유전학 등의 연구 분야에서 널리 사용되는 오픈소스 프로그래밍 언어입니다. S 언어에서 파생되었고, 데이터 분석 및 가시화 패키지들이 강점입니다. 최근 인공지능의 관심이 크게 증가하면서 python 언어의 수요가 더 증가하긴 했으나 특히 중,소규모의 데이터 전처리와 가시화, 통계분석 측면에서 여전히 많은 사용자를 확보하고 있는 언어입니다.\nR언어가 주목을 받고 두터운 사용자 층을 확보할 수 있게된 핵심 동력이 Rstudio 입니다. Rstudio를 개발한 Posit은 자체적으로 최고수준의 오픈소스 개발팀이 있으며 tidyverse, tidymodel, shiny 등의 데이터 분석 및 가시화 관련 주요 패키지를 개발하였고 정기적으로 conference 개최를 하면서 기술 보급의 핵심 역할을 하고 있습니다. R을 활용한 데이터 분석은 tidyverse 가 나오기 이전과 이후로 분리될 수 있을 정도로 tidyverse는 많은 변화와 효율향상을 이뤄냈습니다.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#installing-r-rstudio",
    "href": "01-intro.html#installing-r-rstudio",
    "title": "2  Introduction",
    "section": "2.2 Installing R / RStudio",
    "text": "2.2 Installing R / RStudio\nR 사용을 위해서는 R 언어의 코어 프로그램을 먼저 설치하고 그 다음 R 언어용 IDE(Integrated Development Environment)인 RStudio 설치가 필요합니다. Rstudio는 R 언어를 위한 오픈소스 기반 통합개발환경(IDE)으로 R 프로그래밍을 위한 편리한 기능들을 제공해 줍니다.\n\n2.2.1 Installing R\n\nR 공식 웹사이트 [https://www.r-project.org/]를 방문하세요. 왼쪽 메뉴 상단에 위치한 CRAN을 클릭합니다.\n목록에서 한국 미러 사이트 중 하나를 선택합니다.\n‘Windows용 R 다운로드’를 클릭한 다음 ’base’ 링크로 들어갑니다.\n’Windows용 R x.x.x 다운로드’를 클릭하여 실행 가능한 프로그램을 다운로드합니다.\n다운로드된 R-x.x.x-win.exe 파일을 로컬 컴퓨터에서 실행합니다 (2023년 11월 현재, R의 최신 버전은 4.3.2입니다).\n설치 프로그램의 지시에 따라 R 언어 소프트웨어 설치를 완료합니다.\n\n\n\n2.2.2 Installing RStudio\n\nPosit의 Rstudio 공식 [https://posit.co/] 웹사이트를 방문한 다음, 페이지 상단의 ’Products &gt; RStudio IDE’를 클릭합니다.\n‘Open Source Edition’ Free의 ’Download Rstudio Desktop’을 클릭합니다.\n’Download Rstudio’의 ’Download Rstudio desktop for windows’를 클릭하여 다운로드를 시작합니다.\n다운로드된 RStudio-x.x.x.exe 파일을 로컬 컴퓨터에서 실행합니다 (2023년 11월 현재, RStudio 데스크톱의 최신 버전은 2023.09입니다).\n설치 가이드를 따라 설치를 완료합니다.\n\n\n\n2.2.3 Posit Cloud\nPosit Cloud는 클라우드에서 RStudio를 제공하여 사용자가 설치 및 설정 없이 브라우저에서 직접 RStudio를 사용할 수 있게 합니다.\n\nposit.cloud에 방문하여 사용자로 등록합니다 (Google 계정을 사용할 수 있습니다).\n로그인하고 ’Cloud Free’를 선택하여 시작합니다.\n이 환경에서는 1GB의 RAM과 1 CPU를 무료로 제공합니다.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#rstudio-interface-and-keyboard-shortcuts",
    "href": "01-intro.html#rstudio-interface-and-keyboard-shortcuts",
    "title": "2  Introduction",
    "section": "2.3 RStudio Interface and Keyboard Shortcuts",
    "text": "2.3 RStudio Interface and Keyboard Shortcuts\nRStudio는 코드 편집 창, 콘솔 창, 환경 및 파일 패널을 제공합니다.\n주요 키보드 단축키\n\n코드 실행: Ctrl + Enter\n콘솔 창으로 이동: Ctrl + 2\n코드 편집 창으로 이동: Ctrl + 1\n저장: Ctrl + S\n코드 주석 처리: Ctrl + Shift + C",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#starting-a-project",
    "href": "01-intro.html#starting-a-project",
    "title": "2  Introduction",
    "section": "2.4 Starting a Project",
    "text": "2.4 Starting a Project\n’RStudio’에서 ’파일 &gt; 새 프로젝트’로 가서 새 프로젝트를 시작할 수 있습니다.\n\nHello World Example\nCreate a new R file and execute the following code:\n\n\nmystring &lt;- \"Hello \\n world!\"\ncat(mystring)\nprint(mystring)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#getting-help",
    "href": "01-intro.html#getting-help",
    "title": "2  Introduction",
    "section": "2.5 Getting Help",
    "text": "2.5 Getting Help\nR은 방대한 도움말 데이터를 제공하며, 다음과 같은 명령어로 특정 함수의 도움말과 예제를 찾아볼 수 있습니다.\n\nhelp(\"mean\")\n?mean\nexample(\"mean\")\nhelp.search(\"mean\")\n??mean\nhelp(package=\"MASS\")\n\nRStudio 치트시트는 다양한 R 기능을 한눈에 알아볼 수 있게 만든 cheatsheet 형태의 문서를 참고할 수 있습니다. 자세한 내용은 Posit Cheatsheets를 참조하세요.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#r-패키지와-데이터셋",
    "href": "01-intro.html#r-패키지와-데이터셋",
    "title": "2  Introduction",
    "section": "2.6 R 패키지와 데이터셋",
    "text": "2.6 R 패키지와 데이터셋\nR 패키지는 함수와 데이터셋의 묶음으로, 다른 사람들이 만들어 놓은 코드나 기능을 가져와 사용함으로써 코드 작성의 수고로움을 줄이고, 편리하고 검증된 함수(기능)를 빠르게 도입하여 사용할 수 있습니다. 예를 들어 sd() 함수는 stats 패키지에서 제공하는 함수로, 표준편차 계산을 위한 별도의 함수를 만들어서 사용할 필요가 없습니다.\n\nlibrary(UsingR)\n\n\n2.6.1 패키지 설치 및 로드\n패키지는 CRAN 또는 Bioconductor와 같은 저장소에서 구할 수 있으며, 아래와 같이 RStudio를 이용하거나 콘솔창에서 install.packages() 함수를 이용할 수 있습니다.\n\ninstall.packages(\"UsingR\")\n\n\n\n2.6.2 설치 디렉토리 확인하기\nR 및 패키지의 설치 디렉토리는 다음 명령어로 확인할 수 있습니다.\n\n.libPaths()\npath.package()\n\n\n\n2.6.3 패키지 데이터 사용하기\n패키지 안에 포함된 데이터도 사용할 수 있으며 data() 함수를 이용해서 패키지 데이터를 사용자 작업공간에 복사해서 사용할 수 있습니다.\n\ndata(rivers)\nlength(rivers)\nclass(rivers)\ndata(package=\"UsingR\")\nlibrary(HistData)\nhead(Cavendish)\nstr(Cavendish)\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-markdown.html",
    "href": "02-markdown.html",
    "title": "3  Quarto and Markdown",
    "section": "",
    "text": "3.1 Introduction\nQuarto는 데이터 과학에서 사용되는 코드와 리포트를 결합할 수 있는 통합 문서 시스템입니다. 마이크로소프트 워드나 한글과 같은 워드 프로세서에서 프로그래밍 코드와 데이터 분석을 수행할 수 있는 것처럼, Quarto를 사용하면 텍스트 기반의 마크다운 문법으로 문서를 작성하고 다양한 형식의 출력물로 변환할 수 있습니다. 이러한 출력물에는 HTML, PDF, Word 문서, 슬라이드 쇼, 책, 웹사이트 등이 포함됩니다.\nQuarto에 대한 더 자세한 정보는 Quarto 공식 웹사이트에서 확인할 수 있습니다. 해당 웹사이트에는 Quarto 소개 동영상과 Quarto 공식 사이트 메뉴얼이 있으며, Quarto를 사용할 때 참고할 수 있는 cheatsheet도 제공됩니다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#quarto의-기본-작동-원리",
    "href": "02-markdown.html#quarto의-기본-작동-원리",
    "title": "3  Quarto and Markdown",
    "section": "3.2 Quarto의 기본 작동 원리",
    "text": "3.2 Quarto의 기본 작동 원리\nQuarto는 plain text 기반으로 작성되며 .qmd 라는 확장자를 갖는 파일로 저장됩니다. 다음과 같은 텍스트 파일이 Quarto 파일의 전형적인 예입니다.\n\nQuarto 문서에는 주로 세 가지 유형의 컨텐츠가 포함됩니다. 첫째, YAML 헤더는 문서의 메타데이터를 정의하며, JSON처럼 데이터를 저장하는 데 사용됩니다. 둘째, 코드 청크는 백틱(```)으로 둘러싸여 있으며, R, Python 등의 다양한 언어 코드를 실행할 수 있습니다. 셋째, 일반 텍스트와 마크다운 문법으로 작성된 내용입니다.\n    ---\n    title: \"Lecture\"\n    format: \n      html:\n        toc: true\n        toc-floating: true\n        toc-depth: 2\n        number-sections: true\n    ---\n이러한 Quarto 파일은 render라는 명령어로 원하는 포맷의 문서로 변환할 수 있습니다. 아래 화면은 기본 Quarto 문서 생성시 보여지는 내용이며 html 형식으로 rendering 하기 위해서는 YAML에 html 임을 명시하고 아래와 같이 render함수를 사용하면 됩니다. 또는 Rstudio 코드 입력창 상단의 Render 버튼으로 pdf나 html 문서를 생성할 수 있습니다.\n\nQuarto는 내부적으로 knitr 패키지를 사용하여 R 및 기타 언어의 코드를 실행하여 .md 파일로 변환하고 .md 파일은 pandoc을 통해 HTML, PDF, Word 등 다양한 형식의 문서로 최종 변환됩니다\n```{r}\n#| eval=F\n\nquarto::quarto_render(\"test.qmd\", output_format = \"html\")\n```",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#코드-입력",
    "href": "02-markdown.html#코드-입력",
    "title": "3  Quarto and Markdown",
    "section": "3.3 코드 입력",
    "text": "3.3 코드 입력\nQuarto에서 코드 청크를 삽입하는 방법은 다음과 같습니다. 단축키 Ctrl + Alt + I (Windows) 또는 Cmd + Option + I (macOS)를 사용할 수 있습니다. 코드 청크의 실행과 표시 여부를 결정하는 옵션을 다음과 같이 사용할 수 있습니다:\n\ninclude: false - 코드는 실행되지만 결과와 코드를 문서에 표시하지 않습니다.\necho: false - 코드는 실행되고 결과가 포함되지만 코드는 숨깁니다.\neval: false - 코드를 실행하지 않고 문서에만 표시합니다.\nmessage: false, warning: false, error: false - 코드 실행 중 발생하는 메시지, 경고, 에러를 숨깁니다.\nfig.cap: \"...\" - 코드로 생성된 그림에 캡션을 추가합니다.\n\nR 코드 청크 예시:\n코드는 실행되지만 결과와 코드를 표시하지 않습니다.\n```{r}\n#| include=FALSE\n\nsummary(cars)\n```\n코드는 실행되고 결과가 포함되지만 코드는 숨깁니다.\n```{r}\n#| echo=FALSE\n\nsummary(cars)\n```\n코드를 실행하지 않고 문서에만 표시합니다.\n```{r}\n#| eval=FALSE\n\nsummary(cars)\n```\nPython 코드 청크 예시:\n```{python}\n#| eval: false\nx = \"hello, python in Quarto\"\nprint(x.split(' '))\n```\nQuarto 문서에서 코드 청크와 마크다운 문법을 사용하여 내용을 서식화하고 다양한 프로그래밍 언어의 코드를 실행할 수 있습니다. Quarto에 대한 자세한 정보와 사용법은 Quarto 공식 문서에서 확인할 수 있습니다.\nQuarto에서는 `r ` 을 사용해서 코드청크가 아닌 곳에 R 코드를 넣을 수 있습니다 (Inline code). 또한 R 언어 외에도 Python, SQL, Bash, Rcpp, Stan, JavaScript, CSS 등의 다양한 프로그래밍 언어에 대해서도 코드청크 기능을 사용할 수 있습니다. 그런데 이러한 언어들이 사용 가능해지기 위해서는 해당 언어들을 실행해주는 엔진이 (인터프리터) 있어야 하며 python의 경우 reticulate 라는 패키지가 이러한 기능을 담당합니다. 이 패키지를 설치할 경우 miniconda라는 가상환경 및 데이터 분석을 위한 오픈소스 패키지가 자동으로 설치됩니다.\n```{r}\n#| eval: false\nlibrary(reticulate)\n```\n위 reticulate 라이브러리를 로딩 후 아래 python 코드청크를 실행시킬 수 있습니다.\n```{python}\n#| eval: false\nx = \"hello, python in R\"\nprint(x.split(' '))\n```",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#markdown-문법",
    "href": "02-markdown.html#markdown-문법",
    "title": "3  Quarto and Markdown",
    "section": "3.4 Markdown 문법",
    "text": "3.4 Markdown 문법\n마크다운은 plain text 기반의 마크업 언어로서 마크업 언어는 태그 등을 이용해서 문서의 데이터 구조를 명시하는데 이러한 태그를 사용하는 방법 체계를 마크업 언어라고 합니다. 가장 대표적으로 html 이 있습니다.\n    &lt;html&gt;\n      &lt;head&gt;\n        &lt;title&gt; Hello HTML &lt;/title&gt;\n      &lt;/head&gt;\n      &lt;body&gt;\n      Hello markup world!\n      &lt;/body&gt;\n    &lt;/html&gt;\n마크다운도 몇 가지 태그를 이용해서 문서의 구조를 정의하고 있으며 상세한 내용은 Pandoc 마크다운 문서를 참고하시기 바랍니다. 마크다운언어의 철학은 쉽게 읽고 쓸 수 있는 문서입니다. plain text 기반으로 작성되어 쓰기 쉬우며 (아직도 사람들이 메모장 많이 사용하는 이유와 같습니다) 태그가 포함되어 있어도 읽는데 어려움이 없습니다. 위 html 언어와 아래 markdown 파일의 예들을 보시면 그 차이를 어렵지 않게 이해할 수 있습니다.\n마크다운에서는 Enter를 한 번 입력해서 줄바꿈이 되지 않습니다. &lt;br&gt; 또는 문장 마지막에 공백을 두 개 입력하면 되겠습니다.\n    이 분장은 줄바꿈이&lt;br&gt;\n    됩니다\n마크다운 테그를 몇 가지 살펴보면 먼저 # 을 붙여서 만드는 header 가 있습니다.\n    # A level-one header\n    ## A level-two header\n    ### A level-three header\n\n    # A level-one header {#l1-1}\n    ## A level-two header {#l2-1}\n    ### A level-three header {#l3-1}\n\n    # A level-one header {#l1-2}\n    ## A level-two header {#l2-2}\n    ### A level-three header {#l3-2}\n인용문구를 나타내는 Block quotations이 있습니다.\n\nThis is block quote. This paragraph has two lines\n\n    &gt; This is block quote. This paragraph has two lines\n\nThis is a block quote.\n\nA block quote within a block quote.\n\n\n    &gt; This is a block quote.\n    &gt;\n    &gt; &gt; A block quote within a block quote.\nItalic\n    *Italic*\nBold\n    **Bold**\nNaver link\n    [Naver link](https://www.naver.com/)\n이미지를 직접 삽입하고 가운데 정렬합니다.\n\n\n\n\n자동차 모델에 따른 고속도로 연비 분포\n\n\n\n    &lt;center&gt;\n    ![자동차 모델에 따른 고속도로 연비 분포](images/rmarkdown/000002.png){width=\"200\"}\n    &lt;/center&gt;\nLists:\n순서형 리스트는 숫자 해더를 사용하고 비순서형 리스트는 dash나 다른 bullet 포인트를 사용합니다.\n\n첫 번째\n두 번째\n세 번째\n\n\n아이템 1\n아이템 2\n아이템 3\n\n아이템 3-1\n아이템 3-2\n\n\n\n    1.  첫 번째\n    2.  두 번째\n    3.  세 번째\n    \n    -   아이템 1\n    -   아이템 2\n    -   아이템 3\n        -   아이템 3-1\n        -   아이템 3-2\n참고로 소스코드 그대로 표현하기 위해서는 #| echo: fanced 를 사용하거나 두 개의 중괄호 (curly braces)를 (fanced echo 도움말) 사용하며 일반 택스트의 경우는 백틱 세 개나 (```) 들여쓰기를 사용합니다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#스타일",
    "href": "02-markdown.html#스타일",
    "title": "3  Quarto and Markdown",
    "section": "3.5 스타일",
    "text": "3.5 스타일\n아래와 같이 YAML 해더에 css파일을 삽입하고 해당되는 class 또는 id에 해당하는 내용에 스타일을 적용할 수 있습니다.\n    .header1 {\n    color: red;\n    }\n위와 같이 style.css 파일 작성 후 quarto파일에서 다음과 같이 사용\n    ---\n    title: \"test\"\n    format:\n      html:\n        css: styles.css\n    ---\n    \n    ```{r}\n    #| classes: header\n    \n    2 + 2\n    ```",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#테이블",
    "href": "02-markdown.html#테이블",
    "title": "3  Quarto and Markdown",
    "section": "3.6 테이블",
    "text": "3.6 테이블\nkable 함수를 이용하여 Quarto 문서에 포함되는 표를 원하는 방향으로 작성할 수 있습니다. mtcars는 데이터프레임 형식의 데이터입니다.\n\nknitr::kable(\n  mtcars[1:5, ], \n  caption = \"A knitr kable.\"\n)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#yaml-헤더",
    "href": "02-markdown.html#yaml-헤더",
    "title": "3  Quarto and Markdown",
    "section": "3.7 YAML 헤더",
    "text": "3.7 YAML 헤더\nQuarto 파일에서 YAML의 가장 중요한 기능은 output 포멧을 지정하는 것이며 title, author, date, 등을 설정할수도 있습니다.\n    ---\n    title: \"R Programming\"\n    subtitle: \"Using Quarto\"\n    format:\n      html:\n        css: style.css\n        includes:\n          in_header: header.html\n          after_body: footer.html\n        toc: true\n        toc_float: true\n        number_sections: true\n    mainfont: NanumGothic\n    ---",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "02-markdown.html#output-format",
    "href": "02-markdown.html#output-format",
    "title": "3  Quarto and Markdown",
    "section": "3.8 Output format",
    "text": "3.8 Output format\nQuarto의 output format 설정은 사용자가 만드는 문서의 종류와 필요에 맞게 유연하게 조정할 수 있으며, 이를 통해 다양한 형식의 고품질 문서를 생성할 수 있습니다. Quarto 문서에 대한 보다 자세한 정보는 Quarto 공식 문서에서 확인할 수 있습니다.\n\n\n\n\n\n\nExercises\n\n\n\n\n기본 HTML 문서 생성. Quarto를 사용하여 간단한 HTML 문서를 생성합니다. 이 문서에는 자기 소개, 몇 개의 섹션, 그리고 R 코드 청크가 포함되어야 합니다.\n\n\n새 Quarto 문서 생성\n문서의 제목을 “My Quarto”로 설정\nYAML 헤더에 format: html 추가\n마크다운 언어로 자기소개 섹션과 데이터 분석 섹션 추가\n“데이터 분석” 섹션에 mtcars 데이터셋의 요약 통계를 보여주는 코드 청크를 포함\n\n\n슬라이드 쇼 생성. Quarto를 사용하여 간단한 슬라이드 쇼를 생성합니다. 이 슬라이드 쇼에는 여러 개의 슬라이드와 최소 하나의 인터랙티브한 R 코드 청크가 포함되어야 합니다.\n\n\n새 Quarto 문서를 생성하고 파일 이름을 “슬라이드 쇼 연습”으로 설정\nYAML 헤더에 format: revealjs 추가\n첫 번째 슬라이드에는 간단한 소개 및 슬라이드 쇼의 주제 작성\n두 번째 슬라이드에는 ggplot2 사용한 mtcars 데이터셋의 mpg vs. cyl 그래프 표시\nlibrary(ggplot2)\nggplot(mtcars, aes(x=cyl, y=mpg)) + geom_point()\n세 번째 슬라이드에는 결론 및 요약 포함\n\n\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Quarto and Markdown</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html",
    "href": "03-r-programming.html",
    "title": "4  R-programming",
    "section": "",
    "text": "4.1 What is a programming language\n프로그래밍 언어는 임의의 문제를 해결하기 위해서 만들어진 인간이 이해할 수 있는 코드를 기계가 이해할 수 있는 코드로 전환해주는 도구입니다. 즉, 인간과 기계가 소통하기 위한 언어를 말하며 프로그램은 해당 문제를 풀기위한 논리 연산의 집합으로 봅니다.\nR은 programming language로서 다른 프로그래밍 언어와 같이 몇 가지 공통적 개념을 가지고 있지만 (변수, 자료형, 함수, 조건문, 반복문) 또한 다른 언어와 차별되는 목적과 기능을 가집니다. 이번 장에서는 변수(variable, Object), 자료형(Class), 함수(Function), 조건문 및 반복문 (Flow control)에 대해서 알아보도록 합니다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html#console-calculator",
    "href": "03-r-programming.html#console-calculator",
    "title": "4  R-programming",
    "section": "4.2 Console calculator",
    "text": "4.2 Console calculator\nR은 콘솔에서 바로 계산을 수행할 수 있는 스크립트 언어입니다. 다음과 같은 연산을 콘솔에 입력하고 엔터를 누르면 결과를 바로 볼 수 있습니다. 참고로 이전에 수행한 명령은 콘솔에 커서가 있는 상태에서 위 아래 화살표를 누르면 볼 수 있고 엔터를 눌러 재사용 할 수 있습니다. ;을 사용하면 두 개의 명령을 동시에 수행할 수 있습니다.\n\n2 + 2\n((2 – 1)^2 + (1 – 3)^2 )^(1/2)\n2 + 2; 2 - 2\n\n\n\n\n\n\n\nExercises\n\n\n\n\n다음 공식들을 계산하는 R 코드를 작성하시오\n\n\\[ \\sqrt{(4+3)(2+1)} \\]\n\\[ 2^3 + 3^2 \\]\n\\[ \\frac{0.25 - 0.2}{\\sqrt{0.2 (1-0.2)/100}}\\]\n\n\n\n4.2.1 Terminology\n\nSession: R 언어 실행 환경\nConsole: 명령어 입력하는 창\nCode: R 프로그래밍 변수/제어문 모음\nObject: 변수, 함수 등 프로그래밍에서 사용되는 모든 객체 (Data structure)\n\narray: 1D, 2D, 3D, … 형태 값들의 모임\nvector: 1차원 형태 값들의 모임 combine function c() EX: c(6, 11, 13, 31, 90, 92)\nmatrix: 2차원 형태 값들의 모임 (같은 타입 값으로 구성)\ndata frame: 2차원 형태 값들의 모임 (다른 타입 값 구성 가능)\nlist: vector, matrix, data.frame 및 list 등 다양한 객체를 원소로 가집\n\nfunction: 특정 기능 수행, [함수이름, 입력값 (arguments), 출력값 (return)] 으로 구성\nData (value): 값 - 자료형 (Data type)\n\nIntegers\ndoubles/numerics\nlogicals\ncharacters\nfactor: 범주형\n\nConditionals (조건, 제어):\n\nif, ==, & (AND), | (OR) Ex: (2 + 1 == 3) & (2 + 1 == 4)\nfor, while: 반복 수",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html#data-and-variables",
    "href": "03-r-programming.html#data-and-variables",
    "title": "4  R-programming",
    "section": "4.3 Data and variables",
    "text": "4.3 Data and variables\n\n\n\n\n\n\n카이스트 강의\n\n\n\n(23.11.15) 데이터의 타입과 데이터를 담는 변수의 타입 구분하기\n\n\n\n4.3.1 Data\n데이터의 의미는 사실을 나타내는 수치입니다.\n\n맥도너 정보경제학 (1963)\n\n지혜 (wisdom) : 패턴화된 지식\n지식 (knowledge) : 가치있는 정보\n정보 (information) : 의미있는 데이터\n데이터 (data) : 단순한 사실의 나열\n\n\n일반적인 데이터는 속성에 따라서 다음과 같이 분류할 수 있습니다.\n\n범주형 데이터 (Categorical Data)\n\n질적 데이터로, 숫자로 표현될 수 있지만 그 숫자들은 수치적 의미를 지니지 않습니다.\n명목형 (Nominal): 순서나 순위가 없는 범주를 나타냅니다. 예시: 사람 이름.\n순서형 (Ordinal): 순서나 순위가 있는 범주를 나타냅니다. 예시: 달리기 경기의 도착 순서.\n\n수치형 데이터 (Numerical Data)\n\n수치로 표현되며, 이 수치는 데이터의 속성을 반영합니다.\n구간형 (Interval): 순서가 있고, 간격이 동일하지만, 절대적인 ’0’이 없는 데이터입니다. 예시: 선수들의 종점 통과 시간.\n비율형 (Ratio): 절대적인 ’0’이 존재하며, 비율 비교가 가능한 데이터입니다. 예시: 출발시간 대비 종점 통과 시간.\n\n\n\n\n\n4.3.2 Variables\n변수는 데이터를 저장하는 공간으로 이해할 수 있습니다.\n\nAssignment operator ( &lt;- OR = )\n\nValid object name &lt;- value\n단축키: Alt + - (the minus sign)\n\n내장 변수 Built-in variables\n\n\nx &lt;- 2\ny &lt;- x^2 – 2*x + 1\ny\nx &lt;- \"two\"  \nsome_data &lt;- 9.8\npi\n\n\n변수이름 작명법\n\nCharacters (letters), numbers, “_”, “.”\nA and a are different symbols\nNames are effectively unlimited in length\n\n\n\ni_use_snake_case &lt;- 1\notherPeopleUseCamelCase &lt;- 2\nsome.people.use.periods &lt;- 3\nAnd_aFew.People_RENOUNCEconvention &lt;- 4\n\nR에서 변수는 데이터를 담는 그릇이고 앞에서 언급한바와 같이 데이터마다 다른 특성의 타입이 있으므로 변수도 그에 맞는 타입을 갖습니다. R에서 사용하는 주요 데이터 타입은 다음과 같습니다.\n\nNumeric (수치형 데이터)\n\n\nDiscrete (이산형): 개별적인 값들로 이루어진 데이터. 예시: 카운트, 횟수.\nContinuous (연속형): 연속적인 값들로 이루어진 데이터. 예시: 키, 몸무게.\nDate and time: 날짜와 시간을 나타내는 데이터.\n\n\nFactors (범주형 데이터)\n\n\n데이터를 그룹화하는 데 사용되는 범주형 데이터\nCharacter 데이터를 범주형 데이터로 사용할 때 사용합니다. 예시: 데이터 식별자.\n\n\nCharacter (문자형 데이터)\n\n\n텍스트 문자열을 나타내는 데이터\n\n\nLogical (논리형 데이터)\n\n\n불리언(Boolean) 값인 TRUE 또는 FALSE로 표현되는 데이터\n\n다음은 R에서 가장 많이 이용되는 데이터 중 하나인 붓꽃 데이터이며 각각의 데이터 타입을 다음과 같이 확인할 수 있습니다.\n\ndata(iris)\niris\nclass(iris$Sepal.Length)\nstr(iris)\nglimpse(iris)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html#object-data-structure",
    "href": "03-r-programming.html#object-data-structure",
    "title": "4  R-programming",
    "section": "4.4 Object (Data structure)",
    "text": "4.4 Object (Data structure)\n\n\n\n\n\n\n카이스트 강의\n\n\n\n(23.11.15) 변수의 타입과 객체 (Object)의 타입 구분. R에서 Object는 함수까지 포함하고 있으나 변수 관점에서 vector, matrix, data.frame, list 등의 객체의 타입은 구조에 따라 나눌 수 있음.\n\n\n변수, 함수 등 프로그래밍에서 사용되는 모든 개체를 말합니다. 앞서 언급한 변수의 데이터 타입은 데이터 값의 타입이라고 볼 수 있고 뒤에 이야기할 vector, data.frame, list 등 데이터 타입은 변수 구조의 타입으로 볼 수 있습니다.\n\n4.4.1 vector\nvector는 R의 기본 데이터 구조입니다. numeric vector, logical vector, character vector 등 저장되는 값의 타입에 따라 크게 세가지로 나눌 수 있습니다. class() 함수를 이용해서 값의 타입을 알아낼 수 있습니다. Combine function인 c()를 활용하여 만들며 값을 순차적으로 붙여갈 수 있습니다. 다음과 같은 Univariate (단변량, Single variable)을 표현할 때 사용됩니다.\n\\[ x_1, x_2, ..., x_n \\]\n\nx &lt;- c(10.4, 5.6, 3.1, 6.4, 21.7) \nclass(x)\ny &lt;- c(\"X1\", \"Y2\",  \"X3\",  \"Y4\")\nclass(y)\nz &lt;- c(T, F, F, T)\nclass(z)\n\n\n4.4.1.1 numeric\nnumeric 형식의 벡터는 다음과 같은 다양한 편의 함수들을 사용해서 만들수 있습니다.\n\n1:5\nseq(1,5, by=1)\nseq(0, 100, by=10)\nseq(0, 100, length.out=11)\n?seq\n\nrep(5, times=10)\nrep(1:3, times=4)\nrep(1:3, each=3)\n\n\n\n\n\n\n\nExercises\n\n\n\n\nodds라는 이름의 변수에 1부터 100까지의 홀수만을 저장하시오 (seq() 함수 사용)\n\n\n\n인덱싱은 배열형 (vector, matrix, data.frame 등) 데이터의 일부 데이터를 참조할 때 사용하는 방법입니다. [와 ]를 사용하며 위치를 나타내는 수로 참조합니다.\n\nx[1]\nx[1:3]\ni &lt;- 1:3\nx[i]\nx[c(1,2,4)]\ny[3]\n\n또한 해당 위치의 이름으로 참조하기도 합니다.\n\nhead(precip)\nprecip[1]\nprecip[2:10]\nprecip[c(1,3,5)]\nprecip[-1]\nprecip[\"Seattle Tacoma\"]\nprecip[c(\"Seattle Tacoma\", \"Portland\")]\nprecip[2] &lt;- 10\n\n참고로 vector 들은 다음과 같은 builtin 함수들을 사용해서 해당 변수의 attribute를 알아낼 수 있습니다. attribute에는 원소 이름, 타입, 길이 등 vector형 변수가 가질 수 있는 특성을 말합니다.\n\nhead(precip)\nclass(precip)\nlength(precip)\nnames(precip)\n\ntest_scores &lt;- c(100, 90, 80)\nnames(test_scores) &lt;- c(\"Alice\", \"Bob\", \"Shirley\")\ntest_scores\n\n\n\n4.4.1.2 logical\nLogical 벡터는 True 또는 False를 원소로 갖는 벡터 입니다. 앞글자가 대분자로 시작하는 것을 기억하시고 T 또는 F와 같이 한 문자로 표현할 수도 있습니다. 특정 조건에 대한 판단 결과를 반환할 경우에도 논리값을 사용합니다. 이 경우 조건을 판단 후 인덱싱 방법으로 (which, any, all 등 사용) 해당 값들을 뽑아내기도 합니다. 또한 활용이 많은 sample 함수의 사용법을 익혀둡니다.\n\nx &lt;- 1:20\nx &gt; 13\ntemp &lt;- x &gt; 13\nclass(temp)\n\nages &lt;- c(66, 57, 60, 41,  6, 85, 48, 34, 61, 12)\nages &lt; 30\nwhich(ages &lt; 30)\ni &lt;- which(ages &lt; 30)\nages[i]\nany(ages &lt; 30)\nall(ages &lt; 30)\n\nrandom_number &lt;- sample(c(1:10), 2)\n\n\n\n\n\n\n\nExercises\n\n\n\n\n1부터 100까지의 수를 evens이라는 이름의 변수에 저장하고 이 중 짝수만을 뽑아내서 출력하시오 (which()함수 사용)\nsample 함수를 사용하여 앞서 odds와 evens 변수에서 랜덤하게 1개씩의 샘플을 뽑아서 mynumbers에 저장하시오\n어떤 짝수가 뽑혔는지 찾아서 출력하시오 (which와 인덱싱 사용)\n\n\n\n\n\n4.4.1.3 character\nCharacter(문자형) 벡터의 경우 문자열을 다루는데 자주 쓰이는 paste() 함수의 사용법을 알아두면 편리합니다. paste() 함수는 서로 다른 문자열을 붙이는데 주로 사용됩니다. 참고로 문자열을 나누는 함수는 strsplit() 입니다. paste()에서 붙이는 문자 사이에 들어가는 문자를 지정하는 파라메터는 sep 이고 strsplit()함수에서 자르는 기준이 되는 문자는split 파라미터로 지정해 줍니다 (?split 또는 ?paste 확인).\n\npaste(\"X\", \"Y\", \"Z\", sep=\"_\")\npaste(c(\"Four\",\"The\"), c(\"Score\",\"quick\"), c(\"and\",\"fox\"), sep=\"_\")\npaste(\"X\", 1:5, sep=\"\")\npaste(c(\"X\",\"Y\"), 1:10, sep=\"\")\n\nx &lt;- c(\"X1\", \"Y2\", \"X3\", \"Y4\", \"X5\")\npaste(x[1], x[2])\npaste(x[1], x[2], sep=\"\")\npaste(x, collapse=\"_\")\n\nstrsplit(\"XYZ\", split=\"\")\nsort(c(\"B\", \"C\", \"A\", \"D\"))\n\n\n\n\n\n\n\nExercises\n\n\n\n\nm이라는 변수에 “Capital of South Korea is Seoul” 문자열을 저장하고 “Capital of South Korea”를 따로 뽑아내 m2에 저장하시오 (substr() 사용)\nLETTERS 내장함수에서 랜덤하게 10개의 문자를 뽑아내 myletters 변수에 저장하고 이들을 연결하여 (paste 사용) 하나의 문장(String)을 만드시오\nmyletters 변수의 문자들을 알파벳 순서대로 정렬하고 (sort 사용) 이들을 연결하여 하나의 문장 (String)을 만드시오\n\n\n\n\n\n4.4.1.4 factor\nFactor형은 범주형데이터를 저장하기 위한 object 이며 R 언어에서 특별히 만들어져 사용되고 있습니다. factor() 함수를 이용해 생성하며 생성된 객체는 다음과 같이 level이라는 범주를 나타내는 특성값을 가지고 있습니다.\n예를 들어 어린이 5명이 각각 빨강, 파랑, 노랑, 빨강, 파랑 색종이를 들고 있을때 색의 종류를 나타내는 값들은 빨강, 파랑, 노랑 입니다. 다섯 명의 아이들이 어떤 색의 색종이를 들고 있는지와는 상관없이 세 가지 범주의 값을 가지는 것 입니다.\n\nx &lt;- c(\"Red\", \"Blue\", \"Yellow\", \"Red\", \"Blue\")\ny &lt;- factor(x)\ny\n\n새로운 범주의 데이터를 추가할 경우 다음과 같이 해당되는 level을 먼저 추가하고 값을 저장해야 합니다.\n\nlevels(y)\ny[1] &lt;- \"Gold\"\ny\n\nlevels(y) &lt;- c(levels(y), \"Gold\")\nlevels(y)\ny\ny[1] &lt;- \"Gold\"\ny\n\nfactor는 기본적으로 level에 표시된 순서가 위치 (정렬) 순서입니다. 이를 바꾸기 위해서는 다음과 같이 levels 함수를 이용해서 순서를 바꿀 수 있습니다.\n\nlibrary(MASS)\nstr(Cars93)\nx &lt;- Cars93$Origin\nplot(x)\nlevels(x) &lt;- c(\"non-USA\", \"USA\")\nlevels(x)\nplot(x)\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n아미노산 Phe, Leu, Ser 를 값으로 갖는 범주형 변수 (factor)를 생성하시오\n각 아미노산과 해당 아미노산을 코딩하는 nucleotide triplets (codon)을 어떤 형태의 변수로 저장할 수 있을지 고민해 보시오\n\n\n\n\n\n4.4.1.5 Missing values\n특정 값이 “Not available” 이거나 “Missing value” 일 경우 벡터의 해당 원소 자리에 데이터의 이상을 알리기 위해 NA를 사용합니다. 따라서 일반적인 연산에서 NA가 포함되어 있는 경우 데이터의 불완전성을 알리기 위해 연산의 결과는 NA가 됩니다. is.na() 함수는 해당 변수에 NA 값이 있는지를 검사해주는 함수이며 R에는 이 외에도 다음과 같은 특수 값들이 사용되고 있습니다.\n\nNA: Not available, The value is missing\nNULL: a reserved value\nNaN: Not a number (0/0)\nInf: (1/0)\n\n\nhip_cost &lt;- c(10500, 45000, 74100, NA, 83500)\nsum(hip_cost)\nsum(hip_cost, na.rm=TRUE)\n?sum\n\n\n\n4.4.1.6 Useful functions\n다음은 벡터형 변수와 같이 쓰이는 유용한 함수들입니다.\n\nz &lt;- sample(1:10, 100, T)\nhead(z)\nsort(z)\norder(z)\ntable(z)\np &lt;- z/sum(z)\nround(p, digits=1)\n\nis 함수를 사용하여 데이터 타입이 사용자가 의도한 타입과 맞는지 검사할 수 있습니다. 콘솔창에서 is.를 타이핑한 후 잠시 기다리면 다양한 is 합수를 볼 수 있습니다.\n\nis.na(1)\nis.numeric(1)\nis.logical(TRUE)\nis.data.frame(\"A\")\nis.character(\"A\")\n\nas 함수는 데이터 타입을 변환해주는 함수입니다.\n\ndigits &lt;- runif(10)*10\nclass(digits)\ndigits_int &lt;- as.integer(digits)\nclass(digits_int)\ndigits_char &lt;- as.character(digits_int)\nclass(digits_char)\ndigits_num &lt;- as.numeric(digits_char)\nclass(digits_num)\n\n\n\n\n4.4.2 matrix\n매트릭스는 2차원 행렬로 같은 형식의 데이터 값 (numberic, character, logical) 으로만 채워진 행렬을 말합니다. 메트릭스를 만드는 방법은 아래와 같으며 nrow 와 ncol 파라메터에 행과 열의 수를 넣고 각 셀에 들어갈 값은 가장 앞에 위치한 data 파라메터에 넣어 줍니다 (?matrix로 파라메터 이름 확인). 메트릭스 인덱싱은 메트릭스 안의 값을 저장하거나 참조할때 (빼올때) 사용하는 방법입니다. 메트릭스 변수이름 바로 뒤에 대괄호를 이용해서 제어를 하며 대괄호 안에 콤마로 구분된 앞쪽은 row, 뒷쪽은 column 인덱스를 나타냅니다.\n\nmymat &lt;- matrix(0, nrow=100, ncol=3) # 1\nmymat[,1] &lt;- 1:100 # 2\nmymat[,2] &lt;- seq(1,200,2) # 3\nmymat[,3] &lt;- seq(2,200,2) # 4\n\n매트릭스의 row나 column에 이름이 주어져 있을 경우 이름을 따옴표(“)로 묶은 후 참조가 가능합니다. row나 column의 이름은 rownames() 또는 colnames()로 생성하거나 변경할 수 있습니다. row나 column의 개수는 nrow() 또는 ncol() 함수를 사용합니다.\n\ncolnames(mymat)\ncolnames(mymat) &lt;- c(\"A\", \"B\", \"C\")\ncolnames(mymat)\ncolnames(mymat)[2] &lt;- \"D\"\ncolnames(mymat)\nrownames(mymat) &lt;- paste(\"No\", 1:nrow(mymat), sep=\"\")\nrownames(mymat)\n\n여러 row나 column을 참조할 경우 아래와 같이 combine 함수를 사용하여 묶어줘야 하며 스칼라값을 (임의의 숫자 하나) 더하거나 뺄 경우 vector / matrix 연산을 기본으로 수행합니다.\n\nmymat[c(2,3,4,5),2] # 5\nmymat-1 # 6\nmysub &lt;- mymat[,2] - mymat[,1] #7\nsum(mysub) #8\nsum(mysub^2) #8\n\n\n\n\n\n\n\nExercises\n\n\n\n\nscore 라는 변수에 1부터 100까지 중 랜덤하게 선택된 20개의 수로 10 x 2 matrix를 만드시오 (sample() 사용)\nscore의 row 이름을 문자형으로 Name1, Name2, …, Name10으로 지정하시오 (paste() 사용)\nscore의 column 이름을 문자형으로 math와 eng로 지정하시오\n이 matrix의 첫번째 컬럼과 두 번째 컬럼의 수를 각각 더한 후 total_score라는 변수에 저장하시오\ntotal_score의의 오름차순 순서를 나타내는 인덱스 (order()함수 사용)를 o라는 변수에 저장하시오\nscore를 o순서로 재배치하고 score_ordered 변수에 저장하시오\n\n\n\n\n\n4.4.3 data.frame\n데이터프레임은 형태는 매트릭스와 같으나 컬럼 하나가 하나의 vector형 변수로서 각 변수들이 다른 모드의 값을 저장할 수 있다는 차이가 있습니다. $ 기호를 이용하여 각 구성 변수를 참조할 수 있습니다. 컬럼 한 줄이 하나의 변수 이므로 새로운 변수도 컬럼 형태로 붙여 넣을 수 있습니다. 즉, 각 row는 샘플을 나타내고 각 column은 변수를 나타내며 각 변수들이 갖는 샘플의 개수 (row의 길이, vector 의 길이)는 같아야 합니다. R 기반의 데이터 분석에서는 가장 선호되는 데이터 타입이라고 볼 수 있습니다.\n\n## data.frame\nids &lt;- 1:10\nids\nidnames &lt;- paste(\"Name\", ids, sep=\"\")\nidnames\nstudents &lt;- data.frame(ids, idnames)\nstudents\nclass(students$ids)\nclass(students$idnames)\nstudents$idnames\nstr(students)\n\nstudents &lt;- data.frame(ids, idnames, stringsAsFactors = F)\nclass(students$idnames)\nstudents$idnames\nstudents[1,]\nstr(students)\n\n데이터프레임에서는 $를 사용하여 변수 이름으로 인덱싱이 가능합니다.\n\n## data frame indexing \nstudents$ids\nstudents[,1]\nstudents[,\"ids\"]\n\n\n\n\n\n\n\nExercises\n\n\n\n\nmath라는 변수에 1부터 100까지 중 랜덤하게 선택된 10개의 수를 넣으시오\neng라는 변수에 1부터 100까지 중 랜덤하게 선택된 10개의 수를 넣으시오\nstudents라는 변수에 문자형으로 Name1, Name2, …, Name10으로 지정하시오 (paste() 사용)\nmath와 eng라는 벡터에 저장된 값들의 이름을 students 변수에 저장된 이름으로 지정하시오\nmath와 eng 벡터를 갖는 score 라는 data.frame을 만드시오\nmath와 eng 변수를 지우시오 (rm()사용)\nscore data frame의 math와 eng를 각각 더한 후 total_score라는 변수에 저장 하시오\n\n\n\n\n\n4.4.4 list\n리스트는 변수들의 모임이라는 점에서 데이터프레임과 같으나 구성 변수들의 길이가 모두 같아야 하는 데이터프레임과는 달리 다른 길이의 변수를 모아둘 수 있는 점이 다릅니다. 즉, R언어에서 두 변수를 담을 수 있는 데이터 타입은 list와 data frame 두 종류가 있는데 list 변수 타입은 vector 형태의 여러개의 element를 가질 수 있으며 각 vector의 길이가 모두 달라도 됩니다. list의 인덱싱에서 [ ]는 리스트를 반환하고 [[ ]]는 vector element들을 반환합니다.\n\n\n## list\nparent_names &lt;- c(\"Fred\", \"Mary\")\nnumber_of_children &lt;- 2\nchild_ages &lt;- c(4, 7, 9)\ndata.frame(parent_names, number_of_children, child_ages)\nlst &lt;- list(parent_names, number_of_children, child_ages)\nlst[1]\nlst[[1]]\nclass(lst[1])\nclass(lst[[1]])\nlst[[1]][1]\nlst[[1]][c(1,2)]\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n위 아미노산 예제에서 Phe, Leu, Ser 각각의 코돈을 원소로 갖는 세 개의 vector 변수들을 만들고 이를 aalist 라는 이름의 하나의 리스트 변수로 만드시오\naalist 리스트를 data.frame 형식의 aadf 변수로 만드시오 (데이터 구조를 바꾸어 저장 가능)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html#functions",
    "href": "03-r-programming.html#functions",
    "title": "4  R-programming",
    "section": "4.5 Functions",
    "text": "4.5 Functions\n\n\n\n\n\n\n카이스트 강의\n\n\n\n(23.11.15) 함수의 구조와 사용법 익히기\n\n\n함수(Function)란 사용자가 원하는 기능을 수행하는 코드의 모음으로서 반복적으로 쉽게 사용할 수 있도록 만들어 놓은 코드 입니다.\n\n4.5.1 A script in R\n함수의 개념을 배우기 전에 스크립트를 활용한 명령어 수행을 알아보겠습니다. R 프로그래밍을 통해서 사용자가 원하는 기능을 수행하는 방법은 다음과 같이 스크립트를 만들어서 실행하는 것 입니다. 일반적으로 R을 이용한 스크립트 명령을 어떻게 실행하는지 알아보겠습니다. 다음 예제는 입력 값들의 평균을 계산해서 출력해 주는 스크립트 명령입니다. R base 패키지에서 기본으로 제공되는 mean()이라는 함수가 있지만 사용하지 않고 sum()과 length() 함수를 사용했습니다.\n\nnumbers &lt;- c(0.452, 1.474, 0.22, 0.545, 1.205, 3.55)\ncat(\"Input numbers are\", numbers, \"\\n\")\nnumbers_mean &lt;- sum(numbers)/length(numbers)\nout &lt;- paste(\"The average is \", numbers_mean, \".\\n\", sep=\"\")\ncat(out)\n\n상황에 따라 다르긴 하지만 보통 위 스크립트를 실행할 때 R 파일을 하나 만들고 source()라는 함수를 사용해서 파일 전체를 한번에 읽어들이고 실행을 시킵니다. 위 코드를 myscript.R 이라는 새로운 R 파일을 하나 만들고 저장 후 다음과 같이 실행할 수 있습니다. 참고로 위 파일은 현재 Working directory와 같은 위치에 저장해야 합니다.\n\nsource(\"myscript.R\")\n\n그러나 위와 같은 식으로 실행할 경우 다음 몇 가지 문제가 있습니다. 하나는 입력 값이 바뀔 때마나 파일을 열어 바뀐 값을 저장해 줄 필요가 있습니다. 결과 값에 대해서 다른 처리를 하고 싶을 경우 또한 파일을 직접 수정해 주어야 합니다. 또한 모든 변수들이 전역변수로 사용되어 코드가 복잡해질 경우 변수간 간섭이 생길 가능성이 높습니다.\n\n\n4.5.2 Build a function\n함수는 특정 데이터를 입력으로 받아 원하는 기능을 수행한 후 결과 데이터를 반환하는 구조를 가집니다. 함수는 일반적으로 다음과 같은 포멧으로 구현할 수 있습니다.\n\nmy_function_name &lt;- function(parameter1, parameter2, ... ){\n  ##any statements\n  return(object)\n}\n\n예를 들어 다음과 같은 my_sine 함수를 만들 수 있으며 parameter (매개변수)는 x이고 y는 반환값을 저장하는 지역변수 입니다.\n\nmy_sine &lt;- function(x){\n    y &lt;- sin(x)\n    return(y)\n}\n\n만들어진 함수는 다음과 같이 사용할 수 있습니다. 만들어진 함수는 처음에 한 번 실행해 주어 실행중인 R session에 등록한 후 사용할 수 있습니다. 여기서 함수로 전달되는 값 pi는 argument (전달인자) 라고 합니다. 전달인자는 함수에서 정의된 매개변수의 갯수와 같은 수의 전달인자를 입력해 주어야 합니다. 참고로 parameter와 argument는 많은 사람들이 혼동하는 단어입니다. 본 예에서 my_sine함수의 괄호 안에 있는 변수 x는 parameter이고 x에 들어가는 값인 pi 나 90은 argument 입니다.\n\nmy_sine(pi)\nmy_sine(90)\nsin(90)\n\n\nTerminology\n\nfunction name: my_sine\nparameter: x\nargument: pi\nreturn value: y\n\n\n이제 위 스크립트 (myscript.R) 에서 사용된 코드를 함수로 바꿔봅니다. numbers (전달인자)를 받는 매개변수를 x로 하고 함수 이름은 mymean 이고 평균값 (numbers_mean)을 반환하는 합수입니다.\n\nnumbers &lt;- c(0.452, 1.474, 0.22, 0.545, 1.205, 3.55)\n\nmymean &lt;- function(x){\n  cat(\"Input numbers are\", x, \"\\n\")\n  numbers_mean &lt;- sum(x)/length(x)\n  out &lt;- paste(\"The average is \", numbers_mean, \".\\n\", sep=\"\")\n  cat(out)\n  return(numbers_mean)\n}\n\nretval &lt;- mymean(numbers)\ncat(retval)\n\nmyscript.R이라는 파일을 열고 작성된 스크립트에 더해서 아래처럼 함수 코드를 만들 경우 source() 함수로 함수를 세션으로 읽어오고 바로 사용할 수 있습니다. 위와 같이 함수를 만들 경우 입력 값을 언제든 바꿔서 사용할 수 있고 반환값에 대한 추가적인 연산도 쉽게 수행 할 수 있습니다.\n\nnew_values &lt;- c(1:10)\nretval &lt;- mymean(new_values)\nretval\n\n\n\n\n\n\n\nExercises\n\n\n\n\n변수 x에 1, 3, 5, 7, 9를, 변수 y에 2, 4, 6, 8, 10을 저장하는 코드를 작성하시오\nx와 y를 더한 값을 z에 저장하는 코드를 작성하시오\nmysum 이라는 이름의 함수를 작성하되 두 변수를 입력으로 받아 더한 후 결과를 반환하는 코드를 작성하시오\nmymean 이라는 이름의 함수를 작성하되 두 변수를 입력으로 받아 평균을 구한 후 결과를 반환하는 코드를 작성하시오\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nmysd라는 이름의 (표본)표준편차를 구하는 함수를 myscript.R 파일에 구현하시오 (sd()함수 사용하지 않고, 다음 표준편차 공식 이용)\n\n\\[\n\\sigma = \\sqrt{\\frac{\\sum(x-mean(x))^2}{length(x)-1}}\n\\]\n코드는 아래와 같음\n```{r}\n\nmysd &lt;- function(x){\n  numbers_sd &lt;- sqrt(sum((x - mymean(x))^2)/(length(x)-1))  \n  return(numbers_sd)\n}\n```\n\n1부터 100까지의 값을 x에 저장하고 mysd 함수를 사용해서 표준편차를 구하시오\n\n\n앞서 작성한 mymean 함수와 mysd 함수를 같이 사용하여 x를 표준화 하고 z로 저장하시오. 표준화 공식은 다음과 같음\n\n\\[\nz = \\frac{x - mean(x)}{sd(x)}\n\\]\n\nx 와 z 변수를 원소로 갖는 y라는 이름의 data.frame을 생성하시오\n\n\n\n\n\n4.5.3 local and global variables\n함수를 사용함에 따라서 함수 안에서 사용되는 변수와 함수 밖에서 사용되는 변수들의 경우를 명확히 이해할 필요가 있습니다. 다음 코드를 보면 전역변수 x, y는 지역변수 x, y와 독립적으로 사용되고 있습니다.\n\nmy_half &lt;- function(x){\n  y &lt;- x/z\n  cat(\"local variable x:\", x, \"\\n\")\n  cat(\"local variable y:\", y, \"\\n\")\n  cat(\"global variable z:\", z, \"\\n\")\n  return(y)\n}\ny &lt;- 100\nx &lt;- 20\nz &lt;- 30\ncat(\"Global variable x:\", x, \"\\n\")\ncat(\"Global variable y:\", y, \"\\n\")\ncat(\"Global variable z:\", z, \"\\n\")\nmy_half(5)\n\nmy_half &lt;- function(x, z){\n  y &lt;- x/z\n  cat(\"local variable x:\", x, \"\\n\")\n  cat(\"local variable y:\", y, \"\\n\")\n  cat(\"local variable z:\", z, \"\\n\")\n  return(y)\n}\n\nmy_half(5, 10)\n\nlog, sin등의 함수들은 Built-in function으로 같은 이름의 함수를 만들지 않도록 주의합니다.\n\nx &lt;- pi\nsin(x)\nsqrt(x)\nlog(x)\nlog(x, 10)\nx &lt;- c(10, 20, 30)\nx + x\nmean(x)\nsum(x)/length(x)\n\n\n\n4.5.4 Vectorized functions\n초기에 R이 다른 프로그래밍 언어에 비해서 경쟁력을 갖는 이유 중 하나가 바로 이 벡터 연산 기능 이였습니다. vector 변수에 들어있는 각 원소들에 대해서 특정 함수나 연산을 적용하고 싶을 경우 전통 방식의 C나 Java등의 언어에서는 원소의 개수만큼 반복문을 돌면서 원하는 작업을 수행 했습니다. 그러나 R의 벡터 연산 기능은 별도의 반복문 없이 vector 안에 있는 원소들에 대한 함수 실행 또는 연산을 수행할 수 있습니다.\n\nx &lt;- c(10, 20, 30)\nx + x\nsqrt(x)\nsin(x)\nlog(x)\nx-mean(x)\n\nlength(x)\ntest_scores &lt;- c(Alice = 87, Bob = 72, James= 99)\nnames(test_scores)\n\n\n\n\n\n\n\nExercises\n\n\n\n다음은 한 다이어트 프로그램의 수행 전 후의 다섯 명의 몸무게이다.\n\n\n\nBefore\n78\n72\n78\n79\n105\n\n\nafter\n67\n65\n79\n70\n93\n\n\n\n\n각각을 before 와 after 이름의 변수에 저장 후 몸무게 값의 변화량을 계산하여 diff 라는 변수에 저장하시오\ndiff에 저장된 값들의 합, 평균, 표준편차를 구하시오\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n다음 네 학생이 있으며 “John”,“James”,“Sara”, “Lilly” 각 나이는 21, 55, 23, 53 이다. ages 라는 변수를 생성하고 각 나이를 저장한 후 who라는 이름의 함수를 만들어서 50살 이상인 사람의 이름을 출력하는 함수를 만드시오.\n\n\nages라는 변수에 나이 저장, c() 함수 이용, vector 형태 저장\nnames() 함수 이용해서 각 ages 벡터의 각 요소에 이름 붙이기\nwhich() 함수 사용해서 나이가 50보다 큰 인덱스 찾고 해당 인덱스 값들을 idx에 저장\nages에서 idx에 해당하는 인덱스를 갖는 값을 sel_ages에 저장\nnames()함수를 이용해서 sel_ages의 이름을 sel_names에 저장\n위 설명을 참고해서 input이라는 파라메터를 갖고 sel_names라는 50살 이상인 사람의 이름을 반환하는 who50이라는 이름의 함수 만들기\nwho50 함수의 사용법은 who50(ages) 임",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html#flow-control",
    "href": "03-r-programming.html#flow-control",
    "title": "4  R-programming",
    "section": "4.6 Flow control",
    "text": "4.6 Flow control\n\n\n\n\n\n\n카이스트 강의\n\n\n\n(23.11.15) ifelse, if_else, case_when 등 최신 조건문 등의 사용법도 같이 알아두기\n\n\n\n4.6.1 if statements\nR에서의 제어문의 사용은 다른 프로그래밍 언어와 거의 유사합니다. 먼저 if 는 다음과 같은 형식으로 사용되며 () 안에 특정 조건 판단을 위한 표현이 들어갑니다.\n\nif(condition){\n  expr_1\n}else{\n  expr_2\n}\n\n특히 condition은 하나의 원소에 대한 조건 판단문으로 T 또는 F 값 하나만을 반환하는 문장이어야 합니다. 위 코드는 만약 condition 조건이 True 이면 expr_1를 실행하고 False이면 expr_2를 실행하라는 명령입니다. condition 안에서 사용되는 비교 연산자들은 다음과 같습니다.\n\n\nx &lt;- 2\nif(x%%2 == 1){\n  cat(\"Odd\")\n}else{\n  cat(\"Even\")\n} \n\nx &lt;- 5\nif(x &gt; 0 & x &lt; 4){\n  print(\"Positive number less than four\")\n}\n\nif(x &gt; 0) print(\"Positive number\")\n\nx &lt;- -5\nif(x &gt; 0){\n  print(\"Non-negative number\")\n} else if(x &lt;= 0 & x &gt; -5){\n  print(\"Negative number greater than -5\")\n} else {\n  print(\"Negative number less than -5\")\n}\n\nif(x &gt; 0)\n  print(\"Non-negative number\")\nelse\n  print(\"Negative number\")\n\n\n\n4.6.2 ifelse statements\nif는 하나의 조건만 비교하는데 사용할 수 있습니다. 그러나 변수에는 여러 값이 벡터형식으로 들어가고 벡터연산을 수행할 경우의 결과도 벡터형식으로 나오지만 if문은 이들을 한 번에 처리하기 어렵습니다. ifelse는 이러한 단점을 보완하여 여러 값을 한번에 처리할 수 있습니다.\n\nifelse (condition, True일 때 리턴값, False일 때 리턴값)\n\nifelse의 경우 빠르게 원하는 값을 반환할 수 있으나 조건별로 다른 추가적인 명령의 수행은 불가능하다는 단점이 있습니다.\n\nx &lt;- c(1:10)\nif(x&gt;10){\n  cat(\"Big\")\n}else{\n  cat(\"Small\")\n}\n\nifelse(x&gt;10, \"Big\", \"Small\")\n\n\n\n\n\n\n\nExercises\n\n\n\n\n다음은 median (중간값)을 구하는 공식이며 x의 길이가 (n이) 홀수일 경우와 짝수일 경우에 따라서 다른 공식이 사용된다. 다음 공식과 코드를 이용하여 mymedian 이라는 이름의 함수를 만들고 입력 값들의 중간값을 구해서 반환하는 함수를 만드시오. (%% 나머지 연산, if문 사용, 아래 중간값 코드 참고)\n\n\\[\nmedian(X) =\n\\begin{cases}\n\\frac{1}{2} X[\\frac{n}{2}] + \\frac{1}{2} X[1+\\frac{n}{2}] & \\mbox{if } n \\mbox{ is even} \\\\\nX[\\frac{n+1}{2}] & \\mbox{if } n \\mbox{ is odd}\n\\end{cases}\n\\]\n\nsorted_x &lt;- sort(x)\n# 만약 짝수이면 \nretval &lt;- sort_x[n/2]/2 + sort_x[1+(n/2)]/2\n# 만약 홀수이면 \nretval &lt;- sort_x[(n+1)/2]\n\n\n\n\n\n4.6.3 for, while, repeat\n\n\n\n\n\n\n카이스트 강의\n\n\n\n(23.11.15) R에서 반복문은 가능하면 사용하지 않음\n\n\nfor 문은 반복적으로 특정 코드를 실행하고자 할 때 사용됩니다. 다음과 같은 형식으로 사용할 수 있습니다.\n\nfor(var in seq){\n  expression\n}\n\nvar는 반복을 돌 때마다 바뀌는 변수로 {} 안에서 사용되는 지역 변수 입니다. seq는 vector 형식의 변수로 반복을 돌 때마다 순차적으로 var에 저장되는 값들 입니다.\n\nx &lt;- 1:10\nfor(i in x){\n  cat(i, \"\\n\")\n  flush.console()\n}\n\nsum_of_i &lt;- 0\nfor(i in 1:10){\n  sum_of_i &lt;- sum_of_i + i\n  cat(i, \" \", sum_of_i, \"\\n\");flush.console()\n}\n\nwhile문도 for문과 같이 반복적으로 특정 코드를 수행하고자 할 때 사용합니다. 사용하는 문법은 다음과 같으며 cond는 True 또는 False 로 반환되는 조건문을 넣고 True 일 경우 계속해서 반복하면서 expressions를 수행하며 이 반복은 cond가 False로 될 때 까지 계속됩니다.\n\nwhile(cond){\n  expression\n}\n\nwhile문을 사용할 경우 다음과 같이 indicator라 불리우는 변수를 하나 정해서 반복 할 때마다 값이 바뀌도록 해 주어야 합니다. 그렇지 않으면 무한 루프를 돌게 되는 문제가 발생합니다.\n\ni &lt;- 10\nf &lt;- 1\nwhile(i&gt;1){\n  f &lt;- i*f\n  i &lt;- i-1\n  cat(i, f, \"\\n\")\n}\nf\nfactorial(10)\n\nrepeat 명령은 조건 없이 블럭 안에 있는 코드를 무조건 반복하라는 명령 입니다. 따라서 블럭 중간에 멈추기 위한 코드가 필요하고 이 명령이 break 입니다.\n\nrepeat{\n  expressions\n  if(cond) break\n}\n\ni &lt;- 10\nf &lt;- 1\nrepeat {\n  f &lt;- i*f\n  i &lt;- i-1\n  cat(i, f, \"\\n\")\n  if(i&lt;1) break\n}\nf\nfactorial(10)\n\n\n\n4.6.4 Avoiding Loops\nR에서는 가능하면 loop문을 사용하지 않는 것이 좋습니다. 이는 다른 언어들 보다 반복문이 느리게 수행된다는 이유 때문이기도 합니다. 그러나 R에서는 반복문을 수행하는 것 보다 훨씬 더 빠르게 반복문을 수행 한 것과 같은 결과를 얻을 수 있는 다양한 방법들이 제공되고 있습니다. 차차 그런 기법들에 대한 학습을 진행하도록 하겠습니다.\n\nx &lt;- 1:1E7\nsum(x)\nsystem.time(sum(x))\n\nst &lt;- proc.time()\ntotal &lt;- 0\nfor(i in 1:length(x)){\n  total &lt;- total + x[i]\n}\ned &lt;- proc.time()\ned-st\n\n\n\n\n\n\n\nExercises\n\n\n\n\n다음 네 사람의 이름과 나이를 데이터로 갖는 users 변수를 (data.frame) 만드시오\n\n\nuser_score &lt;- c(90, 95, 88, 70)\nuser_names &lt;- c(\"John\",\"James\",\"Sara\", \"Lilly\")\n\n\n각 사람의 점수가 80보다 작으면 이름 점수: Fail 크면 이름 점수: Pass를 출력을 하는 코드를 작성하시오. 예를 들어 John의 점수는 80보다 크므로 John 90: Pass 출력 (for, print 함수 이용)\n\n\n\n\n\n4.6.5 dplyr::if_else\n\n\n4.6.6 dplyr::case_when",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "03-r-programming.html#object-oriented-programming-advanced",
    "href": "03-r-programming.html#object-oriented-programming-advanced",
    "title": "4  R-programming",
    "section": "4.7 Object Oriented Programming (Advanced)",
    "text": "4.7 Object Oriented Programming (Advanced)\nOOP는 객체지향 프로그래밍 이라고 합니다. OOP를 이용해서 프로그래밍으로 풀고자 하는 문제를 좀 더 명확하게 개념을 수립하고 복잡한 코드를 명료하게 만들 수 있습니다. 그런데 R에서 OOP는 다른 언어보다는 좀 더 어려운 개념적인 이해가 필요합니다. S3, S4, 그리고 Reference class 가 있으며 S3, S4는 Generic function을 이용하며 다른 언어에서 사용하는 OOP 개념과는 다릅니다. Reference class는 다른 언어에서 사용하는 OOP 개념과 유사하며 R6 패키지를 이용해서 사용할 수 있습니다.\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R-programming</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html",
    "href": "04-data-transformation-classic.html",
    "title": "5  Data transform classic",
    "section": "",
    "text": "5.1 Introduction\n일반적인 데이터 분석은 데이터 전처리(변환), 가시화, 모델링(통계분석)의 반복적인 수행으로 진행될 수 있습니다. R에서는 data.frame 형식의 데이터 타입이 주로 사용되며 (최근 tibble형식) 따라서 data.frame 기반의 데이터를 다루기 위한 다양한 함수를 익힐 필요가 있습니다. 이번 강의에서는 data.frame 데이터를 읽거나 쓰는 함수들과 함께 데이터 전처리를 (변환) 위한 함수들을 배워보겠습니다.\n앞에서 배웠던 데이터를 저장하는 object의 종류를 먼저 간략히 정리해 봅니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#introduction",
    "href": "04-data-transformation-classic.html#introduction",
    "title": "5  Data transform classic",
    "section": "",
    "text": "Vectors - 같은 타입의 데이터를 (Numeric, character, factor, …) 저장한 오브젝트로 인덱스는 [, ] 사용.\nLists - 여러개의 vector를 원소로 가질 수 있으며 각 원소 vector들은 문자나 숫자 어떤 데이터 타입도 가능하고 길이가 달라도 됨. list의 인덱싱에서 [ ]는 리스트를 반환하고 [[ ]]는 vector를 반환함.\nMatrices - 같은 타입의 데이터로 채워진 2차원 행렬이며 인덱스는 [i, j] 형태로 i는 row, j는 column 을 나타냄. 메트릭스의 생성은 matrix 명령어를 사용하며 왼쪽부터 column 값을 모두 채우고 다음 컬럼 값을 채워 나가는 것이 기본 설정임. byrow=T 를 통해 row를 먼저 채울수도 있음. row와 column 이름은 rownames와 colnames로 설정이 가능하며 rbind와 cbind로 두 행렬 또는 행렬과 백터를 연결할 수 있음 ( rbind와 cbind의 경우 행렬이 커지면 컴퓨터 리소스 많이 사용함)\ndata.frame - list와 matrix의 특성을 모두 갖는 오브젝트 타입으로 list와 같이 다른 타입의 vector형 변수 여러개가 컬럼에 붙어서 matrix 형태로 구성됨. 단, list와는 다르게 각 변수의 길이가 (row의 길이) 같아야 함. $ 기호로 각 변수들을 인덱싱(접근) 할 수 있고 matrix와 같이 [i,j] 형태의 인덱싱도 가능.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#reading-and-writing",
    "href": "04-data-transformation-classic.html#reading-and-writing",
    "title": "5  Data transform classic",
    "section": "5.2 Reading and writing",
    "text": "5.2 Reading and writing\n\n\n\n\n\n\n카이스트 강의\n\n\n\n텍스트 파일과 엑셀파일 읽기 쓰기\n\n\n파일에 있는 데이터를 R로 읽어들이거나 쓰는 일은 일반적인 데이터 분석 과정에서 필수적일 수 있습니다. 본 강의에서는 일반적으로 사용하는 텍스트 파일과 엑셀파일을 활용하는 방법을 알아보겠습니다.\n\n5.2.1 Text file\n편의상 데이터를 쓰는 과정을 먼저 살펴봅니다. ggplot2 예제에 있는 데이터 중 msleep 데이터는 이 데이터셋은 다양한 동물들의 수면 패턴에 대한 정보를 담고 있습니다. str 또는 dplyr::glimpse 함수로 데이터 전체적인 구조를 파악한 일부 데이터만을 이용해 추가적인 데이터를 생성한 후 별도로 파일에 저장해 보겠습니다.\n\nlibrary(tidyverse)\ndata(msleep)\nstr(msleep)\nglimpse(msleep)\n\nmydf &lt;- data.frame(brainwt = msleep$brainwt, \n           sleep_total = msleep$sleep_total)\nclass(mydf)\n\nmydf &lt;- msleep[,c(\"brainwt\", \"sleep_total\")]\nclass(mydf)\n\nmydf &lt;- msleep |&gt; dplyr::select(brainwt, sleep_total)\nclass(mydf)\n\n마지막 tidyverse 스타일의 mydf 데이터 생성이 가장 추천하는 방법입니다. 파일에 쓰는 방법은 다음과 같습니다. 패키지에 따라서 다양한 파일 쓰기 함수들이 제공되고 있지만 위 두 파일은 utils라는 R의 기본 패키지에 들어있는 함수들로서 가장 많이 사용되는 함수들 입니다. ?write.table 등으로 도움말을 보시고 특히 함수의 전달값 (Arguments) 들을 (quote, row.names, col.names, sep) 익혀두시기 바랍니다.\n\nwrite.table(mydf, file=\"table_write1.txt\")\nwrite.table(mydf, file=\"table_write2.txt\", quote=F)\nwrite.table(mydf, file=\"table_write3.txt\", quote=F, row.names=F)\nwrite.table(mydf, file=\"table_write4.txt\", quote=F, row.names=F, sep=\"\\t\")\nwrite.table(mydf, file=\"table_write5.csv\", quote=F, row.names=F, sep=\",\")\n\n대부분의 텍스트 파일은 아래와 같이 csv 또는 txt 파일로 저장하여 메모장으로 열어 확인할 수 있으며 읽어올 때 구분자 (sep 파라메터) 나 header를 (header 파라메터) 읽을지 등을 옵션으로 지정할 수 있습니다.\n\ndat &lt;- read.csv(\"table_write5.csv\")\nhead(dat)\nstr(dat)\nglimpse(dat)\n\ntable_write5.csv 파일을 열어보면 다음과 같이 header와 “,”로 구분되어 있는 것을 볼 수 있습니다. read.csv 함수의 도움말을 보면 이 함수의 파라메터 head와 sep이 기본값으로 T와 ,로 되어 있는 것을 볼 수 있습니다. read.csv 외에도 read.table, read.delim 등의 함수를 이용해서 택스트 파일을 읽어올 수 있습니다.\n추가로 수면 시간과 뇌 무게의 관계를 보기위해 다음과 같이 데이터를 가시화 할 수 있습니다.\n\nplot(y=mydf$brainwt, x=mydf$sleep_total)\nplot(y=log(mydf$brainwt), x=mydf$sleep_total)\n\nNA를 제거하기 위해서 na.omit 함수를 사용합니다.\n\nmydf2 &lt;- na.omit(mydf)\nmycor &lt;- cor(log(mydf2$brainwt), mydf2$sleep_total)\nfit &lt;- lm(log(mydf2$brainwt) ~ mydf2$sleep_total)\nsummary(fit)\nplot(y=log(mydf2$brainwt), x=mydf2$sleep_total); abline(fit); text(50, 170, round(mycor,2))\n\n\n\n5.2.2 Excel file\n\n\n\n\n\n\n카이스트 강의\n\n\n\n서열 데이터도 많이 다루나 공학생물학 관점에서는 플레이트 기반 데이터 수집과 분석 또한 많이 활용될 수 있음\n\n\n텍스트 파일 외에 엑셀파일은 readxl 이라는 R 패키지를 활용하여 읽거나 쓸 수 있습니다. 패키지는 다음과 같은 방법으로 설치할 수 있으며 read_excel 이라는 함수를 사용해서 데이터를 읽어들일 수 있습니다. readxl은 tidyverse 패키지들 중 하나입니다.\n\n# install.packages(\"readxl\")\nlibrary(readxl)\n\n실습 파일은 형광 세포를 배양하여 형광리더기를 이용해 얻어진 실제 데이터이며 plate_reader.xls 에서 다운로드 받을 수 있습니다. read_excel 함수를 이용하여 파일의 내용을 읽어오면 기본 자료형이 tibble 입니다. tibble은 최근 많이 쓰이는 R object로 data.frame과 유사하나 입력값의 type, name, rowname을 임으로 바꿀 수 없다는 점이 다릅니다.\n\ndat &lt;- read_excel(\"examples/plate_reader.xls\", sheet=1, skip = 0, col_names=T)\n\n엑셀파일에는 두 종류의 (\\(OD600_{nm}\\), Fluorescence) 데이터가 저장되어 있습니다. 첫 번째 sheet에는 다음처럼 데이터가 저장되어 있습니다.\n\n프로토콜 상세 내역이 나온 세 번째 시트를 읽을 경우 sheet 옵션을 3로 설정하면 되며 skip=3으로 하고 컬럼 이름을 별도로 사용하지 않으므로 col_names=T로하여 읽을 수 있습니다.\n\ndat &lt;- read_excel(\"examples/plate_reader.xls\", sheet=3, skip = 3, col_names=F)\n\n참고로 엑셀파일로 저장하기 위해서는 tidyverse의 writexl 패키지를 사용하거나 csv 파일로 데이터를 writing 한 뒤 Excel로 해당 csv 파일을 열고 xlsx 파일로 저장할 수 있습니다.\n\nlibrary(writexl)\ndat &lt;- read_excel(\"examples/plate_reader.xls\", sheet=1)\nwrite_xlsx(dat, path = \"examples/plate_reader.xlsx\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#classical-way-of-the-data-transformation",
    "href": "04-data-transformation-classic.html#classical-way-of-the-data-transformation",
    "title": "5  Data transform classic",
    "section": "5.3 Classical way of the data transformation",
    "text": "5.3 Classical way of the data transformation\n아래 설명하는 subset, filter, merge, split, select 등의 함수는 임의의 데이터를 효과적으로 변환하는데 사용되는 기본 함수들입니다. 그러나 위 함수들을 개별적으로 사용하는 것 보다 tidyverse 방식의 데이터 변환 함수들이 더 많이 사용되고 있습니다. 아래 설명은 필요할 경우 참고하시면 되겠습니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#subset",
    "href": "04-data-transformation-classic.html#subset",
    "title": "5  Data transform classic",
    "section": "5.4 Subset",
    "text": "5.4 Subset\nR에서 데이터 저장은 data.frame이나 matrix 타입을 일반적으로 사용합니다. 이 데이터의 일부 열 또는 행의 데이터만을 가져와서 별도로 저장하거나 분석이 필요할 경우가 있습니다. 이 때 인덱싱을 사용해서 일부 데이터를 선택하고 사용할 수 있으며 subset 함수도 이러한 선별 기능을 제공합니다. subset은 행과 열 모두를 선별할 수 있는 함수입니다. 다음 airquality 데이터는 1973년 날짜별로 뉴욕의 공기질을 측정한 데이터 입니다. NA를 제외한 나머지 데이터만으로 새로운 데이터셋을 만들어 봅시다. is.na함수를 사용하면 해당 데이터가 NA일 경우 TRUE, NA가 아닐 경우 FALSE 를 반환해 줍니다.\n\nglimpse(airquality)\n\nis.na(airquality$Ozone)\nozone_complete1 &lt;- airquality[!is.na(airquality$Ozone),]\nglimpse(ozone_complete1)\nozone_complete2 &lt;- filter(airquality, !is.na(Ozone))\nglimpse(ozone_complete2)\n\n위 ozone_complete1와 ozone_complete2는 같은 결과를 보입니다. 그러나 ozone_complete1 보다는 ozone_complete2 코드가 더 직관적이고 가독성이 높습니다. 특히 airquality$ozone 로 $를 사용하여 변수에 접근한 것이 아닌 Ozone이라는 변수 이름을 직접 사용해서 접근함으로써 코드의 간결성과 가독성을 유지할 수 있습니다. 또한 subset의 select 옵션을 이용해서 변수를 선택할 수도 있으며 &(AND)와 |(OR) 연산자를 사용해서 조건을 두 개 이상 설정할 수 있습니다. 아래 select 옵션에서 -는 해당 변수를 제외한다는 의미 입니다.\n\nozone_complete3 &lt;- subset(airquality, !is.na(ozone), select=c(ozone, temp, month, day))\nozone_complete4 &lt;- subset(airquality, !is.na(ozone) & !is.na(solar.r), select=c(-month, -day))\n\n그러나 위 코드에서 순차적으로 수행되는 변환 과정 역시 여러 프로세스가 반복될 수록 복잡해지고 가독성이 떨어지는 것을 알 수 있습니다.\n\n\n\n\n\n\nExercises\n\n\n\n\nairquality 데이터에서 Temp와 Ozone 변수로 이루어진 df라는 이름의 data.frame을 만드시오 (단 NA가 있는 샘플(열)은 모두 제외하시오)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#merging-and-split",
    "href": "04-data-transformation-classic.html#merging-and-split",
    "title": "5  Data transform classic",
    "section": "5.5 Merging and Split",
    "text": "5.5 Merging and Split\nmerge 함수는 두 개 이상의 데이터셋을 통합하는 기능을 수행하는 함수입니다. 특히 rbind나 cbind와는 다르게, 결합하는 두 데이터에 공통적이거나 한 쪽의 데이터를 기준으로 결합을 수행 합니다. ?merge를 참고하면 by, by.x, by.y, all, all.x, all.y 등의 옵션으로 이러한 설정을 수행할 수 있습니다. 간단한 예제를 통해서 이해해 보겠습니다.\n10명의 사람이 있고 이 사람들의 나이와 성별을 각각 나타낸 두 데이터셋이 있습니다. 그런데 df1은 나이만을 df2는 성별 정보만을 가지고 있으며 두 정보 모두 제공된 사람은 3명 (인덱스 4,5,6) 뿐입니다. 이제 merge를 이용해서 두 데이터셋을 결합해 보겠습니다.\n\n## merge\ndf1 &lt;- data.frame(id=c(1,2,3,4,5,6), age=c(30, 41, 33, 56, 20, 17))\ndf2 &lt;- data.frame(id=c(4,5,6,7,8,9), gender=c(\"f\", \"f\", \"m\", \"m\", \"f\", \"m\"))\n\ndf_inner &lt;- merge(df1, df2, by=\"id\", all=F)\ndf_outer &lt;- merge(df1, df2, by=\"id\", all=T)\ndf_left_outer &lt;- merge(df1, df2, by=\"id\", all.x=T)\ndf_right_outer &lt;- merge(df1, df2, by=\"id\", all.y=T)\n\n만약 두 데이터셋의 id가 다를 경우나 각각 다른 기준으로 결합해야 하는 경우는 by대신 by.x, by.y 옵션을 사용할 수 있습니다.\nsplit 함수는 데이터를 특정 기준으로 나누는 역할을 하며 해당 기준은 factor 형 벡터 형태로 주어질 수 있습니다. 예를 들어 airquality 데이터의 month 변수를 기준으로 데이터를 분리해 보겠습니다.\n\nstr(airquality)\ng &lt;- factor(airquality$Month)\nairq_split &lt;- split(airquality, g)\nclass(airq_split)\nstr(airq_split)\n\n위와 같이 airq_split은 길이가 5인 (5, 6, 7, 8, 9월) list타입이 되었고 각 요소는 서로 다른 size의 data.frame형으로 구성 된 것을 확인할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#transformation",
    "href": "04-data-transformation-classic.html#transformation",
    "title": "5  Data transform classic",
    "section": "5.6 Transformation",
    "text": "5.6 Transformation\nR에서 기존 가지고 있는 데이터의 변경은 새로운 변수의 추가, 삭제, 변형과 샘플의 추가, 삭제, 변형을 생각해 볼 수 있습니다. 이러한 기능은 앞에서 배운 merge, split이나 rbind, cbind, 그리고 인덱싱을 활용한 값 변경 등의 방법을 이용할 수 있습니다. 또한 가장 직관적으로 필요한 변수들을 기존 데이터셋에서 추출한 후 data.frame 명령어를 사용해서 새로운 데이터셋으로 만들어주면 될 것 입니다.\n이러한 방법들 외에 within을 사용할 경우 특정 변수의 변형과 이를 반영한 새로운 데이터셋을 어렵지 않게 만들수 있습니다. with 함수의 사용 예와 함께 within 함수를 사용하여 데이터를 변형하는 예를 살펴봅니다. with나 within 함수는 R을 활용하는데 많이 사용되는 함수들은 아닙니다. 또한 이러한 기능들은 dplyr 등의 패키지에서 제공하는 경우가 많아서 필수적으로 익힐 부분은 아닙니다. 그러나 개념적인 이해를 돕기위한 좋은 도구들이며 여전히 고수준의 R 사용자들이 코드에 사용하고 있는 함수들이므로 알아두는 것이 좋습니다.\n\n## without with\nozone_complete &lt;- airquality[!is.na(airquality$Ozone),\"Ozone\"]\ntemp_complete &lt;- airquality[!is.na(airquality$Temp),\"Temp\"]\nprint(mean(ozone_complete))\nprint(mean(temp_complete))\n\n## with\nwith(airquality, {\n  print(mean(Ozone[!is.na(Ozone)]))\n  print(mean(Temp[!is.na(Temp)]))\n})\n\n위 with 함수에서 보는바와 같이 $를 이용한 변수 접근 대신 with함수 내에서는 ({, } 안에서) 해당 data.frame에 있는 변수 이름을 직접 접근할 수 있으며 따라서 코드의 간결함과 가독성이 향상됩니다.\nwithin 함수는 with함수와 같이 {, } 안에서 변수의 이름만으로 해당 변수에 접근이 가능하나 입력된 데이터와 변경된 변수(들)을 반환한다는 점이 다릅니다. 아래 예는 airquality 데이터의 화씨 (Fahrenheit) 온도를 섭씨 (Celsius) 온도로 변환해서 새로운 데이터셋을 만드는 코드입니다. data.frame을 이용한 코드와 비교해 보시기 바랍니다. 데이터셋 내에서 참조할 변수들이 많아질 경우 airquality$xxx 식의 코드를 줄이는 것 만으로도 코드의 가독성과 간결성을 유지할 수 있습니다.\n\nnewairquality &lt;- within(airquality, {\n  celsius = round((5*(Temp-32))/9, 2)\n})\nhead(newairquality)\n\n## data.frame\ncelsius &lt;- round((5*(airquality$Temp-32))/9, 2)\nnewairquality &lt;- data.frame(airquality, celsius)\nhead(newairquality)\n\n\n\n\n\n\n\nExercises\n\n\n\n\n다음 df 의 hour, minute, second로 나누어진 값들을 초 단위로 변환하여 seconds라는 변수에 저장한 후 기존 df에 추가한 df2 데이터셋을 만드시오 (within 함수 이용)\n\n\ndf &lt;- data.frame(hour=c(4, 7, 1, 5, 8),\n                 minute=c(46, 56, 44, 37, 39),\n                 second=c(19, 45, 57, 41, 27))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#babies-example",
    "href": "04-data-transformation-classic.html#babies-example",
    "title": "5  Data transform classic",
    "section": "5.7 Babies example",
    "text": "5.7 Babies example\nUsingR 패키지의 babies 데이터를 이용해서 산모의 흡연 여부와 신생아 몸무게의 관계를 알아보는 분석을 수행해 보겠습니다. 본 강의를 통해 배우지 않은 내용들이 있지만 코드를 따라 가면서 참고하시기 바랍니다. 우선 UsingR 패키지를 로딩합니다. 산모의 임신 기간이 (gestation) 999로 표기된 데이터는 명백히 에러이며 이들을 NA로 처리합니다.\n\nlibrary(UsingR)\nhead(babies)\n## a simple way to checkout the data\nplot(babies$gestation)  \nbabies$gestation[babies$gestation&gt;900] &lt;- NA\nstr(babies)\n\n아래와 같이 within 함수를 사용해서 babies$ 를 반복해서 입력해주는 불편함을 줄이고 가독성을 높입니다. 똑같은 방법으로 dwt (아빠의 몸무게) 변수의 에러값들에 대해서도 NA 처리를 할 수 있습니다.\n\nnew_babies &lt;- within(babies, {\n  gestation[gestation==999] &lt;- NA\n  dwt[dwt==999] &lt;- NA\n})\nstr(new_babies)\n\nsmoke 변수는 흡연 여부를 나타내는 범주형 변수로 0, 1, 2, 3 값은 의미가 없습니다. 사람이 읽을 수 있는 label을 붙인 factor 형 변수로 변환하는 코드도 함께 작성해 보겠습니다.\n\nstr(babies$smoke)\nnew_babies &lt;- within(babies, {\n  gestation[gestation==999] &lt;- NA\n  dwt[dwt==999] &lt;- NA\n  smoke = factor(smoke)\n  levels(smoke) = list(\n    \"never\" = 0, \n    \"smoke now\" = 1, \n    \"until current pregnancy\" = 2,\n    \"once did, not now\" = 3)\n  })\nstr(new_babies$smoke)\n\n이제 임신기간과 흡연 여부를 분석해 볼 수 있습니다. 흡연 그룹별로 기간에 차이가 있는지를 알아보는 분석은 t-test나 ANOVA를 사용할 수 있습니다.\n\nfit &lt;- lm(gestation~smoke, new_babies)\nsummary(fit) ## t-test 결과 \nanova(fit)\n\n간단히 결과를 보면 summary(fit)은 3가지 t-test의 결과를 보여줍니다. never vs. smoke new 의 경우 t값이 -1.657로 피우지 않은 경우에 비해서 피우는 사람의 임신 기간이 유의하게 줄어들었음을 알 수 있습니다. 그에 비해서 현재 흡연하지 않는 경우 (never vs. until current pregnancy 또는 never vs. once did, not now) 차이가 없는 것으로 나옵니다.\n이제 smoke now 인 경우 또는 나이가 25세 미만인 경우의 샘플에 대해서 newdf를 만들어 봅니다 (subset 함수 사용, id, gestation, age, wt, smoke 변수 선택). 이 후 ggplot을 이용하여 몸무게와 임신기간의 산점도를 그려보면 크게 다르진 않으나 흡연하는 여성 중 몸무게가 적게 나가는 여성에게서 짧은 임신기간을 갖는 경향을 볼 수 있습니다.\n\nnewdf &lt;- subset(new_babies, (smoke==\"smoke now\" | smoke == \"never\") & age &lt; 25, select=c(id, gestation, age, wt, smoke))\n# ggplot(newdf, aes(x=wt, y=gestation, color=smoke)) +\n#   geom_point(size=3, alpha=0.5) +\n#   facet_grid(.~smoke) + \n#   theme_bw()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#useful-functions",
    "href": "04-data-transformation-classic.html#useful-functions",
    "title": "5  Data transform classic",
    "section": "5.8 Useful functions",
    "text": "5.8 Useful functions\n지금까지 배운 여러 R 프로그래밍 기법이나 함수들과 같이 R을 활용한 데이터 분석에서 자주쓰이거나 유용하게 사용되는 함수들을 소개합니다. 먼저 원소들을 비교하여 공통적 또는 유일한 원소들만을 추출해내는 함수들 입니다.\n\n#match(), %in%, intersect()\n\nx &lt;- 1:10\ny &lt;- 5:15\nmatch(x, y)\nx %in% y\nintersect(x, y)\n\n#unique()\nunique(c(x, y))\n\n다음은 스트링 관련 함수들로서 서열데이터 분석 등에서 유용하게 활용되는 함수들 입니다.\n\n#substr()\nx &lt;- \"Factors, raw vectors, and lists, are converted\"\nsubstr(x, 1, 6)\n\n#grep()\ngrep(\"raw\", x)\n\n#grepl()\ngrepl(\"raw\", x)\nif(grepl(\"raw\", x)){\n  cat(\"I found raw!\")\n}\n\nx &lt;- paste(LETTERS, 1:100, sep=\"\")\ngrep(\"A\", x)\nx[grep(\"A\", x)]\n\ngrepl(\"A\", x)\nr &lt;- grepl(\"A\", x)\nif(r){\n  cat(\"Yes, I found A\")\n}else{\n  cat(\"No A\")\n}\n\n#strsplit()\nx &lt;- c(\"Factors, raw vectors, and lists, are converted\", \"vectors, or for, strings with\")\ny &lt;- strsplit(x, split=\", \")\n\n#unlist()\nunlist(y)\n\ny &lt;- strsplit(x, split=\"\")\nychar &lt;- unlist(y)\nycount &lt;- table(y2)\nycount_sort &lt;- sort(ycount)\nycount_sort &lt;- sort(ycount, decreasing = T)\nycount_top &lt;- ycount_sort[1:5]\nycount_top_char &lt;- names(ycount_top)\n\n#toupper(), tolower()\ntoupper(ycount_top_char)\n\n\n\n\n\n\n\nExercises\n\n\n\nbuilt-in 데이터셋 중 state.abb 은 미국의 50개 주에대한 축약어임.\n\n이 중 문자 A 가 들어가는 주를 뽑아 x에 저장 하시오 (grep 또는 grepl 사용)\nstate.abb 중 위 x에 저장된 이름들을 빼고 y에 저장 하시오 (match() 또는 %in%사용)\nstate.abb에 사용된 알파벳의 갯수를 구하고 가장 많이 쓰인 알파벳을 구하시오 (strsplit(), table() 등 사용)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#apply",
    "href": "04-data-transformation-classic.html#apply",
    "title": "5  Data transform classic",
    "section": "5.9 apply",
    "text": "5.9 apply\napply는 데이터를 변형하기 위한 함수라기 보다는 데이터를 다룰 때 각 원소별, 그룹별, row, 또는 column 별로 반복적으로 수행되는 작업을 효율적으로 수행할 수 있도록 해주는 함수입니다. apply 계열의 함수를 적절히 사용하면 효율성이나 편리성 뿐만 아니라 코드의 간결성 등 많은 장점이 있습니다. 쉬운 이해를 위해 colMean 함수를 예로 들면 colMean은 column 또는 row 단위로 해당하는 모든 값들에 대해 평균을 계산해주는 함수이고 apply를 사용할 경우 다음과 같이 apply 함수와 mean 함수를 이용해서 같은 기능을 수행할 수 있습니다. 아래는 babies 데이터의 clearning 된 (위에서 만들었던) new_babies 데이터에 이어서 수행되는 내용입니다.\n\nlibrary(UsingR)\nhead(babies)\ndf &lt;- subset(babies, select=c(gestation, wt, dwt))\ncolMeans(df, na.rm=T)\napply(df, 2, mean, na.rm=T)\n\n위와 같이 colMeans와 apply가 똑같은 결과를 보여주고 있습니다. 두 번째 인자인 margin의 값으로 (?apply참고) 여기서는 2가 사용되었으며 margin 값이 1인지 2인지에 따라서 다음과 같이 작동을 합니다.\n\nmean외에도 다양한 함수들이 사용될 수 있으며 아래와 같이 임의의 함수를 만들어서 사용할 수 도 있습니다. 아래 코드에서는 function(x)...로 바로 함수의 정의를 넣어서 사용했으나 그 아래 mysd 함수와 같이 미리 함수 하나를 만들고 난 후 함수 이름을 이용해서 apply를 적용할 수 있습니다.\n\napply(df, 2, sd, na.rm=T)\napply(df, 2, function(x){ \n  xmean &lt;- mean(x, na.rm=T) \n  return(xmean)\n  })\n\napply 함수는 특히 R에서 느리게 작동하는 loop (for, while 등) 문 대신 사용되어 큰 행렬에 대해서도 빠른 계산 속도를 보여줄 수 있습니다.\n\nn &lt;- 40\nm &lt;- matrix(sample(1:100, n, replace=T), ncol=4)\nmysd &lt;- function(x){\n  xmean &lt;- sum(x)/length(x)\n  tmpdif &lt;- x-xmean\n  xvar &lt;- sum(tmpdif^2)/(length(x)-1)\n  xsd &lt;- sqrt(xvar)\n  return(xsd)\n}\n\n## for \nresults &lt;- rep(0, nrow(m))\nfor(i in 1:nrow(m)){\n  results[i] &lt;- mysd(m[i,])\n}\nprint(results)\napply(m, 1, mysd)\napply(m, 1, sd)\n\napply 함수 외에도 sapply, lapply, mapply 등의 다양한 apply계열 함수가 쓰일 수 있습니다. 먼저 lapply는 matrix 형태 데이터가 아닌 list 데이터에 사용되어 각 list 원소별로 주어진 기능을 반복해서 수행하며 sapply는 lapply와 유사하나 벡터, 리스트, 데이터프레임 등에 함수를 적용할 수 있고 그 결과를 벡터 또는 행렬로 반환합니다.\n\nx &lt;- list(a=1:10, b=exp(-3:3), logic=c(T,T,F,T))\nmean(x$a)\nlapply(x, mean)\nsapply(x, mean)\n\nx &lt;- data.frame(a=1:10, b=exp(-4:5))\nsapply(x, mean)\n\nx &lt;- c(4, 9, 16)\nsapply(x, sqrt)\nsqrt(x)\n\ny &lt;- c(1:10)\nsapply(y, function(x){2*x})\ny*2\n\n마지막 예제에서처럼 sapply나 lapply도 임의의 함수를 만들어 적용시킬 수도 있습니다. 자세히 살펴 보면 y는 10개의 값을 갖는 벡터이고 이 벡터의 각 원소 (값에) 함수를 반복해서 적용하는 것 입니다. 함수에서 x는 각 원소의 값을 차례차례 받는 역할을 하므로 1부터 10까지 값이 함수로 들어가 2를 곱한 수가 반환됩니다. 따라서 벡터연산을 하는 y*2와 결과가 같으나 원하는 함수를 정의해서 자유롭게 사용할 수 있다는 장점이 있습니다. 리스트의 경우는 다음과 같이 사용합니다.\n\ny &lt;- list(a=1:10, b=exp(-3:3), logic=c(T,T,F,T))\nmyfunc &lt;- function(x){\n  return(mean(x, na.rm=T))\n}\nlapply(y, myfunc)\nunlist(lapply(y, myfunc))\n\n즉, myfunc의 x가 list y의 각 원소들, y[[1]], y[[2]], y[[3]]를 각각 받아서 mean 연산을 수행해 줍니다. 결과로 각 list 원소들의 평균 값이 반환되며 unlist 함수는 list 형태의 반환 값을 vector 형태로 전환해 줍니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "04-data-transformation-classic.html#purrr",
    "href": "04-data-transformation-classic.html#purrr",
    "title": "5  Data transform classic",
    "section": "5.10 purrr",
    "text": "5.10 purrr\nTODO\n\n\n\n\n\n\nExercises\n\n\n\n다음은 앞에서 수행했던 airquality 데이터를 월별로 나눈 데이터셋임. 이 데이터셋을 이용하여 각 월별로 온도와 오존 농도의 평균값을 저장한 data.frame 형식의 데이터를 만들기 위하여 다음 단계별 과정에 적절한 코드를 작성하시오\n\n## dataset\ng &lt;- factor(airquality$month)\nairq_split &lt;- split(airquality, g)\n\n\n다음 df의 ozone 평균을 구하는 ozone_func 함수를 작성하시오 (단 입력은 data.frame 형식의 오브젝트를 받고 출력은 평균값 (정수 값 하나) 출력. mean 함수 사용시 데이터에 NA가 포함되어 있을 경우 na.rm=T 옵션 적용)\n\n\n## May data.frame\ndf &lt;- airq_split[[1]]\n#\n# write your code here for ozone_func function\n#\n\n## Usage\nozone_func(df)\n## output\n# 23.61538\n\n\nlapply와 ozone_func 함수를 사용하여 airq_split list 데이터의 월별 ozone 평균 값을 구하고 ozone_means에 vector 형식으로 저장하시오\n위 1), 2)와 같은 방법으로 temp_func 함수를 만들고 월별 temp의 평균값을 temp_means에 vector 형식으로 저장하시오.\n위에서 구해진 두 변수값들을 이용하여 air_means 라는 이름의 data.frame으로 저장하시오\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n다음 코드를 이용해서 파일을 다운로드 하고 myexp에 저장하고 데이터의 구조 및 샘플들의 이름을 확인하시오\nmyexp &lt;- read.csv(“https://github.com/greendaygh/kribbr2022/raw/main/examples/gse93819_expression_values.csv”, header=T)\n\n\n\nmyexp의 1부터 10번째 샘플(컬럼) 데이터를 myexp1으로 11부터 20번째 샘플 데이터를 myexp2로 나누시오\nmyexp1의 row별 평균을 구해서 myexp1mean에 myexp2의 row별 평균을 구해서 myexp2mean에 저장하시오 (apply 이용)\nmyexp1mean과 myexp2mean을 합하여 myexpmean이라는 data.frame을 만드시오 (cbind이용, 주의필요)\nplot을 이용하여 두 평균들의 산포도를 그리시오\nmyexpmean의 두 변수에 대한 차이를 구하여 mydiff 라는 변수에 저장하시오\nmydiff의 값들에 대한 히스토그램 (막대그래프)을 그리시오\n\n\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transform classic</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html",
    "href": "05-data-transformation-tidyverse.html",
    "title": "6  Data transform tidyverse",
    "section": "",
    "text": "6.1 Introduction\ntidyverse (https://www.tidyverse.org/)는 데이터 사이언스를 위한 R 기반의 독창적인 패키지들의 모음입니다. Rstudio의 핵심 전문가인 해들리위컴이 (Hadley Wickham) 중심이 되어 만들어 졌으며 기존의 툴보다 쉽고 효율적으로 데이터 분석을 수행할 수 있습니다.\n데이터사이언스는 넓은 범위의 개념과 방법적인 정도가 있는 것은 아닙니다. 그러나 tidyverse의 목적은 데이터 분석을 위한 핵심이되는 고효율의 툴을 제공하는 것이며 그 철학은 다음과 같은 그림으로 요약할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#introduction",
    "href": "05-data-transformation-tidyverse.html#introduction",
    "title": "6  Data transform tidyverse",
    "section": "",
    "text": "from https://r4ds.had.co.nz/",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#tibble-object-type",
    "href": "05-data-transformation-tidyverse.html#tibble-object-type",
    "title": "6  Data transform tidyverse",
    "section": "6.2 Tibble object type",
    "text": "6.2 Tibble object type\n\n\n\n\n\n\n카이스트 강의\n\n\n\ntibble 데이터 타입입 이해하기\n\n\nR은 20년 이상된 비교적 오랜 역사를 가진 언어로서 data.frame 형태의 데이터 타입이 가장 많이 사용되고 있습니다. 그러나 당시에는 유용했던 기능이 시간이 흐르면서 몇몇 단점들이 드러나는 문제로 기존 코드를 그대로 유지한채 package 형태로 단점을 보완한 새로운 형태의 tibble 오브젝트 형식을 만들어 냈습니다. 대부분의 R 코드는 여전히 data.frame 형태의 데이터 타입을 사용하고 있으나 tidyverse에서는 tibble이 기본으로 사용되는 것을 참고하시기 바랍니다.\n\nlibrary(tidyverse)\n\ntb &lt;- tibble(\n  x = 1:5, \n  y = 1, \n  z = x ^ 2 + y\n)\ntb\n\niris\nas_tibble(iris)\n\ntibble은 data.frame과 다음 몇 가지 점이 다릅니다. data.frame의 경우 타입을 변환할 때 강제로 값의 타입을 바꾸거나 내부 변수의 이름을 바꾸는 경우가 있었으나 tibble은 이를 허용하지 않습니다. 샘플들 (row) 이름을 바꿀수도 없습니다. 또한 프린팅할 때 출력물에 나오는 정보가 다르며 마지막으로 data.frame은 subset에 대한 타입이 바뀔 경우가 있었지만 tibble은 바뀌지 않습니다.\n\nx &lt;- 1:3\ny &lt;- list(1:5, 1:10, 1:20)\n\ndata.frame(x, y)\ntibble(x, y)\n\ntibble은 컬럼 하나가 벡터형 변수가 아닌 리스트형 변수가 될 수 있다는 것도 data.frame과 다른 점 입니다.\n\nnames(data.frame(`crazy name` = 1))\nnames(tibble(`crazy name` = 1))\n\n또한 다음과 같이 사용되는 변수의 (x) 참조 범위가 다릅니다.\n\ndata.frame(x = 1:5, y = x ^ 2)\ntibble(x = 1:5, y = x ^ 2)\n\n\ndf1 &lt;- data.frame(x = 1:3, y = 3:1)\nclass(df1)\nclass(df1[, 1:2])\nclass(df1[, 1])\n\ndf2 &lt;- tibble(x = 1:3, y = 3:1)\nclass(df2)\nclass(df2[, 1:2])\nclass(df2[, 1])\nclass(df2$x)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#tidy-data-structure",
    "href": "05-data-transformation-tidyverse.html#tidy-data-structure",
    "title": "6  Data transform tidyverse",
    "section": "6.3 Tidy data structure",
    "text": "6.3 Tidy data structure\n\n\n\n\n\n\n카이스트 강의\n\n\n\ntidy 데이터 이해하기. Long형과 wide형 데이터 구분은 분석 목적에 따라서 달라질 수 있으나 가능하면 tidy 형태의 데이터로 분석하는 것이 중요함.\n\n\n데이터의 변수와 값을 구분하는 일은 적절한 데이터 분석을 위해 필수적인 과정입니다. 특히 복잡하고 사이즈가 큰 데이터일 경우는 더욱 중요할 수 있으나 경험에 의존해서 구분을 하는 것이 대부분 입니다. Tidy data는 이러한 변수와 값의 명확한 구분과 활용을 위한 데이터 구조중 하나 입니다 (Hadley Wickham. Tidy data. The Journal of Statistical Software, vol. 59, 2014).\n\ntidy data는 다음과 같은 특징이 있습니다.\n\n각 변수는 해당하는 유일한 하나의 column을 가짐\n각 샘플은 해당하는 유일한 하나의 row를 가짐\n각 관측값은 해당하는 유일한 하나의 cell을 가짐\n\n\n\n\nfrom https://r4ds.had.co.nz/\n\n\n이러한 데이터 구조를 유지하는 것이 필요한 이유는 우선적으로 데이터 분석의 효율성에 있습니다. 또한 데이터를 일관성 있게 저장하고 관리하게 되면 그것을 다루는 분석 도구들을 배우고 활용하기 쉬워집니다. 특히 dplyr, ggplot2 및 tidyverse의 패키지들은 tidy 데이터 형태로 작동합니다. 그리고 변수들이 열에 배치되면서 백터연산을 지원하는 대부분의 R 함수들의 성능이 최대화 됩니다.\n\nlibrary(tidyverse)\nlibrary(readxl)\ndat &lt;- read_excel(\"examples/plate_reader.xls\", sheet=1, skip = 0, col_names=T)\n\nhead(dat)\nglimpse(dat)\n\n위 데이터는 전형적인 long형 데이터 입니다. 각 변수는 하나의 컬럼에만 나타나고 각 샘플은 유일한 하나의 row를 가집니다. 만약 플레이터 한 장을 더 측정하면 아래쪽으로 동일한 컬럼에 추가 데이터가 붙게 됩니다. 그러나 임의의 데이터가 long 형인지 wide 형인지 판단하는 기준은 목적에 따라서 다를 수 있습니다. 이럴 경우 특정 목저을 가지고 2차원 평면에 plot을 그릴 때 어떤 데이터를 가지고 그림을 그릴지를 고려한다면 쉽게 판단이 가능합니다.\nTidy 데이터는 Long형 데이터로 알려져 있기도 합니다. 참고로 Wide형 데이터의 경우 샘플 데이터가 늘어날수록 row에 쌓이고 새로운 변수는 column에 쌓이는 방식으로 데이터가 확장되는 형태 입니다. 엑셀에서 볼 수 있는 일반적인 형식으로 다음 그림과 같습니다.\n\nLong형 데이터의 경우 ID, variable, value 세가지 변수만 기억하면 되겠습니다. 위 wide형 데이터 경우를 보면 ID, variable, 그리고 value 이 세가지 요인이 주요 구성 요소임을 알 수 있습니다. Long형으로 변환할 경우 샘플을 참조할 수 있는 어떤 변수 (variable)도 ID가 될 수 있으며 2개 이상의 변수가 ID로 지정될 수 있습니다. 참고로 ID를 지정할 경우 해당 ID는 가능하면 중복되지 않는 값들을 갖는 변수를 사용해야 식별자로서 기능을 적절히 수행할 수 있습니다. Long형을 사용할 경우 데이터의 변수가 늘어나도 행의 수만 늘어나므로 코딩의 일관성과 변수들의 그룹을 만들어서 분석하는 등의 장점이 있습니다. 아래는 새로운 변수 F가 추가될 때 long 형 데이터에 데이터가 추가되는 경우를 나타낸 그림 입니다.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#pipe-operator",
    "href": "05-data-transformation-tidyverse.html#pipe-operator",
    "title": "6  Data transform tidyverse",
    "section": "6.4 Pipe operator",
    "text": "6.4 Pipe operator\n\n\n\n\n\n\n카이스트 강의\n\n\n\n파이프 오퍼레이터 사용법은 필수로 이해하며 기존 magrittr 오퍼레이터보다 네이티브 오퍼레이터 |&gt; 추천\n\n\ntidyverse 패키지를 활용하기 위해서는 파이프 오퍼레이터의 이해가 필요합니다. 기존 magrittr에서 제공하던 %&gt;% 파이프 오퍼레이터와 함께 최근 R 4.1.0부터 도입된 네이티브 파이프 오퍼레이터(|&gt;)를 사용할 수 있습니다. 작동법은 간단히 파이프 오퍼레이터의 왼쪽 코드의 결과를 출력으로 받아 오른쪽 코드의 입력 (첫번째 파라미터의 값)으로 받아들이는 작동을 합니다 (단축키: Shift+Ctrl+m). Tools &gt; Global options &gt; Code 에서 아래와 같이 Use native pipe operator 에 체크해주면 위 단축키를 누를 때 native pipe operator가 표시됩니다.\n\n다음 예에서 보면 sin(pi) 와 같은 함수의 일반적인 사용법 대신 pi |&gt; sin() 처럼 사용해도 똑같은 결과를 보여줍니다. cos(sin(pi))와 같이 여러 합수를 중첩하여 사용할 경우와 비교해서 코드의 가독성이나 효율 측면에서 크게 향상된 방법을 제공해 줍니다.\n\nlibrary(dplyr)\n\npi |&gt; sin()\nsin(pi)\npi |&gt; sin() |&gt; cos()\ncos(sin(pi))\n\n파이프 오퍼레이터는 특히 다음 설명할 dplyr의 group_by, split, filter, summary 등 행렬 편집/연산 함수를 빈번히 다양한 조합으로 쓰게되는 상황에서 더 큰 효과를 발휘할 수 있습니다. 일반적으로 파이프라인의 첫 단계 이후, 각 줄을 두 칸 들여쓰기합니다. 각 인자가 별도의 줄에 있으면 추가로 두 칸 더 들여쓰기를 합니다.\n|&gt;는 플레이스홀더로 _를 사용하고 magrittr의 %&gt;% 플레이스홀더로 .을 사용합니다. magrittr의 %&gt;%는 R 데이터 분석에서 오랜 시간 동안 널리 사용되어 온 파이프 오퍼레이터로, 고급 기능과 유연성을 제공하지만 최근에는 네이티브 파이프 오퍼레이터 (|&gt;)의 사용이 권장되고 있으며 두 오퍼레이터 모두 R에서 데이터 처리와 분석을 보다 효율적이고 직관적으로 만들어주는 중요한 도구입니다.\n다음 코드는 x가 paste의 첫 번째 파라미터로 들어가게 되어 \"1a\", \"2a\", \"3a\", \"4a\", \"5a\"로 a 앞에 x 값들이 붙어서 출력된 것을 알 수 있습니다.\n\nx &lt;- 1:5\nx |&gt; paste(\"a\", sep=\"\")\n\n특정 데이터셋의 컬럼별 평균을 구하고 각 평균의 합을 구할 경우를 생각해 봅시다. R에서는 colMeans라는 특별한 함수를 제공하여 컬럼별로 평균을 계산해 줍니다. 그 후 sum 함수를 사용하여 최종 원하는 값을 얻을 수 있습니다. 이러한 코드를 |&gt; 오퍼레이터를 사용한 경우의 코드와 비교해 볼 수 있습니다.\n\nx &lt;- data.frame(x=c(1:100), y=c(201:300))\nsum(colMeans(x))\n\nx &lt;- data.frame(x=c(1:100), y=c(201:300))\nx |&gt; \n  colMeans() |&gt; \n  sum()\n\n만약 두 번째 파라미터에 입력으로 왼쪽 구문의 출력을 받아들이고 싶을 경우는 플레이스 홀더_을 사용하면 되겠습니다. round 함수는 두 개의 파라미터를 설정할 있 이으며 digits 라는 두 번째 파라미터에 값을 pipe operator로 넘겨주고 싶을 경우 아래와 같이 표현할 수 있습니다.\n\n6 |&gt; round(pi, digits=_)\nround(pi, digits=6)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#pivoting",
    "href": "05-data-transformation-tidyverse.html#pivoting",
    "title": "6  Data transform tidyverse",
    "section": "6.5 Pivoting",
    "text": "6.5 Pivoting\n\n\n\n\n\n\n카이스트 강의\n\n\n\nLong형과 wide형 데이터를 서로 변환할 수 있는 방법 익히기\n\n\n일반적으로 얻어지는 데이터의 형태는 wide형이며 이를 Long형으로 변환하기 위해서는 tidyverse 패키지에 속한 tidyr 패키지의 pivot_longer와 pivot_wider를 사용합니다. 기존에는 reshape2 패키지의 melt함수와 그 반대의 경우 dcast 함수를 사용할 수 있으나 tidyr 패키지가 널리 사용됩니다. wide형 데이터를 long형으로 변환하거나 long형을 wide형으로 변환하는 작업을 pivoting 이라고 합니다.\n\nairquality 데이터는 wide형 데이터로도 볼 수 있고 long형 데이터로 볼 수도 있습니다. 앞에서 언급한 바와 같이 목적에 따라서 airquality 데이터가 wide형이 될 수 있고 long형도 될 수 있습니다. airquality 데이터는 특정 날짜에 airquality 지표 몇 가지에 대한 측정 값을 모아둔 데이터 입니다. 만약 Ozone과 Solar.R 만이 분석에 필요한 변수들이라면 두 개의 변수를 갖는 long형 데이터로 볼 수 도 있습니다.\n\n\n\n\n\n\n카이스트 강의\n\n\n\n아래 내용은 tidy 구조의 데이터를 사용할 경우 변수 이름으로 용이하게 분석할 수 있는 예시를 보여줌\n\nairquality\nmyair2 &lt;- airquality |&gt; \n  dplyr::select(Ozone, Solar.R, Month, Day)\n\nmyair2 |&gt; \n  pivot_longer()\n\nmyair2\nggplot(myair2, aes(x=Solar.R, y=Ozone)) +\n  geom_point()\n\nfit &lt;- lm(myair2$Ozone~myair2$Solar.R)\nsummary(fit)\n\n\n\n그러나 만약 각 컬럼을 airquality를 나타낼 수 있는 범주형 데이터 값으로 본다면 airquality 데이터는 wide형 데이터가 됩니다. 이 데이터를 long형으로 바꿀 경우 ID를 날짜로 하면 데이터들을 식별 할 수 있습니다. 그런데 날짜는 변수가 Month와 Day두 개로 나누어져 있으므로 다음과 같이 두 변수를 식별 변수로 (ID로) 사용 합니다. 확인을 위해 상위 5개의 데이터만 가지고 형 변환을 진행해 보겠습니다.\n\nairquality\n\nmyair &lt;- airquality[1:5,]\nmyair\n\nmyair_long &lt;- pivot_longer(myair, c(\"Ozone\", \"Solar.R\", \"Wind\", \"Temp\"))\nmyair_long \n\nmyair_long &lt;- myair |&gt; \n  pivot_longer(c(\"Ozone\", \"Solar.R\", \"Wind\", \"Temp\"))\nmyair_long \n\nmyair_long2 &lt;- myair |&gt; \n  pivot_longer(c(Ozone, Solar.R, Wind, Temp))\nmyair_long2 \n\nmyair_long3 &lt;- myair |&gt; \n  pivot_longer(!c(Month, Day))\nmyair_long3\n\nmyair_long &lt;- pivot_longer(airquality, c(\"Ozone\", \"Solar.R\", \"Wind\", \"Temp\"))\nmyair_long |&gt; \n  mutate(id = paste(Month, Day, sep=\"-\")) |&gt; \n  ggplot(aes(x=id, y=value, color=name)) +\n  geom_point()\n\n생성되는 long형 데이터의 변수 이름인 name과 value는 다음 파라메터를 지정하여 바꿀 수 있습니다.\n\nmyair_long &lt;- myair |&gt; \n  pivot_longer(c(Ozone, Solar.R, Wind, Temp), \n               names_to = \"Type\", \n               values_to = \"Observation\")\nmyair_long \n\nlong형 데이터를 wide형 데이터로 변환 할 수도 있습니다.\n\nmyair_long |&gt; \n  pivot_wider(\n    names_from = Type, \n    values_from = Observation)\n\nggplot을 이용한 그래프 작성에는 위와 같은 long형 데이터가 주로 사용됩니다. R을 이용한 데이터 가시화는 dplyr 패키지로 wide형 데이터를 편집하고 pivot_longer 함수로 long형 데이터로 변환 후 ggplot을 이용하는 방식으로 수행합니다. 두 데이터 포멧에 대한 좀 더 구체적인 내용은 다음 링크를 참고하시기 바랍니다. https://www.theanalysisfactor.com/wide-and-long-data/\n\n\n\n\n\n\n카이스트 강의\n\n\n\n대부분 R 함수들이 벡터연산을 지원하고 있으며 컬럼을 변수로 하는 long형 데이터(컬럼이 변수)로 정형화해서 사용할 경우 R의 성능을 극대화 할 수 있음\n\n\n\nlibrary(ggplot2)\ndata(msleep)\nhead(msleep)\n\nggplot(msleep, aes(x = brainwt, y = sleep_total)) +\n  geom_point() +\n  scale_x_log10() +\n  xlab(\"Brain Weight (log scale)\") +\n  ylab(\"Total Sleep Time (hours)\") +\n  ggtitle(\"Relationship between Brain Weight and Total Sleep Time\")\n\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nplate read 예제, 샘플: B, C, D, E, F, G 6종, 처리농도: 1~6, 반복: 7~12\nsample name 변수 추가\n농도 변수 추가\n반복 나타내는 dummy 변수 추가\nplot\n\n\n\nlibrary(tidyverse)\nlibrary(readxl)\ndat &lt;- read_excel(\"examples/plate_reader.xls\", sheet=1, skip = 0, col_names=T)\ndat\n\nnewdat &lt;- dat |&gt; \n  mutate(sample = stringr::str_sub(Well, 1, 1)) |&gt; \n  mutate(cpos = as.numeric(stringr::str_sub(Well, 2, -1))) |&gt; \n  mutate(conc = case_when(cpos &lt; 7 ~ cpos,\n                          TRUE ~ cpos-6)\n  ) |&gt; \n  mutate(dupl = case_when(cpos &lt; 7 ~ 1,\n                          TRUE ~ 2)) |&gt; \n  rename(od = \"595nm_kk (A)\",\n         gfp = \"EGFP_sulim (Counts)\") |&gt; \n  dplyr::select(sample, conc, dupl, od, gfp)\n\n\nnewdat |&gt; \n  pivot_longer(c(\"od\", \"gfp\")) |&gt; \n  mutate(id = paste(sample, conc, dupl, sep=\"-\")) |&gt; \n  ggplot(aes(x=id, y=value, color=name)) +\n  geom_point() \n\n\n농도에 따른 OD, GFP 변화 plot 그리기\n처리농도: 0, 0.1, 0.5, 1, 5, 10\n문자형 값은 factor형으로 변환 필요\n\n\nconc_val &lt;- c(0, 0.1, 0.5, 1, 5, 10)\nconc_val[1]\n\nnewdat |&gt; \n  mutate(conc_new = conc_val[conc])\n\nnewdat2 &lt;- newdat |&gt; \n  mutate(conc = conc_val[conc]) |&gt; \n  mutate(dupl = as.character(dupl)) |&gt; \n  mutate_if(is.character, as.factor) \n\nnewdat2 |&gt; \n  ggplot(aes(x=conc, y=od)) +\n  geom_point()\n\nnewdat2 |&gt; \n  ggplot(aes(x=conc, y=od, color=sample)) +\n  geom_point() \n\n\ngrowth data가 아님\nbargraph, x축 샘플/농도, y축 od\n\n\nnewdat2 |&gt; \n  ggplot(aes(x=sample, y=od)) +\n  geom_bar()\n\nnewdat2 |&gt; \n  ggplot(aes(x=sample, y=od)) +\n  geom_bar(stat = \"identity\")\n\nnewdat2 |&gt; \n  ggplot(aes(x=sample, y=od, color=conc)) +\n  geom_bar(stat = \"identity\")\n\nnewdat2 |&gt; \n  ggplot(aes(x=sample, y=od, fill=conc)) +\n  geom_bar(stat = \"identity\")\n\nnewdat2 |&gt; \n  ggplot(aes(x=sample, y=od, fill=conc)) +\n  geom_bar(stat = \"identity\")\n\n\nnewdat2 |&gt; \n  mutate(conc = as.factor(conc)) |&gt; \n  ggplot(aes(x=sample, y=od, fill=conc)) +\n  geom_bar(stat = \"identity\")\n\nnewdat2 |&gt; \n  mutate(conc = as.factor(conc)) |&gt; \n  ggplot(aes(x=sample, y=od, fill=conc)) +\n  geom_bar(stat = \"identity\", position = \"dodge\")\n\n\n다른색으로\n\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\nnewdat2 |&gt; \n  mutate(conc = as.factor(conc)) |&gt; \n  ggplot(aes(x=sample, y=od, fill=conc)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"YlGnBu\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#separating-and-uniting",
    "href": "05-data-transformation-tidyverse.html#separating-and-uniting",
    "title": "6  Data transform tidyverse",
    "section": "6.6 Separating and uniting",
    "text": "6.6 Separating and uniting\n데이터를 분석할 때 하나의 컬럼에 두 개 이상의 변수값이 저장되어 있거나 두 개의 변수를 하나의 컬럼으로 합해야 하는 경우가 종종 있습니다. 전자의 경우 separate() 함수를 사용해서 두 변수(컬럼)으로 나누어 줄 수 있으며 후자의 경우 unite() 함수를 사용하여 두 변수를 하나의 값으로 병합할 수 있습니다. 다음은 airquality데이터에서 Month와 Day 변수를 하나의 컬럼으로 병합하여 Date라는 변수로 만들어 주는 경우의 예 입니다.\n\nnewairquality &lt;- airquality |&gt; \n  unite(Date, Month, Day, sep=\".\")\nnewairquality\n\nseparate()함수를 사용하면 다음과 같이 해당 변수의 값을 나누어 다시 두 개의 변수(컬럼)으로 나누어 줄 수 있습니다.\n\nnewairquality |&gt; \n  separate(col=Date, into = c(\"Month\", \"Day\"), sep = \"\\\\.\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#dplyr",
    "href": "05-data-transformation-tidyverse.html#dplyr",
    "title": "6  Data transform tidyverse",
    "section": "6.7 dplyr",
    "text": "6.7 dplyr\n\n\n\n\n\n\n카이스트 강의\n\n\n\n데이터를 다루기 위한 tidyverse의 가장 핵심이 되는 패키지. 여기서 사용되는 기술은 Genome 데이터 등 여러 타입의 데이터에 대해서 응용해서 활용되고 있음.\n\n\ndplyr (https://dplyr.tidyverse.org/) 은 ggplot2을 개발한 해들리위컴이 (Hadley Wickham) 중심이 되어 만들어 졌으며 ggplot2와 함께 tidyverse의 (https://www.tidyverse.org/) 핵심 패키지 입니다. dplyr은 데이터를 다루는 크기나 분석의 속도, 편의성을 향상시켜 새롭게 만들어놓은 패키지 입니다. 기존 apply와 같은 행렬 연산 기능과 subset, split, group 와 같은 행렬 편집 기능을 더하여 만들어진 도구라고 할 수 있습니다.\ndplyr의 전신이라 할 수 있는 plyr 패키지는 다음과 같이 설명이 되어 있습니다. A set of tools for a common set of problems: you need to split up a big data structure into homogeneous pieces, apply a function to each piece and then combine all the results back together. 즉 split-apply-combine 세 가지 동작을 쉽게 할 수 있도록 만들어 놓은 툴 입니다. R이 다른 언어에 비해 데이터 분석에서 주목을 받는 이유로 split, apply 등의 행렬 연산 함수가 발달한 것을 내세우는데 dplyr은 이들을 보다 더 편리하게 사용할 수 있도록 만들어 놓은 것 입니다.\n이제 dplyr 패키지에서 제공하는 함수를 사용해 보겠습니다. dplyr을 구성하는 중요한 함수는 다음과 같습니다.\n\nselect() - 변수 (columns) 선택\nfilter() - 샘플 (rows) 선택\narrange() - 샘플들의 정렬 순서 변경\nmutate() - 새로운 변수 만들기\nsummarise() - 대표값 만들기\ngroup_by() - 그룹별로 계산 수행\njoin() - 두 tibble 또는 data.frame을 병합할 때 사용\n위 함수들과 (특히 filter, select, mutate, summarise) 조합하여 (함수 내에서) 사용할 수 있는 helper 함수들이 같이 사용될 수 있습니다 (독립적으로도 사용 가능).\n\nacross\nif_any\nif_all\neverything\nstarts_with\nend_with\ncontains\n\n\n이 함수들은 %&gt;%와 함께 쓰이면서 강력한 성능을 발휘합니다. summarise 함수는 특정 값들의 통계 값을 계산해 주는 함수이며 그 외 함수들은 행렬 편집을 위한 함수들로 보시면 되겠습니다. 간단한 예제를 수행하면서 각각의 기능을 살펴보고 왜 dplyr이 널리 사용되고 그 장점이 무엇인지 파악해 보도록 하겠습니다.\n\n6.7.1 select\nselect() 는 주어진 데이터셋으로부터 관심있는 변수를 (column) 선택하여 보여줍니다.\n\nhead(iris)\niris |&gt; \n  select(Species, everything()) |&gt; \n  head(5)\niris |&gt; select(Species, everything())\niris |&gt; select(-Species)\n\n다음 helper 함수들은 select 함수와 같이 유용하게 쓰일 수 있습니다.\n\nstarts_with(“abc”) - “abc” 로 시작하는 문자열을 갖는 변수 이름 ends_with(“xyz”) - “xyz”으로 끝나는 문자열을 갖는 변수 이름 contains(“ijk”) - “ijk” 문자열을 포함하는 변수 이름 matches(“(.)\\1”) - 정규식, 반복되는 문자\n\n\niris |&gt; select(starts_with('S'))\niris |&gt; select(obs = starts_with('S'))\n\n아래는 matches 함수를 사용한 방법 입니다. 좀 더 복잡한 패턴을 적용하여 변수들을 선택할 수 있으며 grep 함수를 사용할 경우도 정규식 패턴을 적용할 수 있습니다.\n\niris2 &lt;- rename(iris, aavar = Petal.Length)\nselect(iris2, matches(\"(.)\\\\1\"))\ntmp &lt;-iris[,3:5]\ncolnames(iris)[grep(\"^S\", colnames(iris))]\niris[,grep(\"^S\", colnames(iris))]\ntmp\n\n아래 (.)\\\\1은 하나의 문자 .가 (어떤 문자든) 한 번 더 \\\\1 사용된 변수 이름을 말하며 이는 aavar 의 aa밖에 없으므로 aavar가 선택됩니다. grep에서 ^ 표시는 맨 처음을 나타내므로 ^S는 S로 시작하는 문자가 되겠습니다. 따라서 grep(\"^S\", colnames(iris))의 경우 컬럼 이름 중 S로 시작하는 이름은 True로 그렇지 않으면 False 값을 리턴합니다.\n\n\n6.7.2 filter\nfilter 함수를 사용해서 원하는 조건의 데이터 (샘플)을 골라낼 수 있습니다.\n\nlibrary(dplyr)\n\nhead(iris)\niris |&gt; \n  filter(Species==\"setosa\")\n\niris |&gt; \n  filter(Species==\"setosa\" | Species==\"versicolor\")\n\niris |&gt; \n  filter(Species==\"setosa\" & Species==\"versicolor\")\n\niris |&gt; \n  filter(Species==\"setosa\" | Species==\"versicolor\") |&gt; \n  dim()\n\nfilter의 ,로 구분되는 매개변수는 and 로직으로 묶인 조건입니다. 지난 강좌에서 보셨듯 R에서 and는 &, or는 |, 그리고 not은 ! 으로 사용하면 되며 filter에서 ,로 구분된 조건은 and와 같다고 보시면 되겠습니다.\n\nImage from (https://r4ds.had.co.nz/)\n\n\n6.7.3 arrange\narrange()는 지정된 변수를 기준으로 값의 크기순서로 샘플들의 배열 순서 즉, row의 순서를 바꾸는 기능을 수행합니다. 기본으로 크기가 커지는 순서로 정렬이 진행되며 작아지는 순서를 원할 경우 desc 함수를 사용할 수 있습니다.\n\niris |&gt; arrange(Sepal.Length)\niris |&gt; arrange(desc(Sepal.Length))\niris |&gt; arrange(Sepal.Length, Sepal.Width)\n\n\n\n6.7.4 mutate\nmutate() 함수는 새로운 변수를 추가할 수 있는 기능을 제공하며 앞에서 배웠던 within()과 비슷하다고 볼 수 있습니다. 아래와 같이 mutate함수는 sepal_ratio라는 변수를 새로 만들어서 기존 iris 데이터들과 함께 반환해 줍니다.\n\niris2 &lt;- iris |&gt; mutate(sepal_ratio = Sepal.Length/Sepal.Width)\nhead(iris2)\n\n\n\n6.7.5 summarise\nsummarise()는 data.frame내 특정 변수의 값들로 하나의 요약값/대푯값을 만들어 줍니다. summarise 함수는 단독으로 쓰이기 보다는 group_by() 기능과 병행해서 쓰이는 경우에 유용하게 쓰입니다. summarise_all() 함수를 사용하면 모든 변수에 대해서 지정된 함수를 실행합니다. 특히 summarise 함수는 다음과 같이 across, if_any, if_all 등의 helper 함수와 조합되어 사용이 가능합니다.\n\niris |&gt; summarise(mean(Sepal.Length), m=mean(Sepal.Width))\niris |&gt; \n  group_by(Species) |&gt; \n  summarise(mean(Sepal.Width))\n\niris |&gt; \n  group_by(Species) |&gt; \n  summarise_all(mean)\n\niris |&gt; \n  group_by(Species) |&gt; \n  summarise(across(everything(), mean))\n\n\niris |&gt; \n  group_by(Species) |&gt; \n  summarise_all(sd)\n\niris |&gt; \n  group_by(Species) |&gt; \n  summarise(across(everything(), sd))\n\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\n96 플레이트 데이터를 읽고 각 반복에 대한 평균과 표준편차 계산\n샘플별로 농도별로 막대그래프 그리고 표준편차 표시\n\n\nlibrary(tidyverse)\nlibrary(readxl)\ndat &lt;- read_excel(\"examples/plate_reader.xls\", sheet=1, skip = 0, col_names=T)\nconc_val &lt;- c(0, 0.1, 0.5, 1, 5, 10)\n\n\nnewdat &lt;- dat |&gt; \n  mutate(sample = stringr::str_sub(Well, 1, 1)) |&gt; \n  mutate(cpos = as.numeric(stringr::str_sub(Well, 2, -1))) |&gt; \n  mutate(conc = case_when(cpos &lt; 7 ~ cpos,\n                          TRUE ~ cpos-6)) |&gt; \n  mutate(dupl = case_when(cpos &lt; 7 ~ 1,\n                          TRUE ~ 2)) |&gt; \n  rename(od = \"595nm_kk (A)\",\n         gfp = \"EGFP_sulim (Counts)\") |&gt; \n  dplyr::select(sample, conc, dupl, od, gfp)\n\nnewdat |&gt; \n  mutate(conc_new = conc_val[conc])\n\nnewdat2 &lt;- newdat |&gt; \n  mutate(conc = as.factor(conc_val[conc])) |&gt; \n  mutate(dupl = as.character(dupl)) |&gt; \n  mutate_if(is.character, as.factor) |&gt; \n  group_by(sample, conc) |&gt; \n  summarise(m = mean(gfp), s = sd(gfp))\n\n\nnewdat2 |&gt; \n  ggplot(aes(x=sample, y=m, fill = conc)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  geom_errorbar(mapping = aes(ymin = m-s, ymax = m+s), position = position_dodge2(width = 0.5, padding = 0.5))\n\n\n\n\n\n6.7.6 join\njoin 함수는 데이터를 병합해주는 기능을 수행하는 함수 입니다. 네 가지 종류의 함수가 있으며 (left_join(), ’right_join(), 'inner_join(), ’full_join()) 기본적으로 공통되는 이름의 변수를 (key) 이용해서 공통되는 샘플끼리 자동으로 병합해 주는 기능을 수행합니다.by`에서 지정해준 파라메터의 값을 기준으로 기능이 수행 됩니다.\n\ndf1 &lt;- data.frame(id=c(1,2,3,4,5,6), age=c(30, 41, 33, 56, 20, 17))\ndf2 &lt;- data.frame(id=c(4,5,6,7,8,9), gender=c(\"f\", \"f\", \"m\", \"m\", \"f\", \"m\"))\n\ninner_join(df1, df2, by=\"id\")\nleft_join(df1, df2, \"id\")\nright_join(df1, df2, \"id\")\nfull_join(df1, df2, \"id\")\n\n# vs.\ncbind(df1, df2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "05-data-transformation-tidyverse.html#code-comparison",
    "href": "05-data-transformation-tidyverse.html#code-comparison",
    "title": "6  Data transform tidyverse",
    "section": "6.8 Code comparison",
    "text": "6.8 Code comparison\n이제 split, apply, combine을 활용하여 평균을 구하는 코드와 dplyr 패키지를 사용하여 만든 코드를 비교해 보도록 하겠습니다. iris 데이터를 분석하여 품종별로 꽃받침의 길이 (Sepal.length)의 평균과 표준편차, 그리고 샘플의 수를 구해보는 코드입니다.\nsplit은 factor형 변수인 Species를 기준으로 iris 데이터를 나누어 주는 역할을 하며 lapply는 list 형 데이터인 iris_split을 각 리스트의 각각의 원소들에 대해서 임의의 함수 function(x)... 를 수행하는 역할을 합니다. 마지막 data.frame으로 최종 경로를 combine 합니다.\n\niris_split &lt;- split(iris, iris$Species)\niris_means &lt;- lapply(iris_split, function(x){mean(x$Sepal.Length)})\niris_sd &lt;- lapply(iris_split, function(x){sd(x$Sepal.Length)})\niris_cnt &lt;- lapply(iris_split, function(x){length(x$Sepal.Length)})\niris_df &lt;- data.frame(unlist(iris_cnt), unlist(iris_means), unlist(iris_sd))\n\n아래는 dplyr 패키지를 사용한 코드 입니다.\n\niris_df &lt;- iris |&gt; \n  group_by(Species) |&gt; \n  summarise(n=n(), mean=mean(Sepal.Length), sd=sd(Sepal.Length))\n\n위에서 보듯 dplyr 패키지를 사용할 경우 그 결과는 같으나 코드의 가독성과 효율성면에서 장점을 보여줍니다. iris 데이터를 받아서 Species에 명시된 그룹으로 나누고 원하는 함수를 타깃 컬럼에 대해서 적용하라는 의미 입니다. 다음은 모든 변수에 대한 평균을 구하는 코드 입니다.\n\niris_mean_df &lt;- iris |&gt; \n  group_by(Species) |&gt; \n  summarise(across(everything(), mean))\n\n자세한 ggplot의 내용은 다음시간에 학습하겠지만 각 평균에 대한 막대그래프를 그러보겠습니다.\n\nlibrary(ggplot2)\n\niris_mean_df2 &lt;- iris_mean_df |&gt; \n  pivot_longer(-Species)\n\nggplot(iris_mean_df2, aes(x=Species, y=value, fill=name)) +\n  geom_bar(stat=\"identity\", position=\"dodge\")\n\n\n\nThis work is available under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Data transform tidyverse</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html",
    "href": "06-bioconductor.html",
    "title": "7  Bioconductor",
    "section": "",
    "text": "7.1 Introduction\nBioconductor는 바이오인포메틱스를 위한 R기반의 데이터, 메소드, 그리고 패키지들의 모음입니다. 2002년 microarray 데이터 분석을 위한 플랫폼으로 시작되었으며 현재 2000개 이상의 패키지로 구성되어 있습니다. R은 분산형 오픈소스이나 Bioconductor는 Full-time developer들에 의해서 유지되고 있습니다. CRAN에 배포되지 않고 CRAN에 비해 더 많은 필수 자료들 (vignettes 등)이 필요하며 높은 수준으로 quality control이 되고 있습니다. Bioconductor는 6개월마다 예정된 릴리스를 통해 모든 bioconductor 패키지가 충돌없이 조화롭게 작동하도록 유지되고 있습니다.\nBioconductor가 R에 기반을 둔 가장 큰 이유는 다수의 통계학자들이 패키지를 만들어서 생물학적 데이터 분석에 활용하고 있다는 점 입니다. 즉, R은 통계 및 “데이터 과학”에서 핵심 역할을 하고 있고 게놈 규모의 실험 데이터를 다루는 분석전문가들에게 R 기반의 도구의 선택은 자연스러운 현상입니다. R은 통계 및 “데이터 과학”에서 사용하기 쉽고 중심적인 역할을 하기 때문에 게놈 규모의 실험 데이터를 다루는 전문가들에게는 R이 자연스러운 선택입니다.\n사용 가능한 패키지들은 이곳을 참고하시면 되겠습니다.\nBioconductor 코어 개발 그룹은 사용자들이 지놈스케일 데이터를 더 편리하게 다루룰 수 있도록 데이터의 구조를 개발하고 있습니다. Bioconductor의 주요 기능은 다음과 같습니다.\n사이트 리뉴얼",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html#introduction",
    "href": "06-bioconductor.html#introduction",
    "title": "7  Bioconductor",
    "section": "",
    "text": "https://www.bioconductor.org\n\n\n\n\n\n\n\n지놈스케일의 서열이나 발현등 대용량 유전자형 데이터 관리 및 통계적 분석을 위한 툴 제공\n분자수준의 현상과 생장이나 질병 등 표현형수준의 관계를 규명하기 위한 정량 데이터 통합 및 관리",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html#packages",
    "href": "06-bioconductor.html#packages",
    "title": "7  Bioconductor",
    "section": "7.2 Packages",
    "text": "7.2 Packages\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nBioconductor에서 제공하는 소프트웨어, DB, Data 종류 이해\nBioconductor 패키지 설치, 도움말, 문서 사용법 이해\n\n\n\n메인화면 &gt;&gt; Use &gt;&gt; Software, Annotation, Experiment\n\nSoftware: 데이터 분석을 위한 알고리즘/툴 모음\nAnnotation: 유전자 symbol/ID mapping, gene ontology 기반 유전자 분류, 유전체상에서 exon, transcript, gene 등의 위치, 단백질 기능 등. Annotation &gt; Packagetype 참고\nExperiment data: 검증된 실험 데이터\nWorkflow: 특정 데이터 분석을 위한 프로세스 모음 RNA-seq, ChIP seq, copy number analysis, microarray methylation, classic expression analysis, flow cytometry 등\n\n\nAnnotation 리소스는 다음과 같이 몇 단계의 레벨로 구분할 수 있습니다.\n\nBSgenome: Biostring 형식으로 저장된 특정 생물의 완전한 염기 서열 정보\nOrgDb: 특정 생물(Organism)의 기능적 annotations\nChipDb: 다양한 microarray platform 기반 Chip (probe) 정보\nTxDb/EnsDb: 전사체 정보, 위치 정보\nInparanoidDb: 단백질 homology 정보\nOthers GO.db: KEGG.db\n\n위 독립적인 annotation 리소스를 통합한 패키지들이 제공되고 있으며 대략적으로 다음과 같습니다.\n\nOrganismDb: 특정 종에 대한 OrgDb, TxDb, GO.db 등을 포함하는 패키지 DB\nAnnotationDbi: OrgDb, ChipDb, TxDb 포함\nAnnotationHub: 다양한 annotation 정보를 얻을 수 있도록 만든 온라인 툴 (Bioconductor’s AnnotationHub service)\nbiomaRt: 다양한 annotation 정보를 얻을 수 있도록 만든 온라인 툴\n모든 .db 패키지는 Bioconductor에 의해서 6개월마다 업데이트됨\n\nHomo.sapiens의 경우 아래와 같으며 biocViews 의 OrganismDb 를 클릭하면 OrganismDb 타입의 annotation 패키지를 볼 수 있습니다. 현재 (23.11) Homo.sapiens, Mus.musculus, Rattus.norvegicus 의 3종류가 제공됩니다.\n\nBioconductor에서 제공하는 패키지를 설치하기 위해서는 BiocManager를 먼저 설치하고 해당 패키지를 설치하시기 바랍니다. BiocManager에는 available()이라는 함수로 (특정 문자가 포함된) 사용 가능한 패키지를 검색할 수 도 있습니다. 예를 들어 IRanges라는 패키지를 설치할 경우 bioconductor 상단 오른쪽의 Search 나 software package list의 검색창에서 IRanges를 입력하여 해당 패키지를 찾고 다음과 같이 설치를 수행합니다.\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"IRanges\")\n## .libPaths()\n\n\n\n\n\n\n\nExercises\n\n\n\n\nOrganismDb는 meta-package의 형태로 OrgDb, TxDb, 그리고 GO.db 패키지들을 포함하는 정보를 가지고 있음. OrganismDB 중 인간의 정보를 가진 Homo.sapiens를 찾아 설치하시오\n\n\n\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"Homo.sapiens\")\n\nlibrary(Homo.sapiens)\nclass(Homo.sapiens)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html#learning-and-support",
    "href": "06-bioconductor.html#learning-and-support",
    "title": "7  Bioconductor",
    "section": "7.3 Learning and support",
    "text": "7.3 Learning and support\n각 패키지는 제목, 저자, 유지관리자, 설명, 참조, 설치법 등의 정보가 포함된 landing page가 있으며 패키지 내 함수들은 상세한 설명과 예제가 제공됩니다. 예를 들어 IRanges의 landing page를 참고하세요. vignettes는 bioconductor의 중요한 특징 중 하나로 R 코드와 함께 패키지를 사용하는 방법에 대한 상세한 설명을 제공하는 문서입니다.\n\nlibrary(IRanges)\n\nvignette(package=\"IRanges\")\nbrowseVignettes(\"IRanges\")\nvignette(\"IRangesOverview\", package=\"IRanges\")\n\nir1 &lt;- IRanges(start=1:10, width=10:1)\nir1\nclass(ir1)\nmethods(class=\"IRanges\")\n\nexample(IRanges)\n?IRanges\n??IRanges\n\n메인페이지 &gt;&gt; Learn &gt;&gt; Support site 게시판에는 관련된 여러 QnA 들이 있어서 유사 문제에 대한 도움을 받을 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html#oop---class-object-and-method",
    "href": "06-bioconductor.html#oop---class-object-and-method",
    "title": "7  Bioconductor",
    "section": "7.4 OOP - Class, Object and Method",
    "text": "7.4 OOP - Class, Object and Method\n객체지향프로그래밍 (OOP)은 복잡한 문제를 프로그래밍할 때 발생되는 코드의 복잡성을 해결할 수 있는 하나의 방안으로 1990년대부터 많이 사용되었습니다.\nR도 객체지향 프로그래밍 언어입니다. 그런데 R은 다른 언어들에 비해서 좀 어려운 (다른) 개념으로 사용됩니다. R에서 사용하는 Class에는 크게 base type, S3, S4, RC, 그리고 R6 등 다양한 타입이 있고 이 중 S3를 많이 사용해 왔으며 S3의 단점을 보완한 S4 형식의 class와 R6를 주로 사용합니다 (AdvancedR?). 본 강의에서는 S3 형식의 class만 다루도록 하겠습니다.\n클래스를 사용하는 이유는 여러가지가 있겠지만 복잡한 개념의 데이터를 구조화하고 쉽게 관리하기 위해서 사용한다고 보면 될 것 같습니다. 여러분이 알아야할 개념은 Class와 Object 그리고 Method 입니다. 사실 R의 모든것이 Object이고 이러한 Object들의 정의가 Class 입니다.\n\nmydf &lt;- data.frame(x=c(1:5), y=LETTERS[1:5])\nmydf\nclass(mydf)\n\n위에서 mydf는 변수라고 부르지만 object라고 부르기도 합니다. mydf의 class는 data.frame 입니다. 클래스는 누구든 원하는 만큼 얼마든지 만들 수 있습니다.\n\nclass(mydf) &lt;- \"myclass\"\nprint(mydf)\nmydf\nclass(mydf)\n\nclass(mydf) &lt;- c(\"data.frame\", \"myclass\")\nmydf\nclass(mydf)\n\n그런데 모든 object들이 OOP 유래는 아닙니다 base object들이 그 예입니다.\n\nx &lt;- 1:10\nclass(x)\nattr(x, \"class\")\n\nmtcars\nattr(mtcars, \"class\")\n\n클래스를 만드는 목적은 앞에서 언급 한 바와 같이 복잡한 개념의 구조화와 쉬운 관리를 위함입니다. 예를 들어 내가 개발한 특정 함수가 특정 데이터 타입만 method는 위와 같은 클래스들에 특화된 어떤 기능을 하는 함수라고 생각하시면 됩니다.\n\nmt &lt;- matrix(1:9, 3,3)\ndf &lt;- data.frame(1:3, 4:6, 7:9)\n\nclass(mt)\nclass(df)\nstr(mt)\nstr(df)\n\n\ndiamonds &lt;- ggplot2::diamonds\n\nsummary(diamonds$carat)\nsummary(diamonds$cut)\n\nmethods(class=\"data.frame\")\nmethods(class=\"myclass\")\n\n위 summary, str 등이 generic function이라 불리는 method들 입니다. class마다 사용 가능한 method가 어떠한 정보가 있는지 알기 위해서 methods()라는 함수를 사용합니다. R의 객체지향프로그래밍에 대한 상세한 내용은 Advanced R를 참고하세요.\n\n\n\n\n\n\nExercises\n\n\n\n\n다음 두 종류의 객체에 대해서 class 가 integer 일 경우 평균을 계산하고 character일 경우 비율을 계산하는 (table 함수 사용) mysummary 함수를 만드시오\n\n\nx &lt;- c(1:10)\ny &lt;- c(\"A\", \"G\", \"G\", \"T\", \"A\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html#bioconductor의-oop",
    "href": "06-bioconductor.html#bioconductor의-oop",
    "title": "7  Bioconductor",
    "section": "7.5 Bioconductor의 OOP",
    "text": "7.5 Bioconductor의 OOP\nbioconductor에서 다루는 genome 스케일의 experiment나 annotation은 대표적인 복잡한 데이터 중 하나 입니다. Bioconductor에서 OOP 개념은 다음과 같습니다.\n\nclass - 복잡한 생물학적 데이터 구조의 틀 정의\nobject - 특정 클래스가 구현된 실체\nmethod - 특정 클래스에 대한 기능 수행\n\n예를 들어 앞에서 설치한 Homo.sapience의 class인 OrganismDb 살펴보면 다음과 같습니다.\n\nlibrary(Homo.sapiens)\nclass(Homo.sapiens)\n?OrganismDb\n\n\nThe OrganismDb class is a container for storing knowledge about existing Annotation packages and the relationships between these resources. The purpose of this object and it’s associated methods is to provide a means by which users can conveniently query for data from several different annotation resources at the same time using a familiar interface.\n\n\nhomo_seq &lt;- seqinfo(Homo.sapiens)\nclass(homo_seq)\n?Seqinfo\n\n\nA Seqinfo object is a table-like object that contains basic information about a set of genomic sequences. …\n\n\nlength(homo_seq)\nseqnames(homo_seq)\n\nbioconductor에는 대용량 정보가 object 형태로 구조화되어 저장되어 있으며 library()함수로 읽어올 수 있고 다양한 함수로 해당 object의 정보를 읽어올 수 있습니다.\n\n\n\n\n\n\nExercises\n\n\n\n\nHomo.sapiens 정보에서 상위 10개 유전자와 상위 10개 exon을 구하시오\n\n\n\n\ngenes(Homo.sapiens)[1:10]\nexons(Homo.sapiens)[1:10]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "06-bioconductor.html#bioconductor-hub",
    "href": "06-bioconductor.html#bioconductor-hub",
    "title": "7  Bioconductor",
    "section": "7.6 Bioconductor hub",
    "text": "7.6 Bioconductor hub\n\nAnnotationHub는 Bioconductor에서 서비스하는 annotation server에 접속할 수 있는 client interface를 제공합니다. annotationHub server는 전장 유전체 정보중 공공에서 활용 가능한 대규모 데이터를 제공합니다. ENSEMBL genome fasta, GTF files, UCSC resources, ENCODE data track 등을 포함합니다.\n\n\nlibrary(AnnotationHub)\nhub &lt;- AnnotationHub()\nclass(hub)\nmcols(hub) |&gt; as.data.frame() |&gt; count(rdataclass)\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bioconductor</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html",
    "href": "07-highthroughput-data.html",
    "title": "8  High-throughput data",
    "section": "",
    "text": "8.1 Next-generation sequencing\nNext-generation sequencing (NGS) 는 DNA나 RNA 서열을 해독하는 기술로 2005년 개발될 초기에는 기존의 Sanger sequencing과는 다르게 여러 DNA 가닥을 동시에 해독하는 특징으로 “massively-parallel sequencing” 으로 불리우기도 했습니다.\nNGS에 대한 자세한 설명은 illuina 사에서 제공하는 튜토리얼의 다음 사이트들을 참고하시기 바랍니다.\n(Shor read) NGS 워크플로는 다음과 같은 네 단계를 순차적으로 수행합니다.\n각 단계별로 보면 다음과 같습니다.\n위 단계 중 Secondary analysis에 해당하는 분석이 일반적으로 우리가 수행하는 RNA-Seq 등의 분석입니다. 시퀀싱 장비에서 읽힌 이미지 정보는 Binary Base Call (BCL) 파일로 변환됩니다. 우리가 일반적으로 다루는 FASTQ 파일은 서열 정보와 quality 정보를 text 형태로 저장한 파일로서 BCL 파일로부터 만들어집니다.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html#next-generation-sequencing",
    "href": "07-highthroughput-data.html#next-generation-sequencing",
    "title": "8  High-throughput data",
    "section": "",
    "text": "Sequencing Fundamentals\nSequencing Illumina Technology\nIllumina Sequencing by Synthesis\n\n\n\n\n\nNGS workflow, figures from Illumina\n\n\n\n\n\n\nLibrary Prep, figures from Illumina\n\n\n\n\n\ncluster generation, figures from Illumina\n\n\n\n\n\nSequencing, figures from Illumina\n\n\n\n\n\nData analysis, figures from Illumina\n\n\n\n\n\n\nData analysis, figures from Illumina",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html#fastq-preprocessing",
    "href": "07-highthroughput-data.html#fastq-preprocessing",
    "title": "8  High-throughput data",
    "section": "8.2 FASTQ preprocessing",
    "text": "8.2 FASTQ preprocessing\nFASTQ 파일에는 타깃 서열정보뿐만아니라 바코드나 인덱스 등의 서열이 포함되어 있습니다.\n\n따라서 분석을 위해서는 위 서열들을 제거하고 quality에 따라서 read 들을 필터링 하는 작업이 필요합니다. 기존에는 linux 스크립트 기반의 소프트웨어들이 사용되었으나 본 강의에서는 Rstudio에서 바로 설치해서 활용할 수 있는 Rfastq 패키지를 사용하겠습니다. Rfastq는 quality control과 polyX trimming, adapter trimming, paired-ed reads merging 등의 기능을 제공하고 있습니다.\n\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"Rfastp\")\n\nexamples 디렉토리 생성 후 예시 fastq 파일 다운로드, rfastq 실행으로 로딩과 필터링을 수행합니다. 참고로 Q10은 약 90%의 정확도, Q20은 약 99%의 정확도, Q30은 약 99.9% 정확도를 갖는 read의 개수 입니다.\n\nlibrary(Rfastp)\n\ndownload.file(url = \"https://github.com/greendaygh/kribbr2022/raw/main/fastq/SRR11549087_1.fastq\", destfile = \"examples/SRR11549087_1.fastq\")\n\nfqfiles &lt;- dir(path = \"examples\", pattern = \"*.fastq\")\n\n#?rfastp\nfastq_report &lt;- rfastp(read1 = file.path(\"examples\", fqfiles[1]), \n                       outputFastq = file.path(\"examples\", paste0(\"filtered_\", fqfiles[1])))\n\nround(qcSummary(fastq_report), 2)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html#sequence-read-archive",
    "href": "07-highthroughput-data.html#sequence-read-archive",
    "title": "8  High-throughput data",
    "section": "8.3 Sequence Read Archive",
    "text": "8.3 Sequence Read Archive\nSRA SRA (Sequence Read Archive)는 High-throughput 시퀀싱 데이터의 공개 데이터베이스 중 가장 큰 규모의 미국 국립 보건원(NIH)의 1차 데이터베이스로서 서열데이터 뿐만 아니라 메타데이터, 유전체, 및 환경 데이터를 포함합니다. NCBI와 EBI(European Bioinformatics Institute), DDBJ(DNA Database of Japan) 간 국제적 제휴를 통해 세 기관에서 제출 받은 데이터는 서로 공유되고 있습니다.\n간략한 사용법은 NBK569238 또는 SRA download 문서 이곳을 참고하시기 바랍니다.\n데이터를 다운로드 할 수 있는 NCBI SRA Toolkit을 제공하며 이 중 MS Windows 64 bit architecture 를 다운로드 받아 압축을 풀고 사용할 적절한 디렉토리로 옮겨 줍니다. 여기서는 D:\\sratoolkit.3.0.0-win64이 곳에 이동해 두었고 전체 디렉토리 구성은 다음과 같습니다.\n\n명령을 어느 디렉토리에서나 사용하고 싶다면 위 경로의 bin 디렉토리를 path로 잡아주는 과정이 필요합니다. 다음 위치로 이동 후 “내PC &gt; 속성 &gt; 고급 시스템 설정 &gt; 환경변수” 를 클릭하면 다음 창이 생성됩니다.\n\nPath를 선택후 편집을 클릭하면 다음 화면이 생성되고 새로만들기를 누른 후 D:\\sratoolkit.3.0.0-win64\\bin라고 입력해주고 모든 창에서 확인을 눌러주면 되겠습니다.\n\n이제 파일 탐색기로 파일을 다운로드 받을 작업 디렉토리로 이동한 후 주소창에 cmd이라고 입력해서 프롬프트가 있는 명령창을 실행합니다.\nfastq-dump.exe를 사용해서 다운로드 받을 수 있으며 최근에는 fasterq-dump를 사용해서 더욱 빠르게 다운로드를 받을 수 있습니다.\n\n뒤에서 설명할 GEO 데이터베이스에서 GSE148719 데이터를 다운로드 해보겠습니다. 위 링크를 클릭해서 들어가면 화면 하단의 SRA Run Selector 라는 링크가 있고 이를 클릭하면 다음과 같은 화면이 보입니다.\n\nMetadata (SraRunTable.txt) 와 Accession list (SRR_Acc_List.txt)를 파일 형태로 다운로드 받은 후 적절한 전처리 후 사용하면 되겠습니다.\nprefetch --option-file SRR_Acc_List.txt\n만약 하나의 fastq 데이터만 다운로드 받을 경우 다음과 같습니다.\nprefetch SRR11549076\n이후 fasta 파일로 변환해 줍니다\nfasterq-dump --split-files SRR11549076\n100000개 read만 별도로 저장\nfastq-dump -X 10000 --split-files SRR11549076",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html#gene-expression-omnibus-geo",
    "href": "07-highthroughput-data.html#gene-expression-omnibus-geo",
    "title": "8  High-throughput data",
    "section": "8.4 Gene expression omnibus (GEO)",
    "text": "8.4 Gene expression omnibus (GEO)\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nGEO data 구조를 이해하고 다운로드\n각 클래스별 사용법 이해\n\n\n\nGEO는 microarray, next-generation sequencing 등의 high-throughput 유전체 데이터를 보유한 공공 저장소입니다.\n\n대규모 기능유전체 데이터베이스\n데이터 기탁 쉽게 만들고 고수준 QC 유지\n사용하기 쉬운 인터페이스 유지\n\nGEO\nPlatform, Sample, Series로 구성되어 있으며 Platform은 사용된 어레이 플랫폼에 대한 설명과 데이터 테이블로 구성되어 있습니다. GPLXXX 형태의 GEO 액세스 번호가 할당되며 하나의 플랫폼은 많은 샘플들에 사용될 수 있습니다. Sample은 개별 샘플이 처리된 조건 등의 설명이 있는 테이블로 구성되며 GSMxxx 형태의 GEO 등록 번호가 할당됩니다. Sample은 하나의 Platform만 참조 가능하며 여러 Series에 포함될 수 있습니다. Series는 관련된 샘플을 그룹화하고 전체 연구의 주요 설명을 제공합니다. GEO 등록 번호 GSExxx가 할당됩니다.\n\n위 세 가지 타입 외에 Datasets 이 있으며 Datasets은 GDSxxx 아이디를 가집니다. 앞서 Series (GSExxx) 데이터가 연구자들이 업로드한 raw 데이터라고 한다면 Datasets (GDSxxx)는 관리자들에 의해 큐레이션된 데이터로 볼 수 있습니다. 브라우져를 통해 쉽게 검색할 수 있습니다. GEO의 상세한 내용은 웹사이트(https://www.ncbi.nlm.nih.gov/geo/info/overview.html)에서도 확인할 수 있습니다.\nBioconductor에서는 GEOquery라는 패키지로 관련 파일들을 다운로드 받을 수 있습니다.\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"GEOquery\")\n\nlibrary(GEOquery)\n#browseVignettes(\"GEOquery\")\n\nThe GDS class - GDS507 데이터세트는 GEO사이트에서 검색하면 다음과 같이 GPL97 칩을 사용했고 tumor tissue와 normal 샘플간 비교를 위한 연구에서 생산된 데이터입니다. 17개의 샘플로 구성되어 있으며 2003년 생산된 데이터 입니다.\n\n\ngds &lt;- getGEO(filename=system.file(\"extdata/GDS507.soft.gz\",package=\"GEOquery\"))\nclass(gds)\nmethods(class=class(gds))\nTable(gds)\nColumns(gds)\n\n“GDS” 객체를 저장한 후 해당 클래스에 해당하는 객체를 어떻게 활용하면 좋을지 모를때가 많습니다. 위 gds를 출력해보면 일반적으로 보던 data.frame 형태와는 다릅니다. “GDS”라는 클래스를 새로 만들면서 그 구조도 필요한대로 만들어 둔 것입니다. 일반적으로 새로운 클래스를 만들때 해당 클래스 특화된 함수들이 제공되고 이러한 함수를 methods라는 명령어로 찾아볼 수 있습니다. Table(gds)를 보면 data.frame 형태로 22,645개의 row와 19개의 column이 있습니다. 각 컬럼은 17개의 샘플 정보와 ID_REF, IDENTIFIER로 구성됩니다.\n각 샘플은 GSM class로 샘플의 실제 측정값과 실험 조건 등 샘플별 정보 포함합니다. 아래 gsm 객체의 Table(gsm) 내용을 보면 컬럼에 있는 VALUE 값이 유전체 발현을 정량화한 값으로, 각 chip에서 해당 probe 서열의 Perfect-Match (PM)과 Mismatch (MM)의 비율인 (logged) PM-MM의 평균입니다.\n\ngsm &lt;- getGEO(filename=system.file(\"extdata/GSM11805.txt.gz\",package=\"GEOquery\"))\nmethods(class=class(gsm))\nhead(Meta(gsm))\nTable(gsm)\nColumns(gsm)\n\nGPL class는 사용된 칩의 기본 Annotation 정보로서 아래 Columns(gpl)을 실행하면 유전자이름과 심볼, ID 등 21개의 정보가 출력됩니다.\n\ngpl &lt;- getGEO(filename=system.file(\"extdata/GPL97.annot.gz\",package=\"GEOquery\"))\ngpl\nmethods(class=class(gpl))\nTable(gpl)\nColumns(gpl)\n\nGSE class는 GDS와 유사한 수준의 데이터를 담고있는 클래스로 관련된 샘플과 annotation 들을 모두 포함한 데이터 입니다. Meta 함수로 전체적인 정보를 알 수 있으며 관련된 sample과 platform 정보는 GSMList와 GPLList로 찾을 수 있습니다.\n\ngse &lt;- getGEO(filename=system.file(\"extdata/GSE781_family.soft.gz\",package=\"GEOquery\"))\nmethods(class=class(gse))\nMeta(gse)\nhead(GSMList(gse))\ngsm &lt;- GSMList(gse)[[1]]\nMeta(gsm)\nTable(gsm)\nColumns(gsm)\n\n\nGPLList(gse)\ngpl &lt;- GPLList(gse)[[1]]\nclass(gpl)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html#expressionset",
    "href": "07-highthroughput-data.html#expressionset",
    "title": "8  High-throughput data",
    "section": "8.5 ExpressionSet",
    "text": "8.5 ExpressionSet\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nBioconductor에서 제공하는 ExpressionSet 구조와 활용법 이해\n\n\n\nBioconductor는 지놈 데이터를 관리하기 위한 표준화된 데이터 구조 class인 ExpressionSet를 제공합니다. ExpressionSet은 HT assay 데이터와 실험 meta를 포함하고 있으며 앞에서 본 GSE 클래스 데이터를 읽어들일때 특정 옵션을 사용하면 ExpressionSet 클래스로 읽어올 수 있습니다.\n 출처BS831 lecture note\n?getGEO 도움말 중 Value 세션을 보면 getGEO 함수를 사용할 때 GSEMatrix 옵션을 사용하면 ExpressionSet 형태로 데이터를 읽어올 수 있다고 설명이 되어 있습니다. 아래와 같이 gse2553 데이터의 클래스가 ExpressionSet인 것을 알 수 있습니다.\n일부 GSE 데이터셋의 경우 phenoData, meta 데이터만 포함되어 있고 아직 featureData, assayData는 포함되지 않은 것이 많아 보입니다. 이 경우 GSM과 GFL 데이터를 각각 모두 받은 후 분석이 필요합니다.\n\nlibrary(GEOquery)\n\ngse2553 &lt;- getGEO('GSE2553',GSEMatrix=TRUE)\ngse2553\nclass(gse2553)\nclass(gse2553[[1]])\nmygse &lt;- gse2553[[1]]\n?ExpressionSet\nmethods(class=class(mygse))\nmypdata &lt;- pData(mygse)\nmyfdata &lt;- fData(mygse)\nmyexdata &lt;- exprs(mygse)\n\n\nmypdata\nclass(myexdata)\n\nGDS2eSet 함수를 사용하면 GDS 클래스 데이터를 ExpressionSet class로 변환할 수 있습니다.\n\ngds &lt;- getGEO(filename=system.file(\"extdata/GDS507.soft.gz\",package=\"GEOquery\"))\nclass(gds)\neset &lt;- GDS2eSet(gds, do.log2=TRUE)\neset\npData(eset)\n\nExample\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nDEG 실습 코드 이해\n\n\n\n다음 예제는 GEOquery 패키지에 있는 데이터셋을 활용하여 간단한 DEG 분석을 수행하는 코드로서 DEG 분석의 원리 이해와 해석을 위해 학습하는 예제입니다. 통계(추정과 검정)을 먼저 참고하고 실습해 보아도 좋겠습니다. 먼저 ExpressionSeq으로 변환하지 않고 tidyverse 패키지와 t-test를 활용해서 DEG를 수행합니다. 이 후 ExpressionSeq으로 변환 후 DESeq2 패키지를 사용하여 분석해보겠습니다.\n\nlibrary(tidyverse)\nlibrary(skimr)\n\ngds &lt;- getGEO(filename = system.file(\"extdata/GDS507.soft.gz\",package=\"GEOquery\"))\ngds\n\nmyexp &lt;- Table(gds)[1:5000,]\nmypheno &lt;- Columns(gds)\n\nglimpse(myexp)\nglimpse(mypheno)\n\nskim(myexp)\nstr(myexp)\n\n샘플들 두 그룹별로 평균을 계산하기 위해서 우선 matrix transpose가 필요합니다. tidyverse는 (대부분의 통계 데이터는) row에 샘플이 위치하고 column에 feature (변수)가 있는 반면 위 myexp는 특성상 샘플이 컬럼에 위치하므로 transpose 수행 후 평균을 계산할 필요가 있습니다. transpose는 long형으로 변환 후 다시 컬럼에 위치할 변수들을 지정해서 wide 형으로 변환하면 됩니다.\n\n## transpose\nmydat_tr &lt;- myexp |&gt; \n  dplyr::select(-IDENTIFIER) |&gt; \n  pivot_longer(cols = -ID_REF) |&gt; \n  pivot_wider(names_from = ID_REF, values_from = value)  \n\n이제 샘플들이 가진 질병 정보를 변수로 추가해줍니다. 이를 위해서 질병 정보를 가진 mypheno 데이터와 mydat_tr을 sample 이름을 기준으로 병합합니다.\n\nmydat2 &lt;- mypheno |&gt; \n  dplyr::select(sample, disease.state) |&gt; \n  left_join(mydat_tr, by = c(\"sample\" = \"name\"))\n\n그룹별로 평균을 계산합니다.\n\nmymean &lt;- mydat2 |&gt; \n  group_by(disease.state) |&gt; \n  summarise(across(where(is.numeric), mean))\n\n각 유전자별 평균값을 그래프로 분석하기 위해서는 normal, RCC가 변수로 되어야하기 때문에 메트리스를 transpose 시켜줍니다.\n\nmymean2 &lt;- mymean |&gt; \n  pivot_longer(-disease.state) |&gt; \n  pivot_wider(names_from=disease.state, values_from = value)\n\n두 그룹의 평균 값에 대한 각 유전자(feature)들의 산포도를 그릴 수 있습니다.\n\nggplot(mymean2, aes(x=normal, y=RCC)) +\n  geom_point() +\n  scale_x_log10() +\n  scale_y_log10()\n\n위 데이터는 feature 별로 normal과 RCC 값들의 평균을 가지고 있습니다. 이제 t-test를 통해 발현이 차이가 나는 유전자를 골라야 합니다. 위 평균을 구한 방법과 유사한 방법으로 표준편차 값을 구한 후 t값을 계산할 수 있으나 아래와 같이 tidyverse 타입의 함수를 사용해서 t.test 를 사용할 수도 있습니다. 일반적으로 R에서 t-test는 t-test라는 함수를 사용합니다.\n\n\nttestval &lt;- mydat2 |&gt;\n  summarise(across(where(is.numeric), function(x){\n    z &lt;- t.test(x[disease.state==\"normal\"], x[disease.state==\"RCC\"])\n    c(z$p.value, z$statistic)\n    }))\n\nttestval\n\n이제 앞에서 만든 평균값 데이터와 pvalue, tstatistic 등의 값들을 하나의 테이블로 만들기 위해서 위 ttestval 데이터를 transpose 시킨 후 mymean2 데이터와 병합합니다.\n\nttestval_tr &lt;- ttestval |&gt; \n  mutate(rnames = c(\"pvalue\", \"tstat\")) |&gt; \n  #column_to_rownames(var=\"rnames\") |&gt; \n  pivot_longer(-rnames) |&gt; \n  pivot_wider(names_from = rnames)\n\nfinaldat &lt;- mymean2 |&gt; left_join(ttestval_tr, by=\"name\")\nfinaldat\n\n유의한 데이터를 선별하고 가시화 합니다. 많은 test를 수행할 때 p-value를 그대로 사용할 경우 multiple testing 문제가 있어서 보정을 해주나 본 예제에서는 적용하지 않겠습니다.\n\nsigdat &lt;- finaldat |&gt; \n  filter(pvalue &lt; 0.001)\n\nfinaldat |&gt; \n  ggplot(aes(x=normal, y=RCC)) +\n  geom_point(alpha=0.2, color=\"#999999\") +\n  scale_y_log10() +\n  scale_x_log10() +\n  geom_point(data=sigdat, aes(x=normal, y=RCC), color=\"blue\", alpha=0.5, shape=20, size=3) +\n  theme_bw()\n\n아 결과는 p-value 가 0.001 이하인 probe들을 표현한 결과로서 정확한 결과 도출을 위해서는 multiple testing correction을 수행 후 수정된 유의확율을 이용할 필요가 있습니다.\n\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nExpresionSet 클래스와 DESeq2를 활용한 DEG 실습 코드 이해\n\n\n\n\nlibrary(tidyverse)\nlibrary(DESeq2)\nlibrary(GEOquery)\n\ngds &lt;- getGEO(filename = system.file(\"extdata/GDS507.soft.gz\",package=\"GEOquery\"))\n\neset &lt;- GDS2eSet(gds, do.log2=F)\neset\nclass(eset)\n\nmethods(class=\"ExpressionSet\")\n\n\nmyexp &lt;- data.frame(exprs(eset))\nmyfeature &lt;- fData(eset)\nmypheno &lt;- pData(eset)\n\nglimpse(myexp)\nskim(myexp)\nstr(myexp)\nglimpse(mypheno)\n\n\nlibrary(DESeq2)\n\n?DESeqDataSetFromMatrix\n\n# boxplot\nmyexp |&gt; \n  rownames_to_column() |&gt; \n  pivot_longer(-rowname) |&gt; \n  ggplot(aes(x=name, y=value)) +\n  geom_boxplot() +\n  scale_y_log10()\n\n# log scale\n\n# remove negative values\nmyexp |&gt; \n  filter(if_any(is.numeric, ~ . &lt; 0))\n\n# convert into count\nmyexpint &lt;- myexp |&gt;\n  mutate(across(where(is.numeric), ~ as.integer(.x))) \n\n# convert to DESeqDataSet class\nmyexpdeg &lt;- DESeqDataSetFromMatrix(countData = as.matrix(myexpint), \n                              colData = mypheno, \n                              design = ~disease.state)\n\nclass(myexpdeg)\n\n# perform analysis\ndds &lt;- DESeq(myexpdeg)\n\n# data boxplot\nnormcounts &lt;- DESeq2::counts(dds, normalized = T)\nnormcounts |&gt; \n  as.data.frame() |&gt; \n  rownames_to_column() |&gt; \n  pivot_longer(-rowname) |&gt; \n  ggplot(aes(x = name, y = value)) +\n  geom_boxplot() +\n  scale_y_log10() \n\nplotDispEsts(dds)\nmyres &lt;- DESeq2::results(dds, contrast = c(\"disease.state\", \"RCC\", \"normal\"))\nsummary(myres)\nDESeq2::plotMA(myres)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "07-highthroughput-data.html#summarizedexperiment",
    "href": "07-highthroughput-data.html#summarizedexperiment",
    "title": "8  High-throughput data",
    "section": "8.6 SummarizedExperiment",
    "text": "8.6 SummarizedExperiment\nExpressionSet은 일반적으로 행이 feature (유전자) 인 마이크로어레이 기반 실험 및 유전자 발현 데이터에 사용되었습니다. 그러나 유전체 분석을 위해서는 유전자 정보 외에도 유전체상의 위치 정보 등이 필요하며 이는 앞서 배운 GenomicRanges 형태의 데이터가 필요합니다. 따라서 최근에는 새로운 버전인 SummarizedExperiment class가 SummarizedExperiment 개발되어 사용되고 있습니다.\n\n\nlibrary(SummarizedExperiment)\n\n#if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n#    install.packages(\"BiocManager\")\n\n#BiocManager::install(\"airway\")\n\nlibrary(airway)\ndata(airway, package=\"airway\")\nse &lt;- airway\nse\n?RangedSummarizedExperiment \n\n# assay data\nassay(se)\n\n# Row (features)\nrowRanges(se)\n\n# Column (sample)\ncolData(se)\n\n# Experiment-wide metadata\nmetadata(se)\n\nSummarizedExperiment 생성\n\nnrows &lt;- 200\nncols &lt;- 6\ncounts &lt;- matrix(runif(nrows * ncols, 1, 1e4), nrows)\nrowRanges &lt;- GRanges(rep(c(\"chr1\", \"chr2\"), c(50, 150)),\n                     IRanges(floor(runif(200, 1e5, 1e6)), width=100),\n                     strand=sample(c(\"+\", \"-\"), 200, TRUE),\n                     feature_id=sprintf(\"ID%03d\", 1:200))\ncolData &lt;- DataFrame(Treatment=rep(c(\"ChIP\", \"Input\"), 3),\n                     row.names=LETTERS[1:6])\n\nse &lt;- SummarizedExperiment(assays=list(counts=counts),\n                     rowRanges=rowRanges, colData=colData)\n\nassay(se)\n\n# Row (regions-of-interest) data\nrowRanges(se)\n\n# Column (sample) data\ncolData(se)\n\n# Experiment-wide metadata\nmetadata(se)\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>High-throughput data</span>"
    ]
  },
  {
    "objectID": "08-Biostrings.html",
    "href": "08-Biostrings.html",
    "title": "9  Biostrings",
    "section": "",
    "text": "9.1 Introduction\nHigh-throughput sequencing 데이터를 포함한 DNA나 Amino acid와 같은 생물학적 서열은 Bioconductor의 다양한 패키지들에 의해서 분석될 수 있으며 특히 Biostrings 패키지는 생물학적 서열을 효과적으로 활용하기 위한 핵심 도구로 활용됩니다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biostrings</span>"
    ]
  },
  {
    "objectID": "08-Biostrings.html#working-with-sequences",
    "href": "08-Biostrings.html#working-with-sequences",
    "title": "9  Biostrings",
    "section": "9.2 Working with sequences",
    "text": "9.2 Working with sequences\nBiostrings는 DNA, RNA, amino acids와 같은 생물학적 string을 다루기 위한 다양한 함수를 제공하는 패키지 입니다. 특히 서열에서의 패턴 탐색이나 Smith-Waterman local alignments, Needleman-Wunsch global alignments 등의 서열 비교함수를 제공하여 간단한 서열 분석에 자주 활용되는 패키지 입니다 (sippl1999biological?). Biostrings 패키지의 설치 방법은 아래와 같습니다.\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"Biostrings\")\n\n\nlibrary(Biostrings)\n\nBiostrings 패키지는 기본적으로 XString, XStringSet, XStringViews 3가지의 class를 정의하고 있습니다. XString은 DNA나 RNA, AA 등 생물학적 서열 한 가닥을 다루기위한 클래스이며 XStringSet은 여러 가닥을 다루기위한 클래스 입니다.\n\nDNAString 함수를 이용해서 객체를 만들어낼 수 있으며 ‘A’, ‘C’, ‘G’, ‘T’ 외에 ‘-’ (insertion), ‘N’ 을 허용합니다.\n\ndna1 &lt;- DNAString(\"ACGT?\")\ndna1 &lt;- DNAString(\"ACGT-N\")\ndna1[1]\ndna1[2:3]\n\ndna2 &lt;- DNAStringSet(c(\"ACGT\", \"GTCA\", \"GCTA\"))\ndna2[1]\ndna2[[1]]\ndna2[[1]][1]\n\n다음 내장변수 들은 Biostrings 패키지를 로드하면 자동으로 저장되는 변수들로 생물학적 서열을 미리 정의해 놓았습니다. IUPAC (International Union of Pure and Applied Chemistry, 국제 순수·응용 화학 연합)\n\nDNA_BASES\nDNA_ALPHABET\nIUPAC_CODE_MAP\nGENETIC_CODE\n\n\n위 변수들을 이용하면 다음처럼 sample() 함수를 이용해서 랜덤하게 DNA 서열을 얻을 수 있습니다. DNA_BASES가 4개 길이를 갖는 벡터인데 이 중 10개를 뽑으려면 replace=T로 해야 합니다.\n\nx0 &lt;- sample(DNA_BASES, 10, replace = T)\nx0\ns1 &lt;- \"ATG\"\ns2 &lt;- \"CCC\"\ns3 &lt;- paste(s1, s2, sep=\"\")\ns3\nx1 &lt;- paste(x0, collapse=\"\")\nx1\n\n관련 함수는 Cheat sheat 참고\n\n9.2.1 XString\nXString 클래스는 DNAString과 RNAString, AAString의 subclass로 나눌 수 있습니다. DNAString class에서 length 함수는 핵산의 갯수를 (DNAStringSet 타입의 변수에서 length는 DNA 가닥의 갯수) 계산하며 핵산의 갯수는 nchar함수로 얻어낼 수 있습니다. toString은 DNAString 타입을 단순 문자열로 변환해주는 함수이며 상보서열, 역상보서열 등의 정보도 complement, reverseComplement 등을 사용하여 찾아낼 수 있습니다.\n\nx0 &lt;- paste(sample(DNA_BASES, 10, replace = T), collapse=\"\")\nx1 &lt;- DNAString(x0)\nclass(x0)\nclass(x1)\nlength(x1)\ntoString(x1)\ncomplement(x1)\nBiostrings::complement(x1)\nreverseComplement(x1)\n\nDNAString의 인덱싱은 vector (string)과 같으며 DNAStringSet은 list의 인덱싱과 같습니다.\n\n## indexing\nx1[1]\nx1[1:3]\nsubseq(x1, start=3, end=5)\nsubseq(x1, 3, 5)\n\n## letter frequency\nalphabetFrequency(x1, baseOnly=TRUE, as.prob=TRUE)\nletterFrequency(x1, c(\"G\", \"C\"), as.prob=TRUE)\n\n\n\n\n\n\n\nExercises\n\n\n\n\n개시코돈과 스탑코돈을 포함한 30개 길이를 갖는 랜덤 유전자서열을 하나 만드시오\nAA_ALPHABET은 IUPAC에서 정의된 아미노산 서열 알파벳이 저장된 내장변수임. “M”과 “*”를 포함하는 10개 길이를 갖는 랜덤 유전자서열을 하나 만드시오\n\n\n\n\n\n9.2.2 XStringSet\nXStringSet역시 DNAStringSet, RNAStringSet, 그리고 AAStringSet으로 나눌 수 있으며 DNAStringSet class는 여러개의 DNAString 을 모아 놓은 집합이라고 보면 됩니다. length 함수는 DNA string의 갯수이며 width 또는 nchar 함수로 각 string의 길이를 구할 수 있으며 이 외 대부분의 DNAString 에서 사용되는 함수가 동일하게 사용될 수 있습니다.\n\nx0 &lt;- c(\"CTC-NACCAGTAT\", \"TTGA\", \"TACCTAGAG\")\nx1 &lt;- DNAStringSet(x0)\nclass(x0)\nclass(x1)\nnames(x1)\nnames(x1) &lt;- c(\"A\", \"B\", \"C\")\nlength(x1)\nwidth(x1)\nsubseq(x1, 2, 4)\nx1[[1]]\nx1[1]\n\n\nx3 &lt;- DNAString(\"ATGAGTAGTTAG\")\nx4 &lt;- c(x1, DNAStringSet(x3))\nx4[-1]\nx4\nalphabetFrequency(x1, baseOnly=TRUE, as.prob=TRUE)\nletterFrequency(x1, c(\"G\", \"C\"), as.prob=TRUE)\nrowSums(letterFrequency(x1, c(\"G\", \"C\"), as.prob=TRUE))\nsubseq(x4, 2, 4)\n\nRNA나 아미노산 역시 동일한 방식으로 적용 가능하며 c 함수를 이용해서 XStringSet으로 변환 가능합니다.\n\nx1 &lt;- paste(sample(AA_ALPHABET, 10, replace = T), collapse=\"\")\nx2 &lt;- paste(sample(AA_ALPHABET, 10, replace=T), collapse=\"\")\n\nx3 &lt;- AAString(x1)\nx4 &lt;- AAString(x2)\n\nAAStringSet(c(x1, x2))\nAAStringSet(c(x3, x4))\n\n\n\n\n\n\n\nExercises\n\n\n\n\n시작코돈과 종결코돈이 있는 길이 36bp 짜리 DNA (랜덤) 서열을 하나 만드시오\n\n\n위와 같은 랜덤서열 10개 만들어서 DNAStringSet으로 변환하시오\n\n\n\n아래는 가장 직관적으로 생각할 수 있는 for를 이용한 방법입니다. 즉, 10개 저장소를 갖는 x0 변수를 미리 생성해 두고 for 문을 돌면서 서열을 하나씩 만들어 저장하는 방법입니다.\n\nx0 &lt;- rep(\"\", 10)\nfor(i in 1:length(x0)){\n  tmp &lt;- paste(sample(DNA_BASES, 30, replace = T), collapse=\"\")\n  x0[i] &lt;- paste(\"ATG\", tmp, \"TAG\", sep=\"\")\n}\nx0\n\n위 코드를 함수로 만들어 보겠습니다. random dna를 만들 때 길이만 다를뿐 같은 코드를 반복해서 사용하고 있습니다. 이럴 경우 DNA 길이를 사용자가 정해주도록 input parameter로 하고 해당 파라메터를 받아 DNA를 만들어 주는 함수를 만들어 사용하면 편리합니다.\n\ndata(DNA_BASES)\nrandom_dna &lt;- function(len){\n  tmp &lt;- paste(sample(DNA_BASES, len, replace = T), collapse=\"\")\n  x0 &lt;- paste(\"ATG\", tmp, \"TAG\", sep=\"\")\n  return(x0)\n}\nrandom_dna(len=30)\nrandom_dna(len=40)\n\n파라메터로 넘겨진 len 값이 sample 함수의 len에 사용된 것을 참고하세요.\n이제 길이 30bp짜리 10개의 서열을 반복해서 만들 때 위 함수를 앞서와 같이 for문을 이용하여 10번 반복해서 실행해 주면 같은 결과를 얻습니다. 위와 같이 함수를 만들어 두면 언제든 DNA 서열을 만들 때 재사용 할 수 있습니다.\n\nx0 &lt;- rep(\"\", 10)\nfor(i in 1:length(x0)){\n  x0[i] &lt;- random_dna(30)\n}\nx0\n\n그런데 R에는 apply 와 같은 행렬연산 함수가 있어서 for문을 사용하지 않고 편리하게 반복문을 실행할 수 있습니다. replicate 함수는 apply와 같은 기능으로 list나 vector 변수에 대해서 사용할 수 있습니다. 즉, 다음과 같이 사용자가 원하는 함수를 반복해서 실행하고 반복 수 만큼의 길이를 갖는 결과를 반환합니다.\n\nx0 &lt;- replicate(10, random_dna(30))\nx0\nx1 &lt;- DNAStringSet(x0)\nx1\n\n\n위 생성한 10개 서열의 GC 비율을 계산하고 bar그래프를 그리시오\n\n위 x0 스트링들을 XStringSet으로 바꾸고 GC 비율을 구한 후 bargraph를 그리겠습니다. gc_ratio가 G와 C의 비율값을 저장한 10x2 테이블이므로 x축에 10개의 서열과 각 서열의 GC비율을 나타내고 y축에 비율 값을 그리는 것으로 생각한 후 ggplot의 aes와 파라메터를 적절히 지정해 줍니다.\nbar plot using ggplto2\n\nx1 &lt;- DNAStringSet(x0)\ngc_ratio1 &lt;- letterFrequency(x1, c(\"G\", \"C\"), as.prob=TRUE)\ngc_ratio2 &lt;- rowSums(gc_ratio1)\nbarplot(gc_ratio2, beside=T)\n\nnames(gc_ratio2) &lt;- paste(\"seq\", 1:length(gc_ratio2), sep=\"\")\nbarplot(gc_ratio2, beside=T)\n\ndata.frame(gc_ratio2) |&gt; \n  rownames_to_column() |&gt; \n  ggplot(aes(x=rowname, y=gc_ratio2, fill=rowname)) +\n  geom_bar(stat=\"identity\") +\n  scale_y_continuous(limits = c(0, 1)) +\n  scale_fill_brewer(palette = \"green\") +\n  theme_bw()\n\n\n\n9.2.3 XStringView\nBiostrings의 또 다른 class인 XStringView는 XString class의 DNA, RNA, AA서열을 사용자가 원하는대로 볼 수 있는 인터페이스를 제공합니다. 사용법은 다음과 같습니다.\n\nx2 &lt;- x1[[1]]\nViews(x2, start=1, width=20)\nViews(x2, start=1, end=4)\nViews(x2, start=c(1,3), end=4)\nViews(x2, start=c(1,3,4), width=20)\nViews(x2, start=c(1,3,4), width=20)\ni &lt;- Views(x2, start=c(1,3,4), width=20)\n\n다음과 같이 한 서열에 대한 여러 부분의 서열 조각도 볼 수 있으며 gaps 함수는 매개변수로 주어진 서열 view의 구간을 제외한 나머지 구간의 서열을 보여주는 함수입니다. successiveviews 함수는 처음 서열부터 매개변수 width에 주어진 갯수 만큼의 서열을 보여주며 rep() 함수를 이용해서 서열의 처음부터 끝까지 보여주는 기능을 합니다.\n\nv &lt;- Views(x2, start=c(1,10), end=c(3,15))\ngaps(v)\n\nsuccessiveViews(x2, width=20)\nsuccessiveViews(x2, width=rep(20, 2))\nsuccessiveViews(x2, width=rep(20, 3))\n\n\n\n\n\n\n\nExercises\n\n\n\n\n1000bp 길이의 랜덤 DNA 서열을 만들고 40bp 단위의 길이로 보는 코드를 작성하시오.\n\n\n\n앞서 만들어둔 random_dna() 함수를 사용하면 되며 successiveViews 함수를 사용해야 하므로 DNAString으로 변환이 필요하며 서열의 길이에 따라서 rep() 를 이용하여 반복 횟수를 자동 계산합니다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biostrings</span>"
    ]
  },
  {
    "objectID": "08-Biostrings.html#sequence-read-and-write",
    "href": "08-Biostrings.html#sequence-read-and-write",
    "title": "9  Biostrings",
    "section": "9.3 Sequence read and write",
    "text": "9.3 Sequence read and write\nBiostrings 패키지의 readDNAStringSet이나 writeXStringSet을 사용하면 기본 DNA/RNA/AA 서열의 읽고 쓰기가 가능하며 fasta와 fastq 등의 파일타입으로 적용이 가능합니다.\n\nx1 &lt;- DNAStringSet(x0)\nwriteXStringSet(x1, \"myfastaseq.fasta\", format=\"fasta\")\n\nnames(x1) &lt;- \"myfastaseq\"\nwriteXStringSet(x1, \"myfastaseq.fasta\", format=\"fasta\")\n\nmyseq &lt;- readDNAStringSet(\"myfastaseq.fasta\", format=\"fasta\")\nmyseq\n\nsuccessiveViews로 나눈 여러개의 DNA 조각을 myfastaseqs.fasta에 저장하고 다시 읽을 수 있습니다.\n\nmyseqs &lt;- DNAStringSet(sv)\nnames(myseqs) &lt;- paste(\"myseqs\", 1:length(myseqs), sep=\"\")\nwriteXStringSet(myseqs, \"myfastaseqs.fasta\", format=\"fasta\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biostrings</span>"
    ]
  },
  {
    "objectID": "08-Biostrings.html#sequence-statistics",
    "href": "08-Biostrings.html#sequence-statistics",
    "title": "9  Biostrings",
    "section": "9.4 Sequence statistics",
    "text": "9.4 Sequence statistics\noligonucleotideFrequency 는 width와 step 이라는 옵션에 따라서 해당 서열의 모든 핵산의 수를 세어주는 합수입니다. 다음에 사용되는 yeastSEQCHR1는 Biostrings 패키지에 포함된 내장 데이터로서 yeast의 첫 번째 염색체 정보를 담고 있습니다.\n\ndata(yeastSEQCHR1) #Biostrings\nyeast1 &lt;- DNAString(yeastSEQCHR1)\n\noligonucleotideFrequency(yeast1, 3)\ndinucleotideFrequency(yeast1)\ntrinucleotideFrequency(yeast1)\n\ntri &lt;- trinucleotideFrequency(yeast1, as.array=TRUE)\ntri\n\n아미노산 정보를 얻기 위해서 ORF를 찾아보겠습니다. yeast의 첫 번째 염색체에 대한 정보는 annotation이 되어 있지만 학습을 위해 툴을 사용하겠습니다. 이미 많은 종류의 ORF 탐색 툴이 나와있지만 본 강의에서는 NCBI에서 제공하는 orffinder를 사용하도록 하겠습니다.\n\n\nmy_ORFs &lt;- readDNAStringSet(\"yeast1orf.cds\")\nhist(nchar(my_ORFs), br=100)\ncodon_usage &lt;- trinucleotideFrequency(my_ORFs, step=3)\nglobal_codon_usage &lt;- trinucleotideFrequency(my_ORFs, step=3, simplify.as=\"collapsed\")\n\ncolSums(codon_usage) == global_codon_usage\nnames(global_codon_usage) &lt;- GENETIC_CODE[names(global_codon_usage)]\ncodonusage2 &lt;- split(global_codon_usage, names(global_codon_usage))\nglobal_codon_usage2 &lt;- sapply(codonusage2, sum) \n\nyeast 첫 번째 염색체에 대한 정보는 bioconductor annotationData OrgDb 또는 bioconductor annotationData TxDb 에서 찾아볼 수 있습니다.\n\n#BiocManager::install(\"org.Sc.sgd.db\")\nlibrary(org.Sc.sgd.db)\nclass(org.Sc.sgd.db)\n?org.Sc.sgd.db\nls(\"package:org.Sc.sgd.db\")\ncolumns(org.Sc.sgd.db)\nmykeys &lt;- keys(org.Sc.sgd.db, keytype = \"ENTREZID\")[1:10]\nAnnotationDbi::select(org.Sc.sgd.db, \n                      keys=mykeys, \n                      columns = c(\"ORF\",\"DESCRIPTION\"),\n                      keytype=\"ENTREZID\")\n\nTxDb\n\nBiocManager::install(\"TxDb.Scerevisiae.UCSC.sacCer3.sgdGene\")\nlibrary(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\nclass(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\ncolumns(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\nmethods(class=class(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene))\nygenes &lt;- genes(TxDb.Scerevisiae.UCSC.sacCer3.sgdGene)\n\n\nlibrary(tidyverse)\n\nmydat &lt;- global_codon_usage2 |&gt; \n  data.frame |&gt; \n  rownames_to_column |&gt; \n  rename(codon = \"rowname\", freq = \".\") \n\nggplot(mydat, aes(x=codon, y=freq)) +\n  geom_bar(stat=\"identity\") \n\nmydat\nAMINO_ACID_CODE[mydat$codon]\n\n\n\n\n\n\n\nExercises\n\n\n\n\nAMINO_ACID_CODE를 이용해서 위 그래프의 1약자를 3약자로 변환, 라벨을 세로로 90도 회전, y축 라벨 “Frequency”, x축 라벨 “Amino acid code”, theme 옵션 “theme_bw” 등을 적용하여 다시 그림을 그리시오 (revisit ggplot2)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biostrings</span>"
    ]
  },
  {
    "objectID": "08-Biostrings.html#pattern-matching",
    "href": "08-Biostrings.html#pattern-matching",
    "title": "9  Biostrings",
    "section": "9.5 Pattern matching",
    "text": "9.5 Pattern matching\nBiostrings 패키지에는 하나의 subject 서열에 특정 pattern이 존재하는지 탐색하는 matchPattern함수를 제공합니다. 만약 여러개의 subject 서열에서 하나의 pattern을 찾을 경우에는 vmatchPattern함수를 사용하고 하나의 subject 서열에 여러개의 pattern을 찾는 경우에는 matchPDict 함수를 사용합니다.\n\nlength(coi)\nhits &lt;- matchPattern(\"ATG\", yeast1, min.mismatch=0, max.mismatch=0)\nhits\nclass(hits)\nmethods(class=\"XStringViews\")\nranges(hits)\n\nhits &lt;- vmatchPattern(\"ATG\", my_ORFs, min.mismatch=0, max.mismatch=0)\nstack(hits)\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Biostrings</span>"
    ]
  },
  {
    "objectID": "09-toolsforsequences.html",
    "href": "09-toolsforsequences.html",
    "title": "10  Tools for sequences",
    "section": "",
    "text": "10.1 Retrive and download sequences from NCBI\n전세계 연구자들이 서열 데이터를 분석하는데 가장 많이 이용하는 사이트 중 하나가 NCBI 이며 따라서 NCBI에서는 연구자들이 데이터베이스에 접근하기위한 편리한 방법을 제공하고 있고 그 중 하나가 Entrez 입니다.\nR에서도 Entrez 기능을 도입한 package들이 제공되고 있으며 그 중 하나가 rentrez 입니다. https://www.ncbi.nlm.nih.gov/books/NBK25500/ 이 곳의 Downloading Full Records 를 참고하시면 좋습니다. Entrez는 대략적으로 다음 9개의 유틸리티를 제공합니다.\n이 중 ESerach, EPost, ESummary, EFetch 등이 많이 사용하는 유틸이며 정보를 다운로드 받을 경우는 EFetch 를 주로 사용하게 됩니다. rentrez 는 위와 같은 NCBI Eutils API를 활용하여 R 환경에서 탐색이나 다운로드 등 NCBI 데이터베이스와 상호작용이 용이하도록 만들어 놓은 tool 입니다. rentrez landing page entrez_dbs명령은 NCBI에서 제공하는 데이터베이스의 리스트를 볼 수 있으며 특정 DB에 대한 설명은 entrez_db_summary를 사용하면 되겠습니다. entrez_search는 각종 키워드를 사용한 검색 기능을 제공합니다.\nlibrary(rentrez)\nrequire(Biostrings)\n\nentrez_dbs()\nentrez_db_summary(\"nuccore\")\n\ncovid_paper &lt;- entrez_search(db=\"pubmed\", term=\"covid19\")\ncovid_paper$ids\n\nnames(covid_paper)\ncovid_paper$ids\n\n\ncovid_link &lt;- entrez_link(db=\"all\", id=covid_paper$ids, dbfrom=\"pubmed\")\nnames(covid_link)\nnames(covid_link$links)\nhead(covid_link$links$pubmed_pubmed)\nentrez_search에서 검색어를 입력하는 방식은 이곳을 참고하세요. 검색으로 찾아진 특정 오브젝트(객체)에 대한 내용은 entrez_summary 함수를 사용하여 조회할 수 있으며 extract_from_esummary로 조회된 아이템들에 대한 정보를 추출할 수 있습니다. 특정 id에 대한 서열 등 다양한 타입의 데이터를 실제로 다운로드 받는 기능은 entrez_fetch 함수가 제공하고 있습니다. entrez_fetch 함수의 rettype 옵션에서 지원하는 데이터 타입을 다운로드 받을 수 있으며 rettype (return type)의 자세한 정보는 Eutils table 또는 NCBI Eutils 페이지를 참고하시기 바랍니다.\n# popset database is a collection of related DNA sequences derived from population\nkatipo_search &lt;- entrez_search(db=\"popset\", term=\"Latrodectus katipo[Organism]\")\nkatipo_search$ids\n\nkatipo_summs &lt;- entrez_summary(db=\"popset\", id=katipo_search$ids)\nnames(katipo_summs)\nkatipo_summs$`41350664`\nclass(katipo_summs)\nmethods(class=\"esummary_list\")\n\ntitles &lt;- extract_from_esummary(katipo_summs, \"title\")\nunname(titles)\n\nprint(katipo_summs)\nkatipo_summs$`1790798044`$gi\n\n\nCOI_ids &lt;- katipo_search$ids[c(2,6)]\ntrnL_ids &lt;- katipo_search$ids[4]\nCOI &lt;- entrez_fetch(db=\"popset\", id=COI_ids, rettype=\"fasta\")\ntrnL &lt;- entrez_fetch(db=\"popset\", id=trnL_ids, rettype=\"fasta\")\n\nwrite(COI, \"examples/COI.fasta\")\nwrite(trnL, \"examples/trnl.fasta\")\n\n#library(Biostrings)\ncoi &lt;- readDNAStringSet(\"examples/COI.fasta\")\ntrnl &lt;- readDNAStringSet(\"examples/trnl.fasta\")\n여러 데이터베이스의 ID는 혼동되는 부분 중 하나입니다. nuccore 데이터베이스는 여러 DB 소스로부터 모아둔 서열 DB이며 sequence identifier관련 내용은 sequenceid 와 version을 참고해 보시기 바랍니다.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Tools for sequences</span>"
    ]
  },
  {
    "objectID": "09-toolsforsequences.html#retrive-and-download-sequences-from-ncbi",
    "href": "09-toolsforsequences.html#retrive-and-download-sequences-from-ncbi",
    "title": "10  Tools for sequences",
    "section": "",
    "text": "카이스트 강의\n\n\n\n\nrentrez 사용법 이해\nnuccore 데이터베이스로부터 정보 다운로드\n\n\n\n\n\n\nEInfo (database statistics)\nESearch (text searches)\nEPost (UID uploads)\nESummary (document summary downloads)\nEFetch (data record downloads)\nELink (Entrez links)\nEGQuery (global query)\nESpell (spelling suggestions)\nECitMatch (batch citation searching in PubMed)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n뎅기바이러스 서열 4종에 대한 NCBI의 accession 번호가 다음과 같음 NC_001477, NC_001474, NC_001475, NC_002640 해당 DNA 서열을 fasta 형식으로 nuccore 데이터베이스에서 다운로드 하시오. (참고로 strwrap 함수 사용법을 익혀두면 좋습니다)\n\n##\nacc &lt;- c(\"NC_001477\", \"NC_001474\", \"NC_001475\", \"NC_002640\")\nall_recs &lt;- entrez_fetch(db=\"nuccore\", id=acc[1:2], rettype=\"fasta\")\nall_recs\nwrite(all_recs, file=\"mydang.fasta\")\ndang &lt;- readDNAStringSet(\"mydang.fasta\", format=\"fasta\")\n\ncat(strwrap(substr(all_recs, 1, 500)), sep=\"\\n\")\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\npopset 데이터베이스에서 “Covid-19” 단어가 들어간 유전자 40개를 찾고 (entrez_search에서 retmax=40 옵션 사용) 이들의 요약 정보 중 title 속성을 출력하시오 (entrez_summary와 extract_from_esummary 함수 사용).\n위 결과에서 찾아진 유전자들 각각이 몇 개의 서열 샘플에 (population) 대해서 연구된 것인지 각각의 서열을 fasta 형태로 다운로드 받고 샘플의 개수에 대한 barplot을 그리시오\n\nsummary_record 결과를 받아서 extract_from_esummary로 title을 추출 후 data.frame으로 변환\ntidyverse의 rownames_to_column() 함수로 uid 정보 변수로 변환, mydata 이름으로 저장\nentrez_fetch 함수로 모든 uid에 대한 샘플 서열 fasta 파일 다운로드 후 파일 저장 (write함수 사용)\nreadDNAStringSet 함수로 읽은 후 앞서 title 정보 비교를 통해서 앞서 mydata 와 병합\n각 uid 별로 몇 개의 서열 샘플이 있는지 정보를 추출 후 barplot 그리기\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\nComparative sequence analysis of SARS-CoV-2 suggests its high transmissibility and pathogenicity 논문을 참고하여 COVID-19 서열의 NCBI accession 번호를 찾고 nuccore 데이터베이스에서 fasta 포멧과 genbank 포멧의 정보를 다운로드 하시오. (데이터는 “covid_table.csv” 파일에 저장되어 있음)\n\ncovid &lt;- data.frame(\nspecies = c(rep(\"Human\", 7), c(\"Civet\", \"Civet\"), rep(\"Bat\", 3), \"Pangolin\"),\ncoronavirus = c(\"SARS-CoV-2\", \"SARS-CoV-2\", \"SARS-CoV-1\", \"SARS-CoV-1\", \"SARS-CoV-1\", \"H-CoV-OC43\", \"MERS-CoV\", \"SARS-CoV\", \"SARS-CoV\", \"SL-CoV\", \"SL-CoV\", \"SL-CoV\", \"SL-CoV\"),\nisolate = c(\"Wuhan Hu-1\", \"USA-WA-1\", \"Urbani\", \"Tor2\", \"GD03T10013\", \"UK/London\",  \"EMC-2012\", \"SZ3\", \"Civet007\", \"ZXC21\", \"WIV16\", \"RaTG13\", \"MP789\"),\nyear = c(\"2020\", \"2020\", \"2002\", \"2002\", \"2003\", \"2011\", \"2011\", \"2003\", \"2004\", \"2015\", \"2013\", \"2013\", \"2020\"),\ngbacc = c(\"NC_045512.2\", \"MN985325.1\", \"AY278741.1\", \"AY274119.3\", \"AY525636.1\", \"KU131570.1\", \"NC_019843.3\", \"AY304486.1\", \"AY572034.1\", \"MG772934.1\", \"KT444582.1\", \"MN996532.1\", \"MT084071.1\"))\nwrite.csv(covid, file = \"examples/covid_table.csv\", quote = F, row.names=F)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Tools for sequences</span>"
    ]
  },
  {
    "objectID": "09-toolsforsequences.html#align-two-sequences",
    "href": "09-toolsforsequences.html#align-two-sequences",
    "title": "10  Tools for sequences",
    "section": "10.2 Align two sequences",
    "text": "10.2 Align two sequences\n서열 정렬은 match, mismatch, penalty 등의 scoring rule을 기반으로 최적의 score를 갖는 서열 정렬을 찾는 알고리즘 입니다. Biostrings 패키지에는 두 개의 서열에 대해 local, global alignment를 수행할 수 있는 pairwiseAlignment 함수를 제공하고 있습니다. 첫 번째 파라메터는 pattern이며 두 번째는 subject 로서 pattern은 query로서 해당 서열이 subject (target)에 있는지를 보는 것과 같습니다.\n\ncovid19seq\n\n?pairwiseAlignment\naln &lt;- pairwiseAlignment(covid19seq[1], covid19seq[2])\nclass(aln)\nmethods(class=\"PairwiseAlignmentsSingleSubject\")\n?PairwiseAlignmentsSingleSubject\n\n위에서 서열 정렬이 된 결과를 DNAString class의 변수에 저장한 후 해당 class에서 제공하는 다양한 함수를 동일하게 적용할 수 있습니다. 또한 writePairwiseAlignments 함수는 두 서열의 비교 결과를 보기 좋게 출력해주는 기능을 수행합니다. summary 함수를 사용하면 염기가 다른 곳의 위치를 출력해주며 consensusString은 50% 초과하는 서열에 대한 문자열을 출력해 줍니다. 이 외에도 score, consensusMatrix 등 다양한 help 함수들이 있습니다.\n\nalnseqs &lt;- c(alignedPattern(aln), alignedSubject(aln))\nclass(alnseqs)\n\naln\n\nwritePairwiseAlignments(aln, block.width=50)\nwritePairwiseAlignments(aln, file=\"examples/covidalign.txt\",  block.width=30)\n\nsummary(aln)\n\nconsensusMatrix(aln)[1:4,1:10]\nconsensusString(aln)\n\nscore(aln)\n\n참고로 아래와 같이 별도의 정보 테이블을 만들고 서열의 이름은 간단히 id 만 사용해서 분석하는 것이 더 효율적입니다. 문자열을 다루는 코드를 익혀두시기 바랍니다.\n\nnames(covid19seq)\n\nids &lt;- strsplit(names(covid19seq), split=\" \") %&gt;% \n  lapply(function(x){x[1]}) %&gt;% \n  unlist\n\ntitles &lt;- strsplit(names(covid19seq), split=\" \") %&gt;% \n  lapply(function(x){\n    paste(x[-1], collapse=\" \")\n    }) %&gt;% \n  unlist\n\ncovid19info &lt;- data.frame(ids, titles)\nnames(covid19seq) &lt;- covid19info$ids\n\naln &lt;- pairwiseAlignment(covid19seq[1], covid19seq[2])\nwritePairwiseAlignments(aln, block.width=50)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Tools for sequences</span>"
    ]
  },
  {
    "objectID": "09-toolsforsequences.html#multiple-sequence-alignment",
    "href": "09-toolsforsequences.html#multiple-sequence-alignment",
    "title": "10  Tools for sequences",
    "section": "10.3 Multiple sequence alignment",
    "text": "10.3 Multiple sequence alignment\nMultiple sequence alignment(MSA) tool은 서열 데이터의 양과 계산량의 문제로 linux 기반 commandline 프로그램들이 많습니다. 대표적으로 CLUSTAL-Omega, MUSCLE. window 기반 환경에서는 docker 등을 활용해서 관련 분석을 수행할 수 있습니다.\n\n10.3.1 msa\nmsa 패키지는 위 Clustal나 MUSCLE 등의 프로그램에 대한 R 인터페이스를 제공하며 Linux 뿐만 아니라 모든 운영체제에서 수행될 수 있도록 만들어 둔 패키지 입니다.\n\nrequire(Biostrings)\nrequire(kableExtra)\n\ndownload.file(url = \"https://raw.githubusercontent.com/greendaygh/kribbr2022/main/covid_table.csv\", destfile = \"examples/covid_table2.csv\")\n\ncovid19 &lt;- read.csv(\"examples/covid_table2.csv\")\nrecs &lt;- entrez_fetch(db=\"nuccore\", id=covid19$gbacc, rettype=\"fasta\")\nwrite(recs, file=\"examples/covid19.fasta\")\ncovid19seq &lt;- readDNAStringSet(\"examples/covid19.fasta\", format=\"fasta\")[1:4]\nsubcovid19seq &lt;- subseq(covid19seq, 1, 2000)\n\n\nlibrary(msa)\n\nalnmsa &lt;- msa(subcovid19seq)\nclass(alnmsa)\nalnmsa\n\nprint(alnmsa, show=\"complete\")\n?msaPrettyPrint\nmsaPrettyPrint(alnmsa, output=\"pdf\", showNames=\"none\", showLogo=\"top\", askForOverwrite=FALSE, verbose=FALSE)\nmyconseq &lt;- msaConsensusSequence(alnmsa)\n\n참고로 정렬된 서열 출력물에 표시되는 ?는 판단하기 모호한 위치를 나타냅니다. 예를 들어 A와 T 가 5:5로 나타난 위치는 ?로 표시됩니다.\nMsaDNAMultipleAlignment class는 Biostring 패키지의 DNAString class를 상속받은 클래스로서 다음과 같이 DNAStringSet class로 변환해서 분석도 가능합니다.\n\nalnseq &lt;- DNAStringSet(aln)\nclass(alnseq)\nalnseq\nmyconseq2 &lt;- ConsensusSequence(alnseq)\n\n위 alignment 결과에서 관심있는 특정 위치만을 선택해서 임의의 분석을 수행하고 싶은 경우 마스킹 함수를 사용할 수 있습니다. 이 기능 역시 MsaDNAMultipleAlignment class는 Biostring 패키지의 DNAString class 모두에 적용이 가능합니다. IRanges 함수는 뒤에서 더 상세히 설명하도록 하겠습니다.\n\ncolM &lt;- IRanges(start=1, end=300)\ncolmask(alnmsa) &lt;- colM\nalnmsa\nmsaConsensusSequence(alnmsa)\nalphabetFrequency(alnmsa)\n\nalphabetFrequency(unmasked(alnmsa))\n\n\n\n10.3.2 DECIPHER\nDECIPHER 패키지는 서열 alignment나 primer design 등을 수행할 수 있는 패키지로 다음과 같이 별도 메모리에 서열을 저장하고 빠르게 alignment를 수행할 수 있어서 중소 규모의 서열에 대한 분석으로 유용하게 사용될 수 있습니다. 다음은 관련 서열을 SQLite 데이터베이스에 저장하고 그 내용을 쉽게 볼 수 있는 기능들 입니다. dbDisconnect 함수를 실행하면 모든 저장된 데이터가 사라지며 매모리는 다시 사용할 수 있게 됩니다.\n\nlibrary(DECIPHER)\n\ndbConn &lt;- dbConnect(SQLite(), \":memory:\")\nSeqs2DB(covid19seq, \"XStringSet\", dbConn, \"covid19\")\nBrowseDB(dbConn)\n\nl &lt;- IdLengths(dbConn)\nAdd2DB(l, dbConn)\nBrowseDB(dbConn)\n\n\nkatipo_search &lt;- entrez_search(db=\"popset\", term=\"Latrodectus katipo[Organism]\")\ntrnL_ids &lt;- katipo_search$ids[4]\ntrnL &lt;- entrez_fetch(db=\"popset\", id=trnL_ids, rettype=\"fasta\")\nwrite(trnL, \"examples/trnl.fasta\")\ntrnl &lt;- readDNAStringSet(\"examples/trnl.fasta\")\n\nSeqs2DB(trnl, \"XStringSet\", dbConn, identifier = \"trnl\")\nBrowseDB(dbConn)\n\ndbDisconnect(dbConn)\n\n다중서열을 정렬하는 AlignSeqs 함수와 BrowseSeqs 함수를 활용해서 html 형태로 정렬된 서열을 볼 수 있습니다. 특히 patterns 옵션을 사용해서 원하는 서열이 존재하는지도 확인할 수 있습니다.\n\n## extract sequences\ncovid19seq2 &lt;- SearchDB(dbConn, identifier = \"covid19\")\nsubcovid19seq &lt;- subseq(covid19seq2, 1, 2000)\naln &lt;- AlignSeqs(subcovid19seq)\naln\nclass(aln)\n\nBrowseSeqs(aln, colWidth = 100)\nBrowseSeqs(aln, colWidth = 100, patterns=DNAStringSet(c(\"ACTG\", \"CSC\")))\nBrowseSeqs(aln, colWidth = 100, patterns=\"-\", colors=\"black\")\n?BrowseSeqs\n\naln2 &lt;- AlignTranslation(subcovid19seq, type=\"AAStringSet\")\nBrowseSeqs(aln2, colWidth = 100)\nBrowseSeqs(aln2, colWidth = 100, highlight=1)\n\nAlignSeqs함수의 결과가 DNAStringSet 클래스이므로 앞서 수행한 마스킹 등의 기능을 동일하게 적용 가능합니다.\nDECIPHER 패키지의 DigestDNA함수를 이용하면 enzyme digestion을 시뮬레이션할 수 있는 기능을 활용할 수 있습니다. 단 숫자 등 필요없는 문자를 제거하기 위해서 stringr 패키지를 사용합니다.\n\ndata(RESTRICTION_ENZYMES)\nRESTRICTION_ENZYMES\nrsite &lt;- RESTRICTION_ENZYMES[\"BsmBI\"]\nrsite &lt;- RESTRICTION_ENZYMES[\"BsaI\"]\n\nd &lt;- DigestDNA(rsite, covid19seq2[1])\nunlist(d)\n#writeXStringSet(unlist(d), file=\"covid19bsmbi.fasta\")\npos &lt;- DigestDNA(rsite, covid19seq2[1], type=\"positions\")\nunlist(pos)\n\n\nlibrary(stringr)\nlibrary(stringi)\n\n\nBrowseSeqs(covid19seq2[1], colWidth = 100, patterns=rsite)\nsub(\"(^[[:alpha:]]*).*\", \"\", rsite)\n\nrsite2 &lt;- paste(str_extract_all(rsite, \"[[A-Z]]\", simplify = T), collapse=\"\")\nrsite3 &lt;- as.character(reverseComplement(DNAString(rsite2)))\nBrowseSeqs(covid19seq2[1], colWidth = 100, patterns=c(rsite2, rsite3))\n\n\n\n\n\n\n\nExercises\n\n\n\n\n앞서 다운로드 받은 Latrodectus katipo 서열 데이터를 읽어들이고 100bp 단위로 출력하시오\nMSA 를 수행하고 정렬된 결과를 100bp 단위로 출력하시오\nConsensusSequence 함수를 이용하여 정렬된 결과로부터 consensus 서열을 추출하시오\n\n\ncoi &lt;- readDNAStringSet(\"COI.fasta\")\nBrowseSeqs(coi)\nalignedcoi &lt;- AlignSeqs(coi)\nBrowseSeqs(alignedcoi)\nclass(alignedcoi)\n\nconseq &lt;- ConsensusSequence(alignedcoi)\n\n\n\n참고로 염기와 아미노산의 Standard Ambiguity Codes는 각각 다음과 같습니다.\n\nDNA ambiguity code \nAmino acid ambiguity code",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Tools for sequences</span>"
    ]
  },
  {
    "objectID": "09-toolsforsequences.html#phylogenetic-trees-with-clustering",
    "href": "09-toolsforsequences.html#phylogenetic-trees-with-clustering",
    "title": "10  Tools for sequences",
    "section": "10.4 Phylogenetic trees with clustering",
    "text": "10.4 Phylogenetic trees with clustering\n다중서열비교 결과는 계통학에서 널리 쓰이며 msa나 DECIPHER 패키지에서 얻어진 결과를 계통학의 tree 형태로 가시화할 수 있습니다. tree 형태의 가시화를 위해 다양한 포멧의 파일이 개발되었고 treeio 패키지는 이들 다양한 포맷의 파일을 쉽게 변환하기 위해 만들어진 패키지 입니다. 다음은 Newick tree 포멧의 예 입니다.\n    ((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59); \n가장 널리 사용되는 포멧은 phylo 형태로서 이는 ape라는 phylogenetic 분석의 대표적인 패키지에서 처음 제안되어 사용되고 있습니다. 최근 ggplot 형태의 ggtree, reference이 개발되어 계통도를 좀더 세밀하게 그릴 수 있으며 ggtree는 phylo 형태의 포맷을 주로 사용합니다.\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\n\nBiocManager::install(\"ggtree\")\n#BiocManager::install(\"treeio\")\n\nPhylogenetic tree는 서열간의 유사도(거리)를 기반으로 분석할 수 있습니다. 앞서 사용한 mas나 DECIPHER 패키지로 얻어진 MSA 결과는 모두 Biostrings 패키지의 XStringSet (DNAStringSet, AAStringSet 등) 클래스 입니다. 따라서 XStringSet의 거리를 계산해주는 Biostrings::stringDist 함수나 DECIPHER::DistanceMatrix가 사용될 수 있습니다. 참고로 phylo class는 as.tibble 함수를 이용해서 테이블 형태로 변환, 활용할 수 있습니다.\n\nlibrary(ape)\nlibrary(ggtree)\n\nalnmsa &lt;- msa(subcovid19seq)\nmydist &lt;- stringDist(DNAStringSet(alnmsa))\nclust &lt;- hclust(mydist)\nclass(clust)\n\nmytree &lt;- as.phylo(clust)\nggtree(mytree, layout=\"circular\") +\n  geom_tiplab()\n\nas.tibble(mytree)\n\nDECIPHER 패키지에는 XStringSet 서열의 거리를 계산해주는 DistanceMatrix 함수가 있습니다. 이 함수를 이용하면 역시 같은 패키지에서 제공하는 IdClusters 함수를 이용해서 유사한 서열끼리 묶어주는 tree 를 만들 수 있습니다. dendrogram는 str 함수 활용이 가능합니다.\n\ndm &lt;- DistanceMatrix(subcovid19seq)\nclass(dm)\n\nclust &lt;- IdClusters(dm, cutoff=10, method=\"NJ\", showPlot=F, type=\"dendrogram\")\nclass(clust)\nmethods(class=\"dendrogram\")\nplot(clust)\nstr(clust)\n\ndendrogram class는 hclust를 거처 phylo class 형태로 변환 후 ggtree 패키지를 활용할 수 있습니다.\n\n## convert to dendrogram -&gt; hclust -&gt; phylo \ncl &lt;- as.hclust(clust)\npy &lt;- as.phylo(cl)\nclass(py)\nggtree(py)\nas.tibble(py)\n\nggtree를 활용하면 다양한 레이아웃을 활용할 수 있고 레이아웃에 대한 정보는 Layouts of a phylogenetic tree 이 곳을 참고하시면 되겠습니다.\n\ntree &lt;- rtree(n = 20)\nggtree(tree)\n\nggplot(tree) +\n  geom_tree() +\n  theme_tree()\n\nggtree(tree, branch.length=\"none\")\n\nggtree(tree, layout=\"circular\") +\n  geom_tiplab(color=\"firebrick\")\n\nggtree(tree, layout=\"circular\") +\n  geom_tiplab(size=3, aes(angle=angle))\n\nggtree(tree, layout=\"circular\", branch.length=\"none\") +\n  geom_tiplab(size=3, aes(angle=angle))\n\nggtree(tree) +\n  theme_tree2() \n\nggtree(tree, layout=\"circular\") +\n  geom_tiplab() + \n  theme(plot.margin = unit(c(100,30,100,30), \"mm\"))\n\nggsave(\"myphylo.pdf\", width = 50, height = 50, units = \"cm\", limitsize = FALSE)\n\ncovid19 example\n\ncovid19seq &lt;- readDNAStringSet(\"covid19.fasta\", format=\"fasta\")[1:6]\nsubcovid19seq &lt;- subseq(covid19seq, 1, 2000)\nnames(subcovid19seq)  &lt;- sapply(strsplit(names(subcovid19seq), \" \"), function(x){return(x[1])})\n  \nalnmsa &lt;- msa(subcovid19seq)\nmydist &lt;- stringDist(DNAStringSet(alnmsa))\nclust &lt;- hclust(mydist)\nmytree &lt;- as.phylo(clust)\n\nggtree(mytree, layout=\"circular\") +\n  geom_tiplab(color=\"firebrick\", size=3)\n\nggtree(mytree) +\n  geom_tiplab(color=\"firebrick\", size=3) +\n  theme_tree2(scale=0.1) \n\n특정 그룹을 highlight 하기 위해서 geom_hilight 함수를 사용합니다.\n\nggtree(tree) +\n  theme_tree2() +\n  geom_tiplab() +\n  geom_hilight(node=20, fill=\"steelblue\", alpha=.4) \n\n노드를 알아보기 위해서 tidytree를 사용할 수 있습니다.\n\nas.tibble(tree)\n\nd &lt;- data.frame(node=c(20, 20, 22), type=c(\"T1\", \"T1\", \"T2\"))\n\nggtree(tree) +\n  theme_tree2() +\n  geom_tiplab() +\n  geom_hilight(d, aes(node=node, fill=type), alpha=.4) +\n  scale_fill_manual(values=c(\"steelblue\", \"darkgreen\"))\n\n\n10.4.1 Facet Utilities\ngeom_facet 와 facet_widths 를 사용하면 추가 판넬에 tree를 그릴 수 있습니다.\n\ntree &lt;- rtree(30)\n\np &lt;- ggtree(tree, branch.length = \"none\") + \n  geom_tiplab() + \n  theme(legend.position='none')\n\na &lt;- runif(30, 0,1)\nb &lt;- 1 - a\ndf &lt;- data.frame(tree$tip.label, a, b)\ndf2 &lt;- pivot_longer(df, -tree.tip.label)\n\np2 &lt;- p + geom_facet(panel = 'bar', data = df2, geom = geom_bar, \n                 mapping = aes(x = value, fill = as.factor(name)), \n                 orientation = 'y', width = 0.8, stat='identity') + \n        xlim_tree(9)\n\nfacet_widths(p2, widths = c(1, 2))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Tools for sequences</span>"
    ]
  },
  {
    "objectID": "09-toolsforsequences.html#blast-result-analysis",
    "href": "09-toolsforsequences.html#blast-result-analysis",
    "title": "10  Tools for sequences",
    "section": "10.5 BLAST result analysis",
    "text": "10.5 BLAST result analysis\nBLAST를 로컬컴퓨터에 설치하거나 docker를 이용해서 활용할 수 있으나 본 강의에서는 직접 BLAST를 수행하는 대신 NCBI에서 실행한 BLAST 출력물을 분석하는 경우에 대해서 설명을 진행하겠습니다. 예시로는 PET를 분해하는 단백질로 알려진 IsPETase의 서열과 유사한 서열을 찾아서 분석해 보겠습니다. IsPETase 정보는 다음과 같습니다 Genes encoding I. sakaiensis 201-F6 IsPETase (WT PETase) (accession number: A0A0K8P6T7).\n\n\n\n\n\n\nExercises\n\n\n\n\nNCBI BLAST 사이트에서 A0A0K8P6T7 단백질에 대한 BLASTp를 수행하시오 (db: nr)\n결과물을 (100개) 다운로드 하고 (fasta와 hit table 각 1개 파일씩) 작업디렉토리로 복사하시오\nfasta 와 hit 데이터를 각각 읽어들이시오\n\n\n100개의 서열을 DECIPHER 패키지를 활용해서 정렬하고 100bp 단위로 출력해보시오\n\n\nalign된 결과에서 consensus 서열을 추출하고 각 위치별로 어떤 아미노산이 많은지 bar 그래프를 그려보시오\n\n\nalign된 결과를 ggtree 패키지를 사용해서 phylogenetic를 그리시오\n\n\n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Tools for sequences</span>"
    ]
  },
  {
    "objectID": "10-tools-for-genome-analysis.html",
    "href": "10-tools-for-genome-analysis.html",
    "title": "11  Tools for genome",
    "section": "",
    "text": "11.1 genbank file\ngenbank 파일은 DNA 및 단백질 서열을 저장하는데 사용되는 서열 파일 포맷으로서 하나 이상의 시퀀스에 대한 정보와, 주석, 특정 서열 구간의 feature 정보와 메타 데이터도 포함합니다. NCBI에서 개발했으며 표준 DNA 및 단백질 서열 파일 형식으로 공공 데이터베이스 등 널리 사용되고 있습니다. R의 genbankr 패키지는 genbank 타입의 데이터를 읽는 readGenBank 함수를 제공합니다.\nGenBankRecord 클래스 객체에 getSeq 함수 (BSgenome 패키지, 대부분 자동 로딩) 사용하면 whole genome 서열을 얻을 수 있습니다.\nrequire(genbankr)\n\ncovid19 &lt;- readGenBank(\"examples/covid19wuhan.gb\")\ncovid19\nclass(covid19)\nmethods(class=\"GenBankRecord\")\ncds(covid19)\nexons(covid19)\n\ncovid19seq &lt;- getSeq(covid19)\ncovid19seq",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tools for genome</span>"
    ]
  },
  {
    "objectID": "10-tools-for-genome-analysis.html#genbank-file",
    "href": "10-tools-for-genome-analysis.html#genbank-file",
    "title": "11  Tools for genome",
    "section": "",
    "text": "카이스트 강의\n\n\n\n\nGenbank 파일 다운로드, 서열정보, feature 정보 추출\ngetSeq 함수 사용\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nNC_045512.2는 우한에서 발생한 코로나바이러스의 accession number임. entrez_fetch 함수를 사용하여 nuccore 데이터베이스에서 genbank 정보를 다운로드 받으시오\n받은 택스트를 covid19wohan.gb라는 파일로 저장하시오\n\n\nrequire(rentrez)\n\nrecs &lt;- entrez_fetch(db=\"nuccore\", id=\"NC_045512.2\", rettype=\"gb\")\nwrite(recs, file=\"examples/covid19wuhan.gb\")",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tools for genome</span>"
    ]
  },
  {
    "objectID": "10-tools-for-genome-analysis.html#iranges",
    "href": "10-tools-for-genome-analysis.html#iranges",
    "title": "11  Tools for genome",
    "section": "11.2 IRanges",
    "text": "11.2 IRanges\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nIRanges 구조와 활용법 이해\n\n\n\n유전체 데이터의 대부분을 차지하는 정보는 전체 지놈 서열 중 어디서 어디까지가 유전자 또는 coding sequence 이고 그 번역된 정보가 무엇인지 설명하는 정보 입니다. 즉, 일련의 feature에 대한 위치와 특성 정보를 분석하는 것이 효율적인 지놈을 분석하기 위해 필수입니다. bioconductor 에서는 이러한 유전체 정보를 효율적으로 분석하고 가시화 하기위한 방법들이 다양하게 개발되어 왔으며 IRanges 와 GenomicRanges 라는 패키지가 대표적으로 사용될 수 있습니다.\nIRanges는 간격을 나타내는 임의의 숫자 세트이며 지놈상에 위치한 특정 feature들의 간격이나 통계적 수치들을 효율적으로 나타내기 위해서 만들어진 패키지 입니다 (Lawrence2013?). 임의의 feature에 대한 시작, 끝, 넓이를 나타내는 숫자들이 리스트로 이루어져 있습니다.\n\nlibrary(IRanges)\n\nir &lt;- IRanges(start = c(1,3,5), end = c(3,5,7))\nir\n\nir &lt;- IRanges(start = 1:10, width = 10:1)\nir\nclass(ir)\nmethods(class=\"IRanges\")\n?IRanges\n\nIRange 는 Rle (run-length encoding format, 런 렝스 부호화) class 를 사용하며 일종의 압축 방법입니다. 예를 들어 GATTGCCCCCCTAG 라는 서열이 있다고 하면 이를 그대로 text 파일에 저장하지 않고 GAT2GC6TAG 라고 표현함으로써 용량을 줄이는 압축의 기능을 합니다. GenomicRange는 이러한 Rle 개념을 사용하기 위해서 Rle라는 기본 함수를 사용합니다.\n\nlibrary(IRanges)\n\nx &lt;- \"GATTGCCCCCCTAG\"\ny &lt;- unlist(strsplit(x, split=\"\"))\nyrle &lt;- Rle(y)\nyrle\n\nrunLength(yrle)\nrunValue(yrle)\nnrun(yrle)\n\nx &lt;- Rle(values = c(1:3), lengths = c(1:3))\nx\nclass(x)\n#methods(class=\"Rle\")\n\n# convert Rle to IRanges\nxrange &lt;- IRanges(start(x), end(x))\nxrange\n\nIRange 생성과는 반대로 IRange 객체로부터 몇몇 함수를 사용하여 정보를 추출할 수 있습니다.\n\nir &lt;- IRanges(start = c(1,3), end = c(4,5))\nir\n\nstart(ir)\nend(ir)\nwidth(ir)\ndisjointBins(ir)\n\nir &lt;- IRanges(start = c(1,3,6), end = c(4,5,7))\nir\nbins &lt;- disjointBins(ir)\nbins\n\n이러한 정보를 가시화하는 가장 간단한 방법은 ggbio라는 패키지를 사용하는 것 입니다.\n\nlibrary(ggbio)\n\nautoplot(ir) \n\nautoplot(ir) + \n  theme_bw()\n\nautoplot(ir, aes(fill=width)) +\n  theme_bw()\n\n특히 disjoin과 reduce 함수는 overlap 되어 있는 구간의 분석을 수행하는데 유용하게 활용 됩니다.\n\nir2 &lt;- disjoin(ir)\nir2\nautoplot(ir)\nautoplot(ir2) \n\nir3 &lt;- IRanges::reduce(ir)\nir3\nautoplot(ir3) \n\n\n\n\n\n\n\nNote\n\n\n\n###Exercises\n\n구간의 길이가 각각 100, 15, 30, 45 인 IRange 객체를 만드시오\n1부터 100까지의 전체 구간에서 시작 위치가 각각 1, 15, 30, 60 이면서 길이가 20 인 IRange 객체를 만드시오",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tools for genome</span>"
    ]
  },
  {
    "objectID": "10-tools-for-genome-analysis.html#genomicranges",
    "href": "10-tools-for-genome-analysis.html#genomicranges",
    "title": "11  Tools for genome",
    "section": "11.3 GenomicRanges",
    "text": "11.3 GenomicRanges\nGenomicRanges는 지놈상의 위치정보와 Bioconductor에서 제공하는 다양한 high-throughput 정보들을 같이 표현하기 위해서 만들어진 패키지입니다.\nGRanges 함수를 이용해서 생성할 수 있으며 browseVignettes(\"GenomicRanges\") 나 methods() 함수를 이용해서 관련된 기능을 찾아서 사용할 수 있습니다.\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nGenomicRanges 구조와 활용법 이해\nmcols, seqlengths\ngetSeq 함수 사용법(with DNAString, GRanges classes)\n\n\n\n\nlibrary(GenomicRanges)\n\n\ngr &lt;- GRanges(\n  seqnames = \"chr1\", \n  ranges = IRanges(1:10, 101:110),\n  strand = rep(\"+\", 10)\n)\ngr\nclass(gr)\n\n다양한 함수 사용법을 보여줍니다.\n\ngr &lt;- GRanges(\n    seqnames = Rle(c(\"chr1\", \"chr2\", \"chr1\", \"chr3\"), c(1, 3, 2, 4)),\n    ranges = IRanges(101:110, end = 111:120, names = head(letters, 10)),\n    strand = Rle(strand(c(\"-\", \"+\", \"*\", \"+\", \"-\")), c(1, 2, 2, 3, 2)),\n    score = 1:10,\n    GC = seq(1, 0, length=10))\ngr\n\nseqnames(gr)\nranges(gr)\nstrand(gr)\n\ngranges(gr) \nmcols(gr) #meta data\nseqlengths(gr)\n\nseqlengths(gr) &lt;- c(249250621, 243199373, 198022430)\nnames(gr)\n\nggbio의 autoplot을 사용하여 IRange와 같이 가시화 할 수 있으며 split 함수를 사용하면 지정된 규칙에 따라 Grange를 나눌 수 있습니다.\n\nautoplot(gr)\nsp &lt;- split(gr, rep(1:2, each=5))\n\n\n\n\n\n\n\nExercises\n\n\n\n위 결과에서 chromosome 별로 항목을 나눈 Grange list를 만드시오\n\n\n앞서 getSeq 함수를 GenBankRecord 객체에 사용할 경우 whole genome 서열을 추출할 수 있음을 보였습니다. 특정 CDS 서열들을 추출할때도 getSeq 함수를 활용할 수 있습니다. 다음과 같이 DNAString 객체와 GRanges 객체를 입력 매개변수로 넣어줄 경우 GRanges 객체에 있는 범위의 CDS들의 서열을 모두 추출할 수 있습니다. 이 때 각 두 객체의 Sequence name은 같아야 합니다. 다음 예제는 NC_045512.2 서열에 대한 CDS 추출, 서열 비교, 가시화 등의 수행합니다.\n:::",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tools for genome</span>"
    ]
  },
  {
    "objectID": "10-tools-for-genome-analysis.html#plyragnes",
    "href": "10-tools-for-genome-analysis.html#plyragnes",
    "title": "11  Tools for genome",
    "section": "11.4 plyragnes",
    "text": "11.4 plyragnes\n위 GenomicRanges 데이터를 dplyr 형태로 좀 더 쉽게 다루기 위한 패키지가 plyragnes 입니다.\n\n\n\n\n\n\n카이스트 강의\n\n\n\n\nplyranges 활용법 이해\nplyranges 와 data.frame 변환 활용 이해 mcols, as_granges\n\n\n\n\nlibrary(plyranges)\nlibrary(tidyverse)\n\ncovid19cds\ngcr &lt;- rowSums(letterFrequency(cdsseqs, c(\"G\", \"C\"), as.prob=T))\n\ncovid19cds |&gt; \n  dplyr::select(gene, product) |&gt; \n  dplyr::mutate(gc = gcr) |&gt; \n  dplyr::filter(gc &lt; 0.4)\n\ncovid19cds |&gt; \n  mcols() |&gt; \n  as.data.frame()\n\ngr &lt;- data.frame(\n        seqnames = sample(c(\"chr1\", \"chr2\"), 7, replace = TRUE),\n        strand = sample(c(\"+\", \"-\"), 7, replace = TRUE),\n        gc = runif(7),\n        start = 1:7,\n        width = 10) |&gt; \n      as_granges()\n\n\n\n\n\n\n\nNote\n\n\n\n###Exercises\n위에서 계산된 GC 비율로 bar 그래프를 그리되 product를 라벨로 지정하여 그리시오",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tools for genome</span>"
    ]
  },
  {
    "objectID": "10-tools-for-genome-analysis.html#visualization",
    "href": "10-tools-for-genome-analysis.html#visualization",
    "title": "11  Tools for genome",
    "section": "11.5 Visualization",
    "text": "11.5 Visualization\n\nrequire(ggplot2)\nrequire(gggenes)\nrequire(plyranges)\n\ntargetr &lt;- covid19cds\n\nas.data.frame(mcols(targetr))\n \nplyranges::summarise(targetr)\n\nplotdf1 &lt;-   data.frame(molecule=seqnames(targetr),\n                         gene=mcols(targetr)$gene,\n                         start=start(targetr),\n                         end=end(targetr),\n                         strand=case_when(\n                                  as.vector(strand(targetr))==\"+\"~ TRUE,\n                                  as.vector(strand(targetr))==\"-\"~ FALSE\n                                )\n                         )\n\n\nggplot(plotdf1, aes(xmin = start, xmax = end, y = molecule, label=gene, fill = gene, forward = strand)) +\n  geom_gene_arrow(\n    #arrowhead_height = unit(3, \"mm\"), \n    #arrowhead_width = unit(1, \"mm\")\n    arrowhead_height = grid::unit(12, \"mm\"),\n    arrowhead_width = grid::unit(6, \"mm\"),\n    arrow_body_height = grid::unit(12, \"mm\")\n    ) +\n  geom_gene_label(align = \"left\", height = grid::unit(19, \"mm\"), grow=TRUE) +\n  theme_genes() +\n  theme(legend.position=\"none\")\n\n다음은 대장균 지놈 NC_000913.3 gb 파일을 다운로드 받고 지놈 전체를 가시화 하는 코드입니다.\n\nlibrary(rentrez)\nlibrary(genbankr)\n\ntmps &lt;- entrez_fetch(\"nuccore\", id=\"NC_000913.3\", rettype=\"gbwithparts\")\nwrite(tmps, \"examples/ecoli-mg1655.gb\")\necoligb &lt;- readGenBank(\"examples/ecoli-mg1655.gb\")\n\necoli_cds &lt;- cds(ecoligb)\necoli_cds\n\np.txdb &lt;- autoplot(ecoli_cds)\np.txdb\n\n#library(igvR)\necoli_cds\nggbio() + \n  circle(ecoli_cds, geom = \"ideo\", fill = \"gray70\") +\n  circle(ecoli_cds, geom = \"scale\", size = 5) +\n  circle(ecoli_cds, geom = \"text\", aes(label = locus_tag), vjust = 0, size = 3) +\n  theme(\n    axis.text.x = element_text(angle=90)\n  )\n\ngr1 &lt;- granges(ecoli_cds)\ngr2 &lt;- granges(ecoli_cds)\nmcols(gr2)$test &lt;- rnorm(length(ecoli_cds))\nggplot() + \n  layout_circle(ecoli_cds, geom = \"ideo\", fill = \"gray70\", radius = 9, trackWidth = 1) +\n  layout_circle(ecoli_cds, geom = \"scale\", size = 3, trackWidth = 1, scale.n=20) +\n  layout_circle(gr1, geom = \"rect\", color = \"steelblue\",  radius = 5) +\n  layout_circle(gr2, geom = \"bar\", aes(y=test), size = 3, trackWidth = 1, scale.n=20, radius = 4) \n\n\n이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tools for genome</span>"
    ]
  },
  {
    "objectID": "99-homeworks.html",
    "href": "99-homeworks.html",
    "title": "12  HOMEWORK",
    "section": "",
    "text": "12.1 HOMEWORK\nYou will write a report describing the genome wide gene expression of putative proteins in your target organism. You will have a Quarto file (qmd file) at the end and upload the file on klms.kaist.ac.kr until 22nd Dec. It should include R code-chunk that can be executable. Insert figures in the qmd file.\nSee the following guide. These steps in the guide include minimal requirements for your reference. You can do any additional work you want. You can do it with the same organism but don’t use the same expression sample (GSE) with the following guide.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>HOMEWORK</span>"
    ]
  },
  {
    "objectID": "99-homeworks.html#homework",
    "href": "99-homeworks.html#homework",
    "title": "12  HOMEWORK",
    "section": "",
    "text": "12.1.1 Preparation a qmd file\n\nInstall R, Rstudio, Quarto on your local computer (OR use posit-cloud)\nCreate a new quarto file\nStart with the YAML head as follows\n\n```{r}\n\n    ---\n    title: \"HOMEWORK\"\n    eval: false\n    author: Your name and student number\n    date: The date you make this\n    format: \n      html: \n        toc: true\n        number-sections: true\n        code-overflow: wrap\n    ---\n    \n```\n\n\n12.1.2 Choose a target organism\n\n\n\n\n\n\nAdditional requirements\n\n\n\n\nInclude a brief description of the organism in the quarto file\n\n\n\n\nChoose a target organism you are interested in\nSearch for its information in NCBI genome database (https://www.ncbi.nlm.nih.gov/datasets/genome/\n\n\n\nClick “Scientific name”\n\n\n\nConfirm if there is any Series in GEO database and Click Reference genome ID\n\n\n\nAt the bottom, memorize Genbank id “U00096.3”\n\n\n\n\n12.1.3 Download\n\nUse rentrez to download gb file (it takes time)\n\n\nlibrary(rentrez)\n\nrecs &lt;- entrez_fetch(db=\"nuccore\", id=\"U00096.3\", rettype=\"gbff\")\nwrite(recs, file=\"examples/u00096-3.gb\")\n\n\n\n12.1.4 Visualize genes with putative functions\n\n\n\n\n\n\nAdditional requirements\n\n\n\n\nWhat’s the proportion of the putative proteins\n\n\n\n\nUse readGenBank() function in genbankr package to load the genbank file\nUse cds() function in Biostrings package to load cds information\nUse pyranges function for filtering\nUse ggbio for visualization\n\n\nlibrary(genbankr)\nlibrary(Biostrings)\nlibrary(BSgenome)\nlibrary(plyranges)\nlibrary(ggbio)\n\nmygenome &lt;- readGenBank(\"examples/u00096-3.gb\")\nmycds &lt;- cds(mygenome)\n\ngr1 &lt;- granges(mycds)\ngr2 &lt;- mycds |&gt; \n  plyranges::filter(grepl(\"putative\", product)) |&gt; \n  granges()\n  \n\nggplot() + \n  layout_circle(mycds, geom = \"ideo\", fill = \"gray70\", radius = 9, trackWidth = 1) +\n  layout_circle(mycds, geom = \"scale\", size = 3, trackWidth = 1, scale.n=20)   +\n  layout_circle(gr1, geom = \"rect\", color = \"steelblue\",  radius = 5)  +\n  layout_circle(gr2, geom = \"rect\", trackWidth = 1, scale.n=20, radius = 4) \n\n\n\n12.1.5 Codon usage\n\n\n\n\n\n\nAdditional requirements\n\n\n\n\nHow long is the whole genome?\nWhat is the average length of cds?\n\n\n\n\nPlot for the codon usage\nUse getSeq() function in BSgenome package to read whole genome sequence\n\n\nmyseq &lt;- BSgenome::getSeq(mygenome)\nmycdsseq &lt;- BSgenome::getSeq(myseq, gr1)\ncodon_usage &lt;- trinucleotideFrequency(mycdsseq, step=3)\nglobal_codon_usage &lt;- trinucleotideFrequency(mycdsseq, step=3, simplify.as=\"collapsed\")\nnames(global_codon_usage) &lt;- GENETIC_CODE[names(global_codon_usage)]\ncodonusage2 &lt;- split(global_codon_usage, names(global_codon_usage))\nglobal_codon_usage2 &lt;- sapply(codonusage2, sum) \n\n\nUse ggplot for the bar graph\nUse dplyr, tibble for tidy data (load tidyverse)\n\n\nlibrary(tidyverse)\n\nglobal_codon_usage2 |&gt; \n  data.frame() |&gt; \n  tibble::rownames_to_column() |&gt; \n  dplyr::rename(gcu = global_codon_usage2, aa = rowname) |&gt; \n  ggplot(aes(x=aa, y=gcu)) +\n  geom_bar(stat=\"identity\")\n\n\n\n12.1.6 CDS length distribution\n\nseqlen &lt;- nchar(mycdsseq) |&gt; \n  data.frame() |&gt; \n  dplyr::rename(len = nchar.mycdsseq.)\nseqlen |&gt; \n  ggplot(aes(x=len)) +\n  geom_density(fill=\"green\", alpha=0.2, adjust=3) +\n  scale_x_continuous(limits = c(-1000, 8000))\n\nseqlen |&gt; \n  summarize(m = mean(len), s = sd(len))\n\n\n\n12.1.7 Load GEO data\n\n\n\n\n\n\nAdditional requirements\n\n\n\n\nInclude description of the data\n\n\n\n\nClick Series related to the target organism\n\n\n\nChoose any GSE with enough number of samples\n\n\n\nAvoid to use zero feature gse dataset as below. Try to use another gse dataset which contains features\n\n\n\nlibrary(GEOquery)\n\ngse &lt;- getGEO('GSE17276', GSEMatrix = TRUE, destdir = \"examples\")\nmygse &lt;- gse[[1]]\nclass(mygse)\nmygse\n\n\n\n12.1.8 Draw boxplot\n\n\n\n\n\n\nAdditional requirements\n\n\n\n\nDescribe what is the difference between normalization and standardization\nDo you need to normalize your data?\n\n\n\n\n\nlibrary(tidyverse)\n\nmypdata &lt;- pData(mygse)\nmyfdata &lt;- fData(mygse)\nmyexp &lt;- as.data.frame(exprs(mygse))\n\n# boxplot\nmyexp |&gt; \n  rownames_to_column() |&gt; \n  pivot_longer(-rowname) |&gt; \n  ggplot(aes(x=name, y=value)) +\n  geom_boxplot() \n\n\n\n12.1.9 The expression of putative proteins\n\nSince we used the same organism for the genome info and GEO database, we can find the expression of putative genes\n\n\nlibrary(plyranges)\n\nputative_locus_tags &lt;- mycds |&gt; \n  mcols() |&gt; \n  data.frame() |&gt; \n  dplyr::filter(grepl(\"putative\", product)) |&gt; \n  dplyr::slice_sample(n=100) |&gt;  ## 100 samples for visulization\n  dplyr::pull(locus_tag)  \n\n\nGet the expression of the putative protein genes\n\n\nnewexp &lt;- myexp |&gt; \n  bind_cols(myfdata) |&gt; \n  dplyr::filter(ORF %in% putative_locus_tags) |&gt; \n  dplyr::select(-ID, -GENE_SYMBOL) |&gt; \n  dplyr::select(ORF, everything()) |&gt; \n  tidyr::drop_na()\n\n\nMerge two dataframes by accession number “GSMxxx” for the addition of group information (phenogroup)\n\n\nphenogroup &lt;- mypdata |&gt; \n  dplyr::select(geo_accession, source_name_ch1)\n\nnewexp_t &lt;- newexp |&gt; \n  pivot_longer(-ORF) |&gt; \n  pivot_wider(names_from = \"ORF\") \n\nnewexp_m &lt;- phenogroup |&gt; \n  left_join(newexp_t, by = join_by(geo_accession == name)) |&gt; \n  dplyr::rename(accno = geo_accession, type = source_name_ch1)\n\n\nVisualization of the putative genes with respect to the phenotype\n\n\nnewexp_m |&gt; \n  pivot_longer(-c(accno, type)) |&gt; \n  group_by(type, name) |&gt; \n  summarize(m = mean(value), s = sd(value)) |&gt; \n  ggplot(aes(x=type, y=m, fill=type)) +\n  geom_bar(stat=\"identity\", position = \"dodge\") +\n  facet_wrap(name ~ .) +\n  scale_x_discrete(labels = NULL)",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>HOMEWORK</span>"
    ]
  },
  {
    "objectID": "11-statistics-and-modeling.html",
    "href": "11-statistics-and-modeling.html",
    "title": "13  Statistics and modeling",
    "section": "",
    "text": "13.1 Statistics\nPredictions through data analysis. In other words, the process of collecting and organizing data and making reliable inferences about unknown facts from it.\n본 강의에서는 Inference와 Prediction을 중심으로 개요를 설명하도록 합니다. Reliability와 Probability, Random variable, Distribution 등은 통계뿐만 아니라 딥러닝에서도 매우 중요한 개념으로 관심있는 분들은 꼭 학습하시길 바랍니다.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Statistics and modeling</span>"
    ]
  },
  {
    "objectID": "11-statistics-and-modeling.html#statistics",
    "href": "11-statistics-and-modeling.html#statistics",
    "title": "13  Statistics and modeling",
    "section": "",
    "text": "13.1.1 Univariate data\n추정 관점에서 변수가 1개 일 때 예시로 모집단의 평균을 추정할 수 있습니다. 아래 에시에서 100개 데이터를 뽑은 것으로 평균을 구하고 이 표본평균을 모평균의 추정량으로 사용할 수 있습니다.\n\nx &lt;- rnorm(100)\nhist(x)\n\nmean(x)\nsd(x)\n\n\n\n\n13.1.2 Multivariate data\n두 개 이상의 변수가 있는 상황에서는 두 변수 사이의 관계를 추정할 수 있습니다. f(x)는 true 관계를 나타내고 관측 데이터를 이용해서 추정합니다.\n\n이렇게 추정된 f(x)는 예측에 활용됩니다. 즉, f(x)를 이용해서 관측되지 않은 x에 대한 y값을 구할 수 있습니다. 이는 BSA와 같은 단백질 정량 등의 실험에서 표준곡선을 그리고 표준곡선을 활용한 농도 계산과 같은 의미 입니다.\n\nlibrary(ggplot2)\n\nx &lt;- rnorm(100)\ny &lt;- x*2 + rnorm(100)\nxy &lt;- data.frame(x, y)\n\nggplot(xy, aes(x=x, y=y)) +\n  geom_point() +\n  geom_smooth(method = lm, formula = y ~ x, se = FALSE)\n\nggplot(xy, aes(x=x, y=y)) +\n  geom_point() +\n  #geom_smooth(method = lm, formula = y ~ x, se = FALSE) +\n  scale_x_continuous(limit=c(-4, 4)) +\n  scale_y_continuous(limit=c(-10, 10)) +\n  geom_abline(intercept = 0.026, slope = 2.11, lwd=2, color=\"blue\")",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Statistics and modeling</span>"
    ]
  },
  {
    "objectID": "11-statistics-and-modeling.html#modeling-and-prediction",
    "href": "11-statistics-and-modeling.html#modeling-and-prediction",
    "title": "13  Statistics and modeling",
    "section": "13.2 Modeling and Prediction",
    "text": "13.2 Modeling and Prediction\n이러한 모델링 방법은 전통적 통계모형에서 최근 인공지능 모형까지 수많은 연구가 진행되어 왔습니다. 이 중 예측 관점에서는 다음과 같은 특성을 말할 수 있습니다.\n\n전통적 통계 모형에서는 p-value와 같이 관측된 통계량에 대한 신뢰성을 검증할 수 있는 반면 최근 AI 모형은 정확도를 더 중시합니다. 인공지능 모형의 복잡도 문제로 요인들의 관계를 설명할 수 없는 경우가 많기 때문인데 최근에는 attention 기법을 이용해서 요인들의 관계를 설명할 가능성도 열려 있습니다.\n\n13.2.1 Statistical learning and Deep learning\n예측의 관점에서 최근의 기계학습이나 인공지능 모형은 지도학습과 비지도학습, 그리고 강화학습으로 나눌 수 있습니다. 이 중 다음과 같이 지도학습은 회귀와 분류, 비지도학습은 군집 및 주성분분석 등으로 나눌 수 있습니다.\n\n비록 통계모형 관점에서 검정의 비중이 줄어들긴 했지만 여전히 통계학의 확률과 분포 이론을 활용하고 있고 이는 딥러닝 역시 마찬가지 입니다. Liear regression은 1개 layer에 ReLU, tanh, sigmoid 등 activation function이 없는 딥러닝 모형과 같고 Logistic regression의 분류 문제는 Layer 1개, Activation function도 하나가 있는 모형과 같습니다. 딥러닝 모형의 일반적인 Dense layer는 여러개의 layer와 softmax 를 갖는 모형과 같습니다.\n\n생성형 모형도 유사한 관계가 있습니다. PCA는 차원축소의 대표적 비지도 학습 모형입니다. 공분산행렬로부터 주성분을 구하고 적절한 주성분 몇 개만을 가지고 전체 데이터를 설명할 수 있습니다. 이렇게 축소된 데이터에서 다시 원래 데이터로 복원하는 모형이 Auto encoder와 같은 개념이며 VAE와 GAN에서도 활용됩니다.\n\n위와 같이 통계 개념을 활용하여 계속해서 새로운 딥러닝 모형이 개발되고 있고 기존 모형들의 올바른 활용을 위해서도 통계 이론 습득이 필요합니다.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Statistics and modeling</span>"
    ]
  },
  {
    "objectID": "11-statistics-and-modeling.html#tidymodel",
    "href": "11-statistics-and-modeling.html#tidymodel",
    "title": "13  Statistics and modeling",
    "section": "13.3 Tidymodel",
    "text": "13.3 Tidymodel\ntidymodel은 기존 R에서 활용되는 수많은 종류의 모델링 기술을 통합하기 위해서 만들어진 패키지 입니다. tidyverse 패키지와 함께 데이터사이언스 분야에서는 주요하게 활용되는 분석 도구입니다. tidyverse에서 데이터분석에 관련한 기본 철학은 아래와 같이 데이터 수집, transform, visualize, model, 그리고 share 이며 이 중 modeling 관련한 프로세스를 통합하고 표준화 했습니다. Recipe와 parsnip 등 다양한 패키지들이 활용되는데 본 강의에서는 다루지 않습니다. 그러나 기계학습 수준의 데이터 규모를 갖는 분석 영역에서는 중요하게 활용될 수 있는 도구로서 최근에 사용이 증가하고 있습니다.\n\n\n13.3.1 Linear regression\n간략히 선형모형 관련한 데이터 생성과 tidymodel 활용한 예시를 아래에 소개해 드리니 참고하시면 되겠습니다.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nx1 &lt;- rnorm(1000)\nx2 &lt;- rnorm(1000)\ny &lt;- x1*2 + x2*4 + rnorm(1000)\n\nxy &lt;- data.frame(x1, x2, y)\n\n# data spliting\nset.seed(123)\n# 3/4 of the data into the training set \nxy_split &lt;- initial_split(xy, prop = 3/4)\n\ntrain_data &lt;- training(xy_split)\ntest_data  &lt;- testing(xy_split)\n\n\n# model type\nmodel &lt;- linear_reg() |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine('lm')\n\n# recipe, the role of variables\nrec &lt;- recipe(\n  y ~ .,\n  data = train_data\n  )  \n\n# estimate a preprocessing recipe\nrec |&gt; \n  prep()\n\n# display data\nrec |&gt; \n  prep() |&gt; \n  juice()\n\nrec |&gt; \n  step_mutate(x12 = x1*x2) |&gt; \n  prep() |&gt; \n  juice() |&gt; \n  boxplot()\n\n\n# workflow \nwk &lt;- workflow() |&gt; \n  add_model(model) |&gt; \n  add_recipe(rec)\n\n# fit the model to the training data\nmodel_fit &lt;- wk |&gt; \n  fit(data = train_data)\n\n# parameter estimates\nmodel_fit |&gt; \n  tidy()\n\n# model statistics (goodness of fit)\nmodel_fit |&gt; \n  glance()\n\n# apply the same recipe to the test set\nnewd &lt;- bake(prep(rec), test_data)\n\n# prediction\nmodel_fit |&gt; \n  predict(new_data = newd)\n  \nmodel_fit |&gt; \n  augment(new_data = newd) \n\nmodel_fit |&gt; \n  augment(new_data = newd) |&gt; \n  dplyr::select(y, .pred) |&gt; \n  ggplot(aes(x=y, y=.pred)) +\n  geom_point()",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Statistics and modeling</span>"
    ]
  },
  {
    "objectID": "12-additional_info.html",
    "href": "12-additional_info.html",
    "title": "14  Additional information",
    "section": "",
    "text": "14.1 Bioconductor installation error",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Additional information</span>"
    ]
  },
  {
    "objectID": "12-additional_info.html#bioconductor-installation-error",
    "href": "12-additional_info.html#bioconductor-installation-error",
    "title": "14  Additional information",
    "section": "",
    "text": "14.1.1 Error\n'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories:     CRAN: https://cran.rstudio.com/\nBioconductor version 3.18 (BiocManager 1.30.22), R 4.3.0 (2023-04-21 ucrt) Installing package(s) 'genbankr'\n경고: package ‘genbankr’ is not available for Bioconductor version '3.18'\n\n\n14.1.2 조치\n\nR 버전 4.2.3 설치 (기존 R, Rstudio 설치된 것 상관없이 진행)\n\ngo to https://cran.r-project.org/mirrors.html and click KOREA https://cran.yu.ac.kr/\nclick the followings “Download R for windows” &gt; “base” &gt; “Previous releases” &gt; “R 4.2.3”\nDownload “R-4.2.3-win.exe” and install it\n\nRstudio 실행 후 R version 변경\n\nRstudio 실행, Tools &gt; Global Options &gt; General\n\n\n\n\n\nRstudio 재시작 후 재설치\nif (!require(“BiocManager”, quietly = TRUE)) install.packages(“BiocManager”)\nBiocManager::install(“genbankr”)",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Additional information</span>"
    ]
  }
]